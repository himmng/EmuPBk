{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from ipywidgets import interact\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import keras as ks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mbackup_data\u001b[0m/  data_read.py  \u001b[01;34mk0.3\u001b[0m/  Testing.ipynb\r\n",
      "BEmu.ipynb    \u001b[01;34mk0.2\u001b[0m/         \u001b[01;34mk1.5\u001b[0m/  Untitled.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.loadtxt('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bk_02_train = np.loadtxt('Bk_02_train')\n",
    "Bk__02_test = np.loadtxt('Bk_02_test')\n",
    "Bk_03_train = np.loadtxt('Bk_03_train')\n",
    "Bk__03_test = np.loadtxt('Bk_03_test')\n",
    "Bk_15_train = np.loadtxt('Bk_15_train')\n",
    "Bk__15_test = np.loadtxt('Bk_15_test')\n",
    "params_train = np.loadtxt('params_train')\n",
    "params_test = np.loadtxt('params_test')\n",
    "index = np.loadtxt('indicies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1019, 550), (1019, 550), (1019, 550))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bk_02_train.shape,Bk_03_train.shape,Bk_15_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bk_15_train = Bk_15_train/10000000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 957 samples, validate on 62 samples\n",
      "Epoch 1/5000\n",
      "957/957 [==============================] - 1s 802us/step - loss: 19.5512 - accuracy: 0.5664 - val_loss: 17.6108 - val_accuracy: 0.7097\n",
      "Epoch 2/5000\n",
      "957/957 [==============================] - 1s 621us/step - loss: 11.3476 - accuracy: 0.7189 - val_loss: 10.1146 - val_accuracy: 0.7581\n",
      "Epoch 3/5000\n",
      "957/957 [==============================] - 1s 621us/step - loss: 8.6784 - accuracy: 0.7273 - val_loss: 10.3538 - val_accuracy: 0.7581\n",
      "Epoch 4/5000\n",
      "957/957 [==============================] - 1s 618us/step - loss: 8.1342 - accuracy: 0.7482 - val_loss: 8.5832 - val_accuracy: 0.7581\n",
      "Epoch 5/5000\n",
      "957/957 [==============================] - 1s 615us/step - loss: 6.0888 - accuracy: 0.7471 - val_loss: 9.9631 - val_accuracy: 0.6935\n",
      "Epoch 6/5000\n",
      "957/957 [==============================] - 1s 617us/step - loss: 5.8481 - accuracy: 0.7419 - val_loss: 8.0716 - val_accuracy: 0.7581\n",
      "Epoch 7/5000\n",
      "957/957 [==============================] - 1s 640us/step - loss: 5.8830 - accuracy: 0.7565 - val_loss: 8.3635 - val_accuracy: 0.8226\n",
      "Epoch 8/5000\n",
      "957/957 [==============================] - 1s 658us/step - loss: 4.7919 - accuracy: 0.7712 - val_loss: 9.8217 - val_accuracy: 0.7419\n",
      "Epoch 9/5000\n",
      "957/957 [==============================] - 1s 656us/step - loss: 4.5495 - accuracy: 0.7889 - val_loss: 8.0263 - val_accuracy: 0.8387\n",
      "Epoch 10/5000\n",
      "957/957 [==============================] - 1s 634us/step - loss: 4.4080 - accuracy: 0.8098 - val_loss: 6.5387 - val_accuracy: 0.8065\n",
      "Epoch 11/5000\n",
      "957/957 [==============================] - 1s 614us/step - loss: 4.1068 - accuracy: 0.8056 - val_loss: 7.9736 - val_accuracy: 0.8226\n",
      "Epoch 12/5000\n",
      "957/957 [==============================] - 1s 616us/step - loss: 3.7498 - accuracy: 0.8109 - val_loss: 8.2137 - val_accuracy: 0.8387\n",
      "Epoch 13/5000\n",
      "957/957 [==============================] - 1s 678us/step - loss: 4.0300 - accuracy: 0.8171 - val_loss: 9.4934 - val_accuracy: 0.8065\n",
      "Epoch 14/5000\n",
      "957/957 [==============================] - 1s 657us/step - loss: 3.5880 - accuracy: 0.8098 - val_loss: 5.9769 - val_accuracy: 0.8387\n",
      "Epoch 15/5000\n",
      "957/957 [==============================] - 1s 658us/step - loss: 3.2121 - accuracy: 0.8098 - val_loss: 7.0583 - val_accuracy: 0.8065\n",
      "Epoch 16/5000\n",
      "957/957 [==============================] - 1s 634us/step - loss: 3.1896 - accuracy: 0.8056 - val_loss: 7.1706 - val_accuracy: 0.8065\n",
      "Epoch 17/5000\n",
      "957/957 [==============================] - 1s 642us/step - loss: 3.7347 - accuracy: 0.7962 - val_loss: 5.0522 - val_accuracy: 0.7903\n",
      "Epoch 18/5000\n",
      "957/957 [==============================] - 1s 655us/step - loss: 3.6114 - accuracy: 0.8046 - val_loss: 5.2315 - val_accuracy: 0.8226\n",
      "Epoch 19/5000\n",
      "957/957 [==============================] - 1s 640us/step - loss: 2.8671 - accuracy: 0.7973 - val_loss: 4.2381 - val_accuracy: 0.8065\n",
      "Epoch 20/5000\n",
      "957/957 [==============================] - 1s 660us/step - loss: 3.1355 - accuracy: 0.8046 - val_loss: 5.4965 - val_accuracy: 0.7903\n",
      "Epoch 21/5000\n",
      "957/957 [==============================] - 1s 664us/step - loss: 3.6738 - accuracy: 0.8046 - val_loss: 8.7312 - val_accuracy: 0.8065\n",
      "Epoch 22/5000\n",
      "957/957 [==============================] - 1s 632us/step - loss: 3.4010 - accuracy: 0.8109 - val_loss: 8.4313 - val_accuracy: 0.8065\n",
      "Epoch 23/5000\n",
      "957/957 [==============================] - 1s 619us/step - loss: 3.0359 - accuracy: 0.8119 - val_loss: 4.9676 - val_accuracy: 0.8065\n",
      "Epoch 24/5000\n",
      "957/957 [==============================] - 1s 613us/step - loss: 2.9510 - accuracy: 0.8036 - val_loss: 3.7369 - val_accuracy: 0.8065\n",
      "Epoch 25/5000\n",
      "957/957 [==============================] - 1s 624us/step - loss: 3.1880 - accuracy: 0.8234 - val_loss: 4.4583 - val_accuracy: 0.7742\n",
      "Epoch 26/5000\n",
      "957/957 [==============================] - 1s 647us/step - loss: 2.5090 - accuracy: 0.8130 - val_loss: 4.8608 - val_accuracy: 0.7903\n",
      "Epoch 27/5000\n",
      "957/957 [==============================] - 1s 661us/step - loss: 2.6360 - accuracy: 0.8276 - val_loss: 4.1444 - val_accuracy: 0.7742\n",
      "Epoch 28/5000\n",
      "957/957 [==============================] - 1s 642us/step - loss: 2.4719 - accuracy: 0.8307 - val_loss: 5.2204 - val_accuracy: 0.7903\n",
      "Epoch 29/5000\n",
      "957/957 [==============================] - 1s 654us/step - loss: 2.8290 - accuracy: 0.8213 - val_loss: 3.6275 - val_accuracy: 0.7903\n",
      "Epoch 30/5000\n",
      "957/957 [==============================] - 1s 631us/step - loss: 1.9414 - accuracy: 0.8213 - val_loss: 8.8373 - val_accuracy: 0.7742\n",
      "Epoch 31/5000\n",
      "957/957 [==============================] - 1s 616us/step - loss: 3.3766 - accuracy: 0.8171 - val_loss: 3.2653 - val_accuracy: 0.7742\n",
      "Epoch 32/5000\n",
      "957/957 [==============================] - 1s 687us/step - loss: 2.8302 - accuracy: 0.8171 - val_loss: 3.3717 - val_accuracy: 0.7742\n",
      "Epoch 33/5000\n",
      "957/957 [==============================] - 1s 658us/step - loss: 2.5597 - accuracy: 0.8234 - val_loss: 3.3924 - val_accuracy: 0.7903\n",
      "Epoch 34/5000\n",
      "957/957 [==============================] - 1s 679us/step - loss: 2.4424 - accuracy: 0.8349 - val_loss: 4.4346 - val_accuracy: 0.7903\n",
      "Epoch 35/5000\n",
      "957/957 [==============================] - 1s 678us/step - loss: 1.8962 - accuracy: 0.8318 - val_loss: 3.6812 - val_accuracy: 0.8226\n",
      "Epoch 36/5000\n",
      "957/957 [==============================] - 1s 636us/step - loss: 1.8413 - accuracy: 0.8213 - val_loss: 2.4267 - val_accuracy: 0.8387\n",
      "Epoch 37/5000\n",
      "957/957 [==============================] - 1s 618us/step - loss: 2.3090 - accuracy: 0.8380 - val_loss: 2.6812 - val_accuracy: 0.8387\n",
      "Epoch 38/5000\n",
      "957/957 [==============================] - 1s 636us/step - loss: 2.0249 - accuracy: 0.8370 - val_loss: 2.2510 - val_accuracy: 0.7903\n",
      "Epoch 39/5000\n",
      "957/957 [==============================] - 1s 633us/step - loss: 1.9765 - accuracy: 0.8318 - val_loss: 4.1992 - val_accuracy: 0.7903\n",
      "Epoch 40/5000\n",
      "957/957 [==============================] - 1s 641us/step - loss: 1.9357 - accuracy: 0.8485 - val_loss: 2.5588 - val_accuracy: 0.7742\n",
      "Epoch 41/5000\n",
      "957/957 [==============================] - 1s 660us/step - loss: 2.2215 - accuracy: 0.8401 - val_loss: 3.3138 - val_accuracy: 0.8065\n",
      "Epoch 42/5000\n",
      "957/957 [==============================] - 1s 674us/step - loss: 1.4092 - accuracy: 0.8454 - val_loss: 2.3269 - val_accuracy: 0.8387\n",
      "Epoch 43/5000\n",
      "957/957 [==============================] - 1s 636us/step - loss: 1.8223 - accuracy: 0.8495 - val_loss: 2.4965 - val_accuracy: 0.8226\n",
      "Epoch 44/5000\n",
      "957/957 [==============================] - 1s 626us/step - loss: 1.3212 - accuracy: 0.8537 - val_loss: 1.6381 - val_accuracy: 0.8548\n",
      "Epoch 45/5000\n",
      "957/957 [==============================] - 1s 619us/step - loss: 1.7745 - accuracy: 0.8433 - val_loss: 2.8242 - val_accuracy: 0.8226\n",
      "Epoch 46/5000\n",
      "957/957 [==============================] - 1s 632us/step - loss: 1.6077 - accuracy: 0.8328 - val_loss: 3.5112 - val_accuracy: 0.8387\n",
      "Epoch 47/5000\n",
      "957/957 [==============================] - 1s 655us/step - loss: 1.4316 - accuracy: 0.8265 - val_loss: 1.6634 - val_accuracy: 0.8548\n",
      "Epoch 48/5000\n",
      "957/957 [==============================] - 1s 664us/step - loss: 2.1212 - accuracy: 0.8339 - val_loss: 6.3438 - val_accuracy: 0.8065\n",
      "Epoch 49/5000\n",
      "957/957 [==============================] - 1s 633us/step - loss: 2.1827 - accuracy: 0.8422 - val_loss: 1.4650 - val_accuracy: 0.8387\n",
      "Epoch 50/5000\n",
      "957/957 [==============================] - 1s 615us/step - loss: 2.2353 - accuracy: 0.8495 - val_loss: 2.0242 - val_accuracy: 0.8387\n",
      "Epoch 51/5000\n",
      "957/957 [==============================] - 1s 623us/step - loss: 1.2131 - accuracy: 0.8506 - val_loss: 1.7492 - val_accuracy: 0.8226\n",
      "Epoch 52/5000\n",
      "957/957 [==============================] - 1s 628us/step - loss: 1.4946 - accuracy: 0.8589 - val_loss: 1.6977 - val_accuracy: 0.8226\n",
      "Epoch 53/5000\n",
      "957/957 [==============================] - 1s 627us/step - loss: 1.7911 - accuracy: 0.8610 - val_loss: 3.7238 - val_accuracy: 0.7903\n",
      "Epoch 54/5000\n",
      "957/957 [==============================] - 1s 642us/step - loss: 1.8312 - accuracy: 0.8464 - val_loss: 15.5316 - val_accuracy: 0.7581\n",
      "Epoch 55/5000\n",
      "957/957 [==============================] - 1s 636us/step - loss: 2.0394 - accuracy: 0.8600 - val_loss: 1.6520 - val_accuracy: 0.9032\n",
      "Epoch 56/5000\n",
      "957/957 [==============================] - 1s 608us/step - loss: 1.6026 - accuracy: 0.8621 - val_loss: 2.1182 - val_accuracy: 0.8548\n",
      "Epoch 57/5000\n",
      "957/957 [==============================] - 1s 606us/step - loss: 2.2915 - accuracy: 0.8746 - val_loss: 5.7154 - val_accuracy: 0.8226\n",
      "Epoch 58/5000\n",
      "957/957 [==============================] - 1s 601us/step - loss: 1.7188 - accuracy: 0.8715 - val_loss: 2.4008 - val_accuracy: 0.8226\n",
      "Epoch 59/5000\n",
      "957/957 [==============================] - 1s 603us/step - loss: 1.2233 - accuracy: 0.8642 - val_loss: 1.3858 - val_accuracy: 0.8548\n",
      "Epoch 60/5000\n",
      "957/957 [==============================] - 1s 606us/step - loss: 1.4164 - accuracy: 0.8662 - val_loss: 1.9538 - val_accuracy: 0.8548\n",
      "Epoch 61/5000\n",
      "957/957 [==============================] - 1s 611us/step - loss: 1.8146 - accuracy: 0.8579 - val_loss: 1.6091 - val_accuracy: 0.8548\n",
      "Epoch 62/5000\n",
      "957/957 [==============================] - 1s 648us/step - loss: 1.1292 - accuracy: 0.8704 - val_loss: 2.2133 - val_accuracy: 0.8710\n",
      "Epoch 63/5000\n",
      "957/957 [==============================] - 1s 621us/step - loss: 1.2082 - accuracy: 0.8652 - val_loss: 1.3611 - val_accuracy: 0.8871\n",
      "Epoch 64/5000\n",
      "957/957 [==============================] - 1s 615us/step - loss: 1.3345 - accuracy: 0.8715 - val_loss: 3.5312 - val_accuracy: 0.8387\n",
      "Epoch 65/5000\n",
      "957/957 [==============================] - 1s 635us/step - loss: 1.4223 - accuracy: 0.8798 - val_loss: 1.6173 - val_accuracy: 0.8387\n",
      "Epoch 66/5000\n",
      "957/957 [==============================] - 1s 616us/step - loss: 0.8828 - accuracy: 0.8704 - val_loss: 2.3539 - val_accuracy: 0.8387\n",
      "Epoch 67/5000\n",
      "957/957 [==============================] - 1s 631us/step - loss: 1.1427 - accuracy: 0.8798 - val_loss: 1.9319 - val_accuracy: 0.8226\n",
      "Epoch 68/5000\n",
      "957/957 [==============================] - 1s 621us/step - loss: 1.1858 - accuracy: 0.8725 - val_loss: 1.3961 - val_accuracy: 0.8387\n",
      "Epoch 69/5000\n",
      "957/957 [==============================] - 1s 613us/step - loss: 2.4522 - accuracy: 0.8589 - val_loss: 1.8718 - val_accuracy: 0.8710\n",
      "Epoch 70/5000\n",
      "957/957 [==============================] - 1s 612us/step - loss: 1.3924 - accuracy: 0.8725 - val_loss: 1.5425 - val_accuracy: 0.8710\n",
      "Epoch 71/5000\n",
      "957/957 [==============================] - 1s 621us/step - loss: 1.7558 - accuracy: 0.8725 - val_loss: 1.7325 - val_accuracy: 0.8710\n",
      "Epoch 72/5000\n",
      "957/957 [==============================] - 1s 660us/step - loss: 1.1449 - accuracy: 0.8757 - val_loss: 1.5741 - val_accuracy: 0.9194\n",
      "Epoch 73/5000\n",
      "957/957 [==============================] - 1s 648us/step - loss: 1.2307 - accuracy: 0.8830 - val_loss: 0.9346 - val_accuracy: 0.8871\n",
      "Epoch 74/5000\n",
      "957/957 [==============================] - 1s 645us/step - loss: 0.9928 - accuracy: 0.8830 - val_loss: 1.5460 - val_accuracy: 0.8387\n",
      "Epoch 75/5000\n",
      "957/957 [==============================] - 1s 639us/step - loss: 1.5965 - accuracy: 0.8715 - val_loss: 3.7279 - val_accuracy: 0.8548\n",
      "Epoch 76/5000\n",
      "957/957 [==============================] - 1s 633us/step - loss: 1.4688 - accuracy: 0.8757 - val_loss: 1.0885 - val_accuracy: 0.8710\n",
      "Epoch 77/5000\n",
      "957/957 [==============================] - 1s 626us/step - loss: 1.2333 - accuracy: 0.8819 - val_loss: 1.0537 - val_accuracy: 0.9032\n",
      "Epoch 78/5000\n",
      "957/957 [==============================] - 1s 673us/step - loss: 1.1035 - accuracy: 0.8725 - val_loss: 1.0498 - val_accuracy: 0.8548\n",
      "Epoch 79/5000\n",
      "957/957 [==============================] - 1s 639us/step - loss: 0.9045 - accuracy: 0.8777 - val_loss: 1.2767 - val_accuracy: 0.8710\n",
      "Epoch 80/5000\n",
      "957/957 [==============================] - 1s 614us/step - loss: 0.9551 - accuracy: 0.8746 - val_loss: 2.2211 - val_accuracy: 0.8710\n",
      "Epoch 81/5000\n",
      "957/957 [==============================] - 1s 641us/step - loss: 1.2323 - accuracy: 0.8736 - val_loss: 0.8924 - val_accuracy: 0.8710\n",
      "Epoch 82/5000\n",
      "780/957 [=======================>......] - ETA: 0s - loss: 1.5295 - accuracy: 0.8936"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b1194923f557>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.088\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBk_15_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.06\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class myCallback(ks.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>=0.96):\n",
    "            print(\"\\nReached 96% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "callbacks = myCallback()\n",
    "model = Sequential()\n",
    "model.add(Dense(80,input_shape=[3,],activation='elu'))\n",
    "model.add(Dense(320,activation='elu'))\n",
    "model.add(Dense(460,activation='elu'))\n",
    "model.add(Dense(560,activation='elu'))\n",
    "model.add(Dense(260,activation='elu'))\n",
    "model.add(Dense(100,activation='elu'))\n",
    "#model.add(Dense(450,activation='elu'))\n",
    "\n",
    "#model.add(Dense(750,activation='elu'))\n",
    "model.add(Dense(550))\n",
    "\n",
    "optimizer = Adamax(lr = 0.0001,beta_1=0.2,beta_2=0.088)   \n",
    "model.compile(loss='mse', optimizer= optimizer, metrics=['accuracy'],)\n",
    "history = model.fit(params_train,Bk_15_train,validation_split=0.06,epochs=5000,batch_size=10,callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ks.models.load_model('bk0.3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "plt.suptitle(r'Accuracy and Loss on the validation set for $B(k_1,k_2,k_3)$ at $k =0.2Mpc^{-1}$')\n",
    "plt.subplot(1,2,1)\n",
    "#plt.hline()\n",
    "c = list(np.arange(0,1,0.2))\n",
    "c.append(0.93)\n",
    "plt.yticks(c)\n",
    "plt.plot(history.history['accuracy'],lw=3,color = 'purple')\n",
    "plt.plot(history.history['val_accuracy'],lw=1.5,color='orange')\n",
    "plt.hlines(y = 0.93,xmin=0,xmax=1600,linestyles='dashdot',lw =1)\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='lower right')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plt.plot(history.history['loss'],color = 'purple')\n",
    "plt.plot(history.history['val_loss'],color='orange')\n",
    "plt.hlines(y = 0,xmin=0,xmax=1600,linestyles='dashed',lw =1)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('bk0.21.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bk_pdct = model.predict(params_test)\n",
    "Bk_pdct.shape, len(Bk_pdct)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = np.array([0.1903934])\n",
    "#k1 = np.array([0.3220935, 1.559453 ])\n",
    "k2byk1 = np.arange(0.50,1.05,0.05) \t\t#======Ratio k2byk1========#\n",
    "cosalpha = np.arange(0.50,1.00,0.01)\t#======cosine of the angle between the k2 and k1 arms =======#\n",
    "k2byk1 = k2byk1.reshape(11,1)\n",
    "k2byk1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bk_ttest = np.zeros(shape=(len(Bk_pdct),11,50))\n",
    "Bk_ppdct = np.zeros(shape=(len(Bk__02_test),11,50))\n",
    "for i in range(len(Bk_pdct)):\n",
    "    Bk_ppdct[i] = Bk_pdct[i].reshape(11,50)\n",
    "    Bk_ttest[i] = Bk__02_test[i].reshape(11,50)\n",
    "\n",
    "Bk_pdct = Bk_ppdct*100.\n",
    "Bk_test = Bk_ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = k2byk1*cosalpha\n",
    "for i in range(len(Bk_pdct)):\n",
    "    for j in range(len(k2byk1)):\n",
    "        for k in range(50):\n",
    "            if cond[j][k] < 0.50:\n",
    "                Bk_pdct[i][j][k] = np.nan\n",
    "                Bk_test[i][j][k] = np.nan\n",
    "\n",
    "Bk_pdct = np.ma.masked_invalid(Bk_pdct)\n",
    "Bk_test = np.ma.masked_invalid(Bk_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(index):\n",
    "    plt.figure(figsize= (14,6))\n",
    "    plt.tick_params(labelsize=10)\n",
    "\n",
    "    plt.suptitle(r'At $k_1$ = {0:f}, $\\zeta$ = {1:.2f}, $Rmfp$= {2:.2f}, $M_h$= {3:.2f}$\\times 10^8 M_\\odot$'.format(k1[0],params_test[index][0] , params_test[index][1] ,1.087*params_test[index][2]))\n",
    "   \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('Bispectrum')\n",
    "    plt.pcolormesh(Bk_test[index],cmap=\"viridis\")\n",
    "    plt.colorbar(label=r\"$\\frac{k_1^3k_2^3Bk}{(2\\pi^2)^2}$\",)\n",
    "    plt.xlabel(r'$cos(\\alpha)$')\n",
    "    plt.ylabel(r'$k_2/k_1$')   \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('ANN prediction')\n",
    "    plt.pcolormesh(Bk_pdct[index],cmap=\"viridis\")\n",
    "    plt.colorbar(label=r\"$\\frac{k_1^3k_2^3Bk}{(2\\pi^2)^2}$\",)\n",
    "    plt.xlabel(r'$cos(\\alpha)$')\n",
    "    plt.ylabel(r'$k_2/k_1$') \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot, index =(0,len(Bk_pdct)-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bk_test[24],params_test[24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative Error & percentage error between actual and predication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re = (Bk_pdct - Bk_test)/Bk_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Bk0.3New.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
