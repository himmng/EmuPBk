{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras as ks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adamax,Adam\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nod = 1058          #===========no. of data points============#\n",
    "k1 = np.array([0.1903934, 0.3220935, 1.559453 ])\n",
    "k2byk1 = np.arange(0.50,1.05,0.05) \t\t#======Ratio k2byk1========#\n",
    "\n",
    "cosalpha = np.arange(0.50,1.00,0.01)\t#======cosine of the angle between the k2 and k1 arms =======#\n",
    "\n",
    "k2byk1 = k2byk1.reshape(11,1)\n",
    "\n",
    "costheta = -cosalpha\n",
    "\n",
    "B_02 = np.loadtxt('bk_norm02')\n",
    "params_02 = np.loadtxt('params02')\n",
    "\n",
    "\n",
    "B_02 = B_02/100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.loadtxt('index')\n",
    "index = np.zeros(len(ind),dtype = int)\n",
    "for i in range(len(ind)):\n",
    "    index[i] = ind[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_test = B_02[index]\n",
    "B_train = np.delete(B_02,index,axis=0)\n",
    "\n",
    "p_test = params_02[index]\n",
    "p_train = np.delete(params_02,index,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_mode='uniform'\n",
    "class myCallback(ks.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>=0.98):\n",
    "            print(\"\\nReached 80% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "callbacks = myCallback()\n",
    "model = Sequential()\n",
    "model.add(Dense(80, input_shape=[3,], activation='elu',kernel_initializer=init_mode,))\n",
    "model.add(Dense(320,activation='elu',kernel_initializer=init_mode))\n",
    "model.add(Dense(460,activation='elu',kernel_initializer=init_mode))\n",
    "model.add(Dense(560,activation='elu',kernel_initializer=init_mode))\n",
    "model.add(Dense(260,activation='elu',kernel_initializer=init_mode))\n",
    "model.add(Dense(100,activation='elu',kernel_initializer=init_mode))\n",
    "model.add(Dense(320,activation='elu',kernel_initializer=init_mode))\n",
    "model.add(Dense(400,activation='elu',kernel_initializer=init_mode))\n",
    "    #model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(550, activation='linear'))\n",
    "    # Compile model\n",
    "optimizer = Adamax(lr=0.0001, beta_1=0.2, beta_2=0.088)\n",
    "model.compile(loss='mse', optimizer=Adam, metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 320)               25920     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 460)               147660    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 560)               258160    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 260)               145860    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               26100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 320)               32320     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 400)               128400    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 550)               220550    \n",
      "=================================================================\n",
      "Total params: 985,290\n",
      "Trainable params: 985,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 40 samples\n",
      "Epoch 1/2000\n",
      "1000/1000 [==============================] - 1s 633us/step - loss: 2.2207 - accuracy: 0.6460 - val_loss: 1.7075 - val_accuracy: 0.7750\n",
      "Epoch 2/2000\n",
      "1000/1000 [==============================] - 0s 451us/step - loss: 1.7254 - accuracy: 0.7340 - val_loss: 1.5954 - val_accuracy: 0.8000\n",
      "Epoch 3/2000\n",
      "1000/1000 [==============================] - 0s 449us/step - loss: 1.6093 - accuracy: 0.7360 - val_loss: 1.6863 - val_accuracy: 0.7500\n",
      "Epoch 4/2000\n",
      "1000/1000 [==============================] - 0s 469us/step - loss: 1.2859 - accuracy: 0.7210 - val_loss: 1.3657 - val_accuracy: 0.7000\n",
      "Epoch 5/2000\n",
      "1000/1000 [==============================] - 0s 465us/step - loss: 0.8618 - accuracy: 0.6940 - val_loss: 1.3007 - val_accuracy: 0.7250\n",
      "Epoch 6/2000\n",
      "1000/1000 [==============================] - 0s 484us/step - loss: 0.7914 - accuracy: 0.7060 - val_loss: 0.9618 - val_accuracy: 0.7250\n",
      "Epoch 7/2000\n",
      "1000/1000 [==============================] - 0s 462us/step - loss: 0.7425 - accuracy: 0.7170 - val_loss: 1.1445 - val_accuracy: 0.7250\n",
      "Epoch 8/2000\n",
      "1000/1000 [==============================] - 0s 487us/step - loss: 0.6865 - accuracy: 0.7140 - val_loss: 0.9527 - val_accuracy: 0.7000\n",
      "Epoch 9/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.6532 - accuracy: 0.7240 - val_loss: 0.9081 - val_accuracy: 0.7250\n",
      "Epoch 10/2000\n",
      "1000/1000 [==============================] - 0s 489us/step - loss: 0.5879 - accuracy: 0.7240 - val_loss: 0.9107 - val_accuracy: 0.7250\n",
      "Epoch 11/2000\n",
      "1000/1000 [==============================] - 0s 487us/step - loss: 0.6232 - accuracy: 0.7230 - val_loss: 0.9529 - val_accuracy: 0.7250\n",
      "Epoch 12/2000\n",
      "1000/1000 [==============================] - 0s 474us/step - loss: 0.5711 - accuracy: 0.7240 - val_loss: 0.9080 - val_accuracy: 0.7250\n",
      "Epoch 13/2000\n",
      "1000/1000 [==============================] - 0s 461us/step - loss: 0.5321 - accuracy: 0.7370 - val_loss: 0.8874 - val_accuracy: 0.7500\n",
      "Epoch 14/2000\n",
      "1000/1000 [==============================] - 0s 454us/step - loss: 0.5092 - accuracy: 0.7470 - val_loss: 1.1304 - val_accuracy: 0.7250\n",
      "Epoch 15/2000\n",
      "1000/1000 [==============================] - 0s 465us/step - loss: 0.5175 - accuracy: 0.7490 - val_loss: 0.8586 - val_accuracy: 0.7500\n",
      "Epoch 16/2000\n",
      "1000/1000 [==============================] - 0s 461us/step - loss: 0.4815 - accuracy: 0.7680 - val_loss: 0.8160 - val_accuracy: 0.8250\n",
      "Epoch 17/2000\n",
      "1000/1000 [==============================] - 0s 443us/step - loss: 0.4622 - accuracy: 0.7650 - val_loss: 0.9108 - val_accuracy: 0.7750\n",
      "Epoch 18/2000\n",
      "1000/1000 [==============================] - 0s 440us/step - loss: 0.4955 - accuracy: 0.7900 - val_loss: 0.8542 - val_accuracy: 0.8250\n",
      "Epoch 19/2000\n",
      "1000/1000 [==============================] - 0s 468us/step - loss: 0.4331 - accuracy: 0.8020 - val_loss: 0.9563 - val_accuracy: 0.7750\n",
      "Epoch 20/2000\n",
      "1000/1000 [==============================] - 0s 463us/step - loss: 0.4584 - accuracy: 0.7860 - val_loss: 0.8609 - val_accuracy: 0.8250\n",
      "Epoch 21/2000\n",
      "1000/1000 [==============================] - 0s 483us/step - loss: 0.5053 - accuracy: 0.7920 - val_loss: 0.9075 - val_accuracy: 0.7750\n",
      "Epoch 22/2000\n",
      "1000/1000 [==============================] - 0s 467us/step - loss: 0.3920 - accuracy: 0.8070 - val_loss: 0.8663 - val_accuracy: 0.8250\n",
      "Epoch 23/2000\n",
      "1000/1000 [==============================] - 0s 450us/step - loss: 0.4262 - accuracy: 0.8110 - val_loss: 0.9866 - val_accuracy: 0.7750\n",
      "Epoch 24/2000\n",
      "1000/1000 [==============================] - 0s 474us/step - loss: 0.3966 - accuracy: 0.8200 - val_loss: 0.8864 - val_accuracy: 0.7500\n",
      "Epoch 25/2000\n",
      "1000/1000 [==============================] - 0s 449us/step - loss: 0.3974 - accuracy: 0.8280 - val_loss: 0.9152 - val_accuracy: 0.8250\n",
      "Epoch 26/2000\n",
      "1000/1000 [==============================] - 0s 453us/step - loss: 0.4209 - accuracy: 0.8270 - val_loss: 0.9072 - val_accuracy: 0.8250\n",
      "Epoch 27/2000\n",
      "1000/1000 [==============================] - 0s 448us/step - loss: 0.3472 - accuracy: 0.8270 - val_loss: 0.8220 - val_accuracy: 0.8250\n",
      "Epoch 28/2000\n",
      "1000/1000 [==============================] - 0s 442us/step - loss: 0.3483 - accuracy: 0.8310 - val_loss: 0.6061 - val_accuracy: 0.8750\n",
      "Epoch 29/2000\n",
      "1000/1000 [==============================] - 0s 442us/step - loss: 0.3240 - accuracy: 0.8420 - val_loss: 0.9331 - val_accuracy: 0.8250\n",
      "Epoch 30/2000\n",
      "1000/1000 [==============================] - 0s 438us/step - loss: 0.4015 - accuracy: 0.8310 - val_loss: 0.5486 - val_accuracy: 0.8250\n",
      "Epoch 31/2000\n",
      "1000/1000 [==============================] - 0s 453us/step - loss: 0.3170 - accuracy: 0.8380 - val_loss: 0.5168 - val_accuracy: 0.8500\n",
      "Epoch 32/2000\n",
      "1000/1000 [==============================] - 0s 454us/step - loss: 0.3215 - accuracy: 0.8370 - val_loss: 0.6862 - val_accuracy: 0.8250\n",
      "Epoch 33/2000\n",
      "1000/1000 [==============================] - 0s 445us/step - loss: 0.3522 - accuracy: 0.8340 - val_loss: 0.5083 - val_accuracy: 0.8250\n",
      "Epoch 34/2000\n",
      "1000/1000 [==============================] - 0s 441us/step - loss: 0.3295 - accuracy: 0.8320 - val_loss: 0.5123 - val_accuracy: 0.8250\n",
      "Epoch 35/2000\n",
      "1000/1000 [==============================] - 0s 450us/step - loss: 0.5645 - accuracy: 0.8360 - val_loss: 0.5668 - val_accuracy: 0.8500\n",
      "Epoch 36/2000\n",
      "1000/1000 [==============================] - 0s 494us/step - loss: 0.3638 - accuracy: 0.8360 - val_loss: 0.9340 - val_accuracy: 0.8500\n",
      "Epoch 37/2000\n",
      "1000/1000 [==============================] - 0s 481us/step - loss: 0.3567 - accuracy: 0.8450 - val_loss: 1.0468 - val_accuracy: 0.8250\n",
      "Epoch 38/2000\n",
      "1000/1000 [==============================] - 0s 438us/step - loss: 0.5802 - accuracy: 0.8220 - val_loss: 0.6238 - val_accuracy: 0.8250\n",
      "Epoch 39/2000\n",
      "1000/1000 [==============================] - 0s 476us/step - loss: 0.3326 - accuracy: 0.8350 - val_loss: 0.5107 - val_accuracy: 0.8250\n",
      "Epoch 40/2000\n",
      "1000/1000 [==============================] - 0s 445us/step - loss: 0.3307 - accuracy: 0.8440 - val_loss: 1.0344 - val_accuracy: 0.8250\n",
      "Epoch 41/2000\n",
      "1000/1000 [==============================] - 0s 454us/step - loss: 0.5020 - accuracy: 0.8360 - val_loss: 0.9003 - val_accuracy: 0.8250\n",
      "Epoch 42/2000\n",
      "1000/1000 [==============================] - 0s 449us/step - loss: 0.3427 - accuracy: 0.8430 - val_loss: 0.8450 - val_accuracy: 0.8250\n",
      "Epoch 43/2000\n",
      "1000/1000 [==============================] - 0s 463us/step - loss: 0.3050 - accuracy: 0.8480 - val_loss: 0.7295 - val_accuracy: 0.8250\n",
      "Epoch 44/2000\n",
      "1000/1000 [==============================] - 0s 453us/step - loss: 0.3778 - accuracy: 0.8430 - val_loss: 0.5197 - val_accuracy: 0.8250\n",
      "Epoch 45/2000\n",
      "1000/1000 [==============================] - 0s 449us/step - loss: 0.2652 - accuracy: 0.8300 - val_loss: 0.4432 - val_accuracy: 0.8750\n",
      "Epoch 46/2000\n",
      "1000/1000 [==============================] - 0s 464us/step - loss: 0.2788 - accuracy: 0.8410 - val_loss: 0.5314 - val_accuracy: 0.8500\n",
      "Epoch 47/2000\n",
      "1000/1000 [==============================] - 0s 490us/step - loss: 0.2543 - accuracy: 0.8370 - val_loss: 0.5247 - val_accuracy: 0.8500\n",
      "Epoch 48/2000\n",
      "1000/1000 [==============================] - 0s 463us/step - loss: 0.2828 - accuracy: 0.8300 - val_loss: 0.4133 - val_accuracy: 0.8500\n",
      "Epoch 49/2000\n",
      "1000/1000 [==============================] - 0s 468us/step - loss: 0.3275 - accuracy: 0.8400 - val_loss: 0.6916 - val_accuracy: 0.8250\n",
      "Epoch 50/2000\n",
      "1000/1000 [==============================] - 0s 459us/step - loss: 0.3253 - accuracy: 0.8370 - val_loss: 0.4939 - val_accuracy: 0.8000\n",
      "Epoch 51/2000\n",
      "1000/1000 [==============================] - 0s 454us/step - loss: 0.2366 - accuracy: 0.8360 - val_loss: 0.4407 - val_accuracy: 0.8500\n",
      "Epoch 52/2000\n",
      "1000/1000 [==============================] - 0s 452us/step - loss: 0.2426 - accuracy: 0.8430 - val_loss: 0.5820 - val_accuracy: 0.8500\n",
      "Epoch 53/2000\n",
      "1000/1000 [==============================] - 0s 443us/step - loss: 0.2563 - accuracy: 0.8380 - val_loss: 0.4481 - val_accuracy: 0.8500\n",
      "Epoch 54/2000\n",
      "1000/1000 [==============================] - 0s 444us/step - loss: 0.2660 - accuracy: 0.8480 - val_loss: 0.4662 - val_accuracy: 0.8000\n",
      "Epoch 55/2000\n",
      "1000/1000 [==============================] - 0s 444us/step - loss: 0.2513 - accuracy: 0.8380 - val_loss: 0.3245 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/2000\n",
      "1000/1000 [==============================] - 0s 456us/step - loss: 0.2428 - accuracy: 0.8380 - val_loss: 0.3414 - val_accuracy: 0.8500\n",
      "Epoch 57/2000\n",
      "1000/1000 [==============================] - 0s 442us/step - loss: 0.2404 - accuracy: 0.8530 - val_loss: 0.4005 - val_accuracy: 0.8500\n",
      "Epoch 58/2000\n",
      "1000/1000 [==============================] - 0s 440us/step - loss: 0.2527 - accuracy: 0.8480 - val_loss: 0.4011 - val_accuracy: 0.8500\n",
      "Epoch 59/2000\n",
      "1000/1000 [==============================] - 0s 440us/step - loss: 0.2414 - accuracy: 0.8580 - val_loss: 1.0169 - val_accuracy: 0.8250\n",
      "Epoch 60/2000\n",
      "1000/1000 [==============================] - 0s 445us/step - loss: 0.2251 - accuracy: 0.8580 - val_loss: 0.3430 - val_accuracy: 0.8500\n",
      "Epoch 61/2000\n",
      "1000/1000 [==============================] - 0s 437us/step - loss: 0.2053 - accuracy: 0.8530 - val_loss: 0.3717 - val_accuracy: 0.8500\n",
      "Epoch 62/2000\n",
      "1000/1000 [==============================] - 0s 434us/step - loss: 0.2060 - accuracy: 0.8540 - val_loss: 0.3451 - val_accuracy: 0.8250\n",
      "Epoch 63/2000\n",
      "1000/1000 [==============================] - 0s 432us/step - loss: 0.2368 - accuracy: 0.8510 - val_loss: 0.3994 - val_accuracy: 0.8000\n",
      "Epoch 64/2000\n",
      "1000/1000 [==============================] - 0s 439us/step - loss: 0.2334 - accuracy: 0.8350 - val_loss: 0.3686 - val_accuracy: 0.8000\n",
      "Epoch 65/2000\n",
      "1000/1000 [==============================] - 0s 442us/step - loss: 0.1905 - accuracy: 0.8480 - val_loss: 0.3311 - val_accuracy: 0.8750\n",
      "Epoch 66/2000\n",
      "1000/1000 [==============================] - 0s 434us/step - loss: 0.2735 - accuracy: 0.8420 - val_loss: 0.2786 - val_accuracy: 0.8750\n",
      "Epoch 67/2000\n",
      "1000/1000 [==============================] - 0s 444us/step - loss: 0.2517 - accuracy: 0.8330 - val_loss: 0.2906 - val_accuracy: 0.8250\n",
      "Epoch 68/2000\n",
      "1000/1000 [==============================] - 0s 451us/step - loss: 0.3122 - accuracy: 0.8250 - val_loss: 0.2862 - val_accuracy: 0.8750\n",
      "Epoch 69/2000\n",
      "1000/1000 [==============================] - 0s 494us/step - loss: 0.2287 - accuracy: 0.8320 - val_loss: 0.2150 - val_accuracy: 0.8000\n",
      "Epoch 70/2000\n",
      "1000/1000 [==============================] - 1s 523us/step - loss: 0.1890 - accuracy: 0.8610 - val_loss: 0.4328 - val_accuracy: 0.8500\n",
      "Epoch 71/2000\n",
      "1000/1000 [==============================] - 1s 526us/step - loss: 0.2357 - accuracy: 0.8400 - val_loss: 0.4758 - val_accuracy: 0.8500\n",
      "Epoch 72/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.2306 - accuracy: 0.8540 - val_loss: 0.3459 - val_accuracy: 0.9000\n",
      "Epoch 73/2000\n",
      "1000/1000 [==============================] - 1s 506us/step - loss: 0.1909 - accuracy: 0.8400 - val_loss: 0.4095 - val_accuracy: 0.8500\n",
      "Epoch 74/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.2662 - accuracy: 0.8320 - val_loss: 0.6699 - val_accuracy: 0.7750\n",
      "Epoch 75/2000\n",
      "1000/1000 [==============================] - 1s 529us/step - loss: 0.2657 - accuracy: 0.8480 - val_loss: 0.2443 - val_accuracy: 0.8250\n",
      "Epoch 76/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.2093 - accuracy: 0.8390 - val_loss: 0.3230 - val_accuracy: 0.8500\n",
      "Epoch 77/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.2123 - accuracy: 0.8550 - val_loss: 0.2555 - val_accuracy: 0.8250\n",
      "Epoch 78/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.2106 - accuracy: 0.8460 - val_loss: 0.3451 - val_accuracy: 0.8250\n",
      "Epoch 79/2000\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 0.1724 - accuracy: 0.8410 - val_loss: 0.8382 - val_accuracy: 0.8500\n",
      "Epoch 80/2000\n",
      "1000/1000 [==============================] - 1s 523us/step - loss: 0.2008 - accuracy: 0.8430 - val_loss: 0.1717 - val_accuracy: 0.8750\n",
      "Epoch 81/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.1909 - accuracy: 0.8420 - val_loss: 0.2008 - val_accuracy: 0.8000\n",
      "Epoch 82/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.1908 - accuracy: 0.8410 - val_loss: 0.1834 - val_accuracy: 0.7750\n",
      "Epoch 83/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.1560 - accuracy: 0.8410 - val_loss: 0.1416 - val_accuracy: 0.8500\n",
      "Epoch 84/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.1931 - accuracy: 0.8470 - val_loss: 0.1415 - val_accuracy: 0.8250\n",
      "Epoch 85/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.1598 - accuracy: 0.8580 - val_loss: 0.3554 - val_accuracy: 0.8500\n",
      "Epoch 86/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.1558 - accuracy: 0.8620 - val_loss: 0.3167 - val_accuracy: 0.8500\n",
      "Epoch 87/2000\n",
      "1000/1000 [==============================] - 1s 533us/step - loss: 0.2177 - accuracy: 0.8530 - val_loss: 0.2296 - val_accuracy: 0.8250\n",
      "Epoch 88/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.1456 - accuracy: 0.8560 - val_loss: 0.2574 - val_accuracy: 0.8500\n",
      "Epoch 89/2000\n",
      "1000/1000 [==============================] - 1s 533us/step - loss: 0.1467 - accuracy: 0.8430 - val_loss: 0.2021 - val_accuracy: 0.8250\n",
      "Epoch 90/2000\n",
      "1000/1000 [==============================] - 1s 505us/step - loss: 0.1306 - accuracy: 0.8460 - val_loss: 0.4056 - val_accuracy: 0.8250\n",
      "Epoch 91/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.1521 - accuracy: 0.8650 - val_loss: 0.1685 - val_accuracy: 0.8250\n",
      "Epoch 92/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.1243 - accuracy: 0.8540 - val_loss: 0.3243 - val_accuracy: 0.8000\n",
      "Epoch 93/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.1366 - accuracy: 0.8410 - val_loss: 0.2208 - val_accuracy: 0.8500\n",
      "Epoch 94/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.1379 - accuracy: 0.8520 - val_loss: 0.1644 - val_accuracy: 0.8000\n",
      "Epoch 95/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.1881 - accuracy: 0.8490 - val_loss: 0.1324 - val_accuracy: 0.8500\n",
      "Epoch 96/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.1613 - accuracy: 0.8580 - val_loss: 0.1443 - val_accuracy: 0.8500\n",
      "Epoch 97/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.1326 - accuracy: 0.8540 - val_loss: 0.3132 - val_accuracy: 0.7750\n",
      "Epoch 98/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.1804 - accuracy: 0.8520 - val_loss: 0.1823 - val_accuracy: 0.8250\n",
      "Epoch 99/2000\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 0.1362 - accuracy: 0.8560 - val_loss: 0.1972 - val_accuracy: 0.8250\n",
      "Epoch 100/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.1549 - accuracy: 0.8630 - val_loss: 0.4021 - val_accuracy: 0.8500\n",
      "Epoch 101/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.1275 - accuracy: 0.8580 - val_loss: 0.2034 - val_accuracy: 0.8500\n",
      "Epoch 102/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.1186 - accuracy: 0.8560 - val_loss: 0.2141 - val_accuracy: 0.8750\n",
      "Epoch 103/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.1647 - accuracy: 0.8480 - val_loss: 0.4023 - val_accuracy: 0.8750\n",
      "Epoch 104/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.1235 - accuracy: 0.8600 - val_loss: 0.1237 - val_accuracy: 0.8500\n",
      "Epoch 105/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.1434 - accuracy: 0.8570 - val_loss: 0.1395 - val_accuracy: 0.7750\n",
      "Epoch 106/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.1279 - accuracy: 0.8630 - val_loss: 0.1829 - val_accuracy: 0.9000\n",
      "Epoch 107/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.1222 - accuracy: 0.8490 - val_loss: 0.1489 - val_accuracy: 0.9250\n",
      "Epoch 108/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.1338 - accuracy: 0.8570 - val_loss: 0.1728 - val_accuracy: 0.8250\n",
      "Epoch 109/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.1132 - accuracy: 0.8540 - val_loss: 0.1450 - val_accuracy: 0.8250\n",
      "Epoch 110/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.1465 - accuracy: 0.8590 - val_loss: 0.1525 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.1247 - accuracy: 0.8560 - val_loss: 0.2025 - val_accuracy: 0.8000\n",
      "Epoch 112/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.1306 - accuracy: 0.8590 - val_loss: 0.1153 - val_accuracy: 0.9000\n",
      "Epoch 113/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.1635 - accuracy: 0.8500 - val_loss: 0.2160 - val_accuracy: 0.8750\n",
      "Epoch 114/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.1108 - accuracy: 0.8600 - val_loss: 0.2446 - val_accuracy: 0.8000\n",
      "Epoch 115/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.1332 - accuracy: 0.8590 - val_loss: 0.2043 - val_accuracy: 0.8000\n",
      "Epoch 116/2000\n",
      "1000/1000 [==============================] - 1s 530us/step - loss: 0.1667 - accuracy: 0.8690 - val_loss: 0.1421 - val_accuracy: 0.8500\n",
      "Epoch 117/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0929 - accuracy: 0.8710 - val_loss: 0.1641 - val_accuracy: 0.8500\n",
      "Epoch 118/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.1226 - accuracy: 0.8600 - val_loss: 0.1724 - val_accuracy: 0.8000\n",
      "Epoch 119/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.1011 - accuracy: 0.8710 - val_loss: 0.2415 - val_accuracy: 0.8000\n",
      "Epoch 120/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.1303 - accuracy: 0.8550 - val_loss: 0.2509 - val_accuracy: 0.8750\n",
      "Epoch 121/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.1504 - accuracy: 0.8660 - val_loss: 0.1997 - val_accuracy: 0.9000\n",
      "Epoch 122/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.1594 - accuracy: 0.8800 - val_loss: 0.2559 - val_accuracy: 0.8750\n",
      "Epoch 123/2000\n",
      "1000/1000 [==============================] - 1s 569us/step - loss: 0.1412 - accuracy: 0.8630 - val_loss: 0.1438 - val_accuracy: 0.8000\n",
      "Epoch 124/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.1271 - accuracy: 0.8650 - val_loss: 0.1165 - val_accuracy: 0.8250\n",
      "Epoch 125/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.1091 - accuracy: 0.8720 - val_loss: 0.1304 - val_accuracy: 0.9250\n",
      "Epoch 126/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.1341 - accuracy: 0.8700 - val_loss: 0.2548 - val_accuracy: 0.8250\n",
      "Epoch 127/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.1295 - accuracy: 0.8800 - val_loss: 0.0960 - val_accuracy: 0.8750\n",
      "Epoch 128/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.1279 - accuracy: 0.8730 - val_loss: 0.0960 - val_accuracy: 0.8750\n",
      "Epoch 129/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.1131 - accuracy: 0.8690 - val_loss: 0.4327 - val_accuracy: 0.8250\n",
      "Epoch 130/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0947 - accuracy: 0.8700 - val_loss: 0.0878 - val_accuracy: 0.8500\n",
      "Epoch 131/2000\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 0.0877 - accuracy: 0.8710 - val_loss: 0.1770 - val_accuracy: 0.9000\n",
      "Epoch 132/2000\n",
      "1000/1000 [==============================] - 1s 505us/step - loss: 0.0963 - accuracy: 0.8680 - val_loss: 0.2105 - val_accuracy: 0.8250\n",
      "Epoch 133/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.1286 - accuracy: 0.8740 - val_loss: 0.1629 - val_accuracy: 0.8250\n",
      "Epoch 134/2000\n",
      "1000/1000 [==============================] - 1s 501us/step - loss: 0.0827 - accuracy: 0.8750 - val_loss: 0.1095 - val_accuracy: 0.8500\n",
      "Epoch 135/2000\n",
      "1000/1000 [==============================] - 1s 507us/step - loss: 0.1233 - accuracy: 0.8680 - val_loss: 0.1365 - val_accuracy: 0.8500\n",
      "Epoch 136/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.1026 - accuracy: 0.8660 - val_loss: 0.1589 - val_accuracy: 0.8750\n",
      "Epoch 137/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.2346 - accuracy: 0.8780 - val_loss: 0.1327 - val_accuracy: 0.8000\n",
      "Epoch 138/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.1679 - accuracy: 0.8640 - val_loss: 0.3188 - val_accuracy: 0.9000\n",
      "Epoch 139/2000\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 0.1651 - accuracy: 0.8480 - val_loss: 0.1163 - val_accuracy: 0.8500\n",
      "Epoch 140/2000\n",
      "1000/1000 [==============================] - 1s 529us/step - loss: 0.1130 - accuracy: 0.8620 - val_loss: 0.1944 - val_accuracy: 0.8500\n",
      "Epoch 141/2000\n",
      "1000/1000 [==============================] - 1s 530us/step - loss: 0.1178 - accuracy: 0.8650 - val_loss: 0.1302 - val_accuracy: 0.8500\n",
      "Epoch 142/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.1369 - accuracy: 0.8760 - val_loss: 0.0994 - val_accuracy: 0.9000\n",
      "Epoch 143/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.1450 - accuracy: 0.8800 - val_loss: 0.1382 - val_accuracy: 0.8500\n",
      "Epoch 144/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.0764 - accuracy: 0.8730 - val_loss: 0.0961 - val_accuracy: 0.8750\n",
      "Epoch 145/2000\n",
      "1000/1000 [==============================] - 1s 525us/step - loss: 0.0915 - accuracy: 0.8930 - val_loss: 0.1193 - val_accuracy: 0.8750\n",
      "Epoch 146/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.1044 - accuracy: 0.8880 - val_loss: 0.1181 - val_accuracy: 0.8500\n",
      "Epoch 147/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0838 - accuracy: 0.8880 - val_loss: 0.1107 - val_accuracy: 0.8500\n",
      "Epoch 148/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.1227 - accuracy: 0.8770 - val_loss: 0.0705 - val_accuracy: 0.8500\n",
      "Epoch 149/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.1126 - accuracy: 0.8700 - val_loss: 0.1223 - val_accuracy: 0.7750\n",
      "Epoch 150/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0749 - accuracy: 0.8750 - val_loss: 0.1425 - val_accuracy: 0.8500\n",
      "Epoch 151/2000\n",
      "1000/1000 [==============================] - 1s 502us/step - loss: 0.2382 - accuracy: 0.8620 - val_loss: 0.1318 - val_accuracy: 0.8750\n",
      "Epoch 152/2000\n",
      "1000/1000 [==============================] - 1s 504us/step - loss: 0.1110 - accuracy: 0.8820 - val_loss: 0.1496 - val_accuracy: 0.8500\n",
      "Epoch 153/2000\n",
      "1000/1000 [==============================] - 1s 505us/step - loss: 0.0916 - accuracy: 0.8710 - val_loss: 0.2461 - val_accuracy: 0.8500\n",
      "Epoch 154/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0803 - accuracy: 0.8800 - val_loss: 0.0673 - val_accuracy: 0.8250\n",
      "Epoch 155/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.1027 - accuracy: 0.8850 - val_loss: 0.1405 - val_accuracy: 0.8500\n",
      "Epoch 156/2000\n",
      "1000/1000 [==============================] - 1s 563us/step - loss: 0.1133 - accuracy: 0.8870 - val_loss: 0.2113 - val_accuracy: 0.8250\n",
      "Epoch 157/2000\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.1552 - accuracy: 0.8800 - val_loss: 0.0898 - val_accuracy: 0.8500\n",
      "Epoch 158/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.1373 - accuracy: 0.8660 - val_loss: 0.1279 - val_accuracy: 0.8500\n",
      "Epoch 159/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0819 - accuracy: 0.8740 - val_loss: 0.1152 - val_accuracy: 0.8500\n",
      "Epoch 160/2000\n",
      "1000/1000 [==============================] - 1s 525us/step - loss: 0.0866 - accuracy: 0.8830 - val_loss: 0.2548 - val_accuracy: 0.8000\n",
      "Epoch 161/2000\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 0.1405 - accuracy: 0.8630 - val_loss: 0.0831 - val_accuracy: 0.8750\n",
      "Epoch 162/2000\n",
      "1000/1000 [==============================] - 1s 531us/step - loss: 0.0862 - accuracy: 0.8880 - val_loss: 0.0839 - val_accuracy: 0.8250\n",
      "Epoch 163/2000\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 0.1015 - accuracy: 0.8630 - val_loss: 0.1128 - val_accuracy: 0.9250\n",
      "Epoch 164/2000\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 0.1877 - accuracy: 0.8890 - val_loss: 0.0840 - val_accuracy: 0.8750\n",
      "Epoch 165/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 543us/step - loss: 0.0957 - accuracy: 0.8760 - val_loss: 0.1127 - val_accuracy: 0.8500\n",
      "Epoch 166/2000\n",
      "1000/1000 [==============================] - 1s 507us/step - loss: 0.1685 - accuracy: 0.8790 - val_loss: 0.1611 - val_accuracy: 0.8250\n",
      "Epoch 167/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0779 - accuracy: 0.8740 - val_loss: 0.1234 - val_accuracy: 0.9000\n",
      "Epoch 168/2000\n",
      "1000/1000 [==============================] - 1s 502us/step - loss: 0.0686 - accuracy: 0.8940 - val_loss: 0.1190 - val_accuracy: 0.8250\n",
      "Epoch 169/2000\n",
      "1000/1000 [==============================] - 1s 503us/step - loss: 0.0644 - accuracy: 0.8990 - val_loss: 0.0869 - val_accuracy: 0.8500\n",
      "Epoch 170/2000\n",
      "1000/1000 [==============================] - 1s 504us/step - loss: 0.0959 - accuracy: 0.8790 - val_loss: 0.0722 - val_accuracy: 0.8750\n",
      "Epoch 171/2000\n",
      "1000/1000 [==============================] - 1s 504us/step - loss: 0.0744 - accuracy: 0.8880 - val_loss: 0.0768 - val_accuracy: 0.8500\n",
      "Epoch 172/2000\n",
      "1000/1000 [==============================] - 1s 506us/step - loss: 0.1183 - accuracy: 0.8760 - val_loss: 0.0957 - val_accuracy: 0.8750\n",
      "Epoch 173/2000\n",
      "1000/1000 [==============================] - 1s 506us/step - loss: 0.0968 - accuracy: 0.8620 - val_loss: 0.1228 - val_accuracy: 0.8750\n",
      "Epoch 174/2000\n",
      "1000/1000 [==============================] - 1s 506us/step - loss: 0.0975 - accuracy: 0.8920 - val_loss: 0.2292 - val_accuracy: 0.8500\n",
      "Epoch 175/2000\n",
      "1000/1000 [==============================] - 1s 502us/step - loss: 0.0770 - accuracy: 0.8830 - val_loss: 0.0976 - val_accuracy: 0.8750\n",
      "Epoch 176/2000\n",
      "1000/1000 [==============================] - 1s 534us/step - loss: 0.0657 - accuracy: 0.8820 - val_loss: 0.1114 - val_accuracy: 0.8000\n",
      "Epoch 177/2000\n",
      "1000/1000 [==============================] - 1s 581us/step - loss: 0.0629 - accuracy: 0.8850 - val_loss: 0.1078 - val_accuracy: 0.8250\n",
      "Epoch 178/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.1117 - accuracy: 0.8880 - val_loss: 0.1695 - val_accuracy: 0.9250\n",
      "Epoch 179/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0683 - accuracy: 0.8770 - val_loss: 0.0788 - val_accuracy: 0.9000\n",
      "Epoch 180/2000\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 0.0687 - accuracy: 0.8950 - val_loss: 0.1116 - val_accuracy: 0.8500\n",
      "Epoch 181/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0794 - accuracy: 0.8830 - val_loss: 0.0804 - val_accuracy: 0.8500\n",
      "Epoch 182/2000\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0770 - accuracy: 0.8850 - val_loss: 0.0811 - val_accuracy: 0.9250\n",
      "Epoch 183/2000\n",
      "1000/1000 [==============================] - 1s 544us/step - loss: 0.0611 - accuracy: 0.8870 - val_loss: 0.1186 - val_accuracy: 0.8750\n",
      "Epoch 184/2000\n",
      "1000/1000 [==============================] - 1s 572us/step - loss: 0.0883 - accuracy: 0.8930 - val_loss: 0.0881 - val_accuracy: 0.9000\n",
      "Epoch 185/2000\n",
      "1000/1000 [==============================] - 1s 556us/step - loss: 0.0570 - accuracy: 0.8910 - val_loss: 0.1402 - val_accuracy: 0.8500\n",
      "Epoch 186/2000\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 0.1006 - accuracy: 0.8960 - val_loss: 0.1097 - val_accuracy: 0.9000\n",
      "Epoch 187/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0608 - accuracy: 0.8970 - val_loss: 0.0966 - val_accuracy: 0.8500\n",
      "Epoch 188/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0692 - accuracy: 0.8940 - val_loss: 0.0837 - val_accuracy: 0.9000\n",
      "Epoch 189/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0691 - accuracy: 0.8880 - val_loss: 0.1006 - val_accuracy: 0.8000\n",
      "Epoch 190/2000\n",
      "1000/1000 [==============================] - 1s 538us/step - loss: 0.0988 - accuracy: 0.8920 - val_loss: 0.1172 - val_accuracy: 0.8250\n",
      "Epoch 191/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.1309 - accuracy: 0.8850 - val_loss: 0.1563 - val_accuracy: 0.9000\n",
      "Epoch 192/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0648 - accuracy: 0.8840 - val_loss: 0.0970 - val_accuracy: 0.9000\n",
      "Epoch 193/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0801 - accuracy: 0.8910 - val_loss: 0.1092 - val_accuracy: 0.9000\n",
      "Epoch 194/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.1087 - accuracy: 0.8740 - val_loss: 0.0794 - val_accuracy: 0.9000\n",
      "Epoch 195/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0779 - accuracy: 0.8860 - val_loss: 0.0809 - val_accuracy: 0.8750\n",
      "Epoch 196/2000\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.0530 - accuracy: 0.8970 - val_loss: 0.0790 - val_accuracy: 0.8500\n",
      "Epoch 197/2000\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 0.0789 - accuracy: 0.8950 - val_loss: 0.0739 - val_accuracy: 0.9250\n",
      "Epoch 198/2000\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.0956 - accuracy: 0.8930 - val_loss: 0.0813 - val_accuracy: 0.8750\n",
      "Epoch 199/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0760 - accuracy: 0.8940 - val_loss: 0.0949 - val_accuracy: 0.8250\n",
      "Epoch 200/2000\n",
      "1000/1000 [==============================] - 1s 525us/step - loss: 0.1229 - accuracy: 0.8910 - val_loss: 0.2168 - val_accuracy: 0.8750\n",
      "Epoch 201/2000\n",
      "1000/1000 [==============================] - 1s 526us/step - loss: 0.0602 - accuracy: 0.8910 - val_loss: 0.1826 - val_accuracy: 0.8750\n",
      "Epoch 202/2000\n",
      "1000/1000 [==============================] - 1s 525us/step - loss: 0.0965 - accuracy: 0.8970 - val_loss: 0.0915 - val_accuracy: 0.8750\n",
      "Epoch 203/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0828 - accuracy: 0.8870 - val_loss: 0.0773 - val_accuracy: 0.9000\n",
      "Epoch 204/2000\n",
      "1000/1000 [==============================] - 1s 529us/step - loss: 0.1396 - accuracy: 0.8810 - val_loss: 0.1934 - val_accuracy: 0.8750\n",
      "Epoch 205/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0677 - accuracy: 0.8940 - val_loss: 0.0696 - val_accuracy: 0.8750\n",
      "Epoch 206/2000\n",
      "1000/1000 [==============================] - 1s 544us/step - loss: 0.0765 - accuracy: 0.8920 - val_loss: 0.1674 - val_accuracy: 0.8500\n",
      "Epoch 207/2000\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 0.0721 - accuracy: 0.8930 - val_loss: 0.0695 - val_accuracy: 0.8750\n",
      "Epoch 208/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0766 - accuracy: 0.8990 - val_loss: 0.0839 - val_accuracy: 0.8500\n",
      "Epoch 209/2000\n",
      "1000/1000 [==============================] - 1s 538us/step - loss: 0.0799 - accuracy: 0.8980 - val_loss: 0.0659 - val_accuracy: 0.8750\n",
      "Epoch 210/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0673 - accuracy: 0.8790 - val_loss: 0.1083 - val_accuracy: 0.8500\n",
      "Epoch 211/2000\n",
      "1000/1000 [==============================] - 1s 523us/step - loss: 0.0731 - accuracy: 0.8980 - val_loss: 0.1246 - val_accuracy: 0.9000\n",
      "Epoch 212/2000\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.0956 - accuracy: 0.8770 - val_loss: 0.0990 - val_accuracy: 0.9250\n",
      "Epoch 213/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0556 - accuracy: 0.9000 - val_loss: 0.0583 - val_accuracy: 0.9250\n",
      "Epoch 214/2000\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 0.0950 - accuracy: 0.8840 - val_loss: 0.2345 - val_accuracy: 0.8500\n",
      "Epoch 215/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0740 - accuracy: 0.8960 - val_loss: 0.0690 - val_accuracy: 0.9000\n",
      "Epoch 216/2000\n",
      "1000/1000 [==============================] - 1s 543us/step - loss: 0.0714 - accuracy: 0.8930 - val_loss: 0.0880 - val_accuracy: 0.8750\n",
      "Epoch 217/2000\n",
      "1000/1000 [==============================] - 1s 530us/step - loss: 0.0618 - accuracy: 0.9010 - val_loss: 0.0484 - val_accuracy: 0.9250\n",
      "Epoch 218/2000\n",
      "1000/1000 [==============================] - 1s 581us/step - loss: 0.0793 - accuracy: 0.8850 - val_loss: 0.0464 - val_accuracy: 0.9000\n",
      "Epoch 219/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0803 - accuracy: 0.8820 - val_loss: 0.0706 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/2000\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 0.0647 - accuracy: 0.9170 - val_loss: 0.0680 - val_accuracy: 0.9250\n",
      "Epoch 221/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0727 - accuracy: 0.9080 - val_loss: 0.0521 - val_accuracy: 0.9250\n",
      "Epoch 222/2000\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 0.0540 - accuracy: 0.9020 - val_loss: 0.0876 - val_accuracy: 0.8750\n",
      "Epoch 223/2000\n",
      "1000/1000 [==============================] - 1s 531us/step - loss: 0.0675 - accuracy: 0.9010 - val_loss: 0.1489 - val_accuracy: 0.9500\n",
      "Epoch 224/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0689 - accuracy: 0.8910 - val_loss: 0.0850 - val_accuracy: 0.8500\n",
      "Epoch 225/2000\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 0.0534 - accuracy: 0.9110 - val_loss: 0.0664 - val_accuracy: 0.9250\n",
      "Epoch 226/2000\n",
      "1000/1000 [==============================] - 1s 559us/step - loss: 0.0953 - accuracy: 0.9050 - val_loss: 0.0863 - val_accuracy: 0.9250\n",
      "Epoch 227/2000\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0599 - accuracy: 0.8980 - val_loss: 0.1471 - val_accuracy: 0.8500\n",
      "Epoch 228/2000\n",
      "1000/1000 [==============================] - 1s 675us/step - loss: 0.0492 - accuracy: 0.9040 - val_loss: 0.0595 - val_accuracy: 0.9000\n",
      "Epoch 229/2000\n",
      "1000/1000 [==============================] - 1s 633us/step - loss: 0.0803 - accuracy: 0.9090 - val_loss: 0.1323 - val_accuracy: 0.9000\n",
      "Epoch 230/2000\n",
      "1000/1000 [==============================] - 1s 617us/step - loss: 0.0668 - accuracy: 0.9040 - val_loss: 0.0717 - val_accuracy: 0.9250\n",
      "Epoch 231/2000\n",
      "1000/1000 [==============================] - 1s 653us/step - loss: 0.0973 - accuracy: 0.8990 - val_loss: 0.0682 - val_accuracy: 0.8500\n",
      "Epoch 232/2000\n",
      "1000/1000 [==============================] - 1s 605us/step - loss: 0.0674 - accuracy: 0.9050 - val_loss: 0.0735 - val_accuracy: 0.9500\n",
      "Epoch 233/2000\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0708 - accuracy: 0.9010 - val_loss: 0.0614 - val_accuracy: 0.9000\n",
      "Epoch 234/2000\n",
      "1000/1000 [==============================] - 1s 569us/step - loss: 0.0595 - accuracy: 0.8980 - val_loss: 0.1108 - val_accuracy: 0.9000\n",
      "Epoch 235/2000\n",
      "1000/1000 [==============================] - 1s 563us/step - loss: 0.0910 - accuracy: 0.8990 - val_loss: 0.0885 - val_accuracy: 0.9000\n",
      "Epoch 236/2000\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0866 - accuracy: 0.8960 - val_loss: 0.0510 - val_accuracy: 0.9000\n",
      "Epoch 237/2000\n",
      "1000/1000 [==============================] - 1s 646us/step - loss: 0.0992 - accuracy: 0.8970 - val_loss: 0.1313 - val_accuracy: 0.8500\n",
      "Epoch 238/2000\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0540 - accuracy: 0.9110 - val_loss: 0.2040 - val_accuracy: 0.9000\n",
      "Epoch 239/2000\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0480 - accuracy: 0.9010 - val_loss: 0.1030 - val_accuracy: 0.9000\n",
      "Epoch 240/2000\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0609 - accuracy: 0.8980 - val_loss: 0.0670 - val_accuracy: 0.8750\n",
      "Epoch 241/2000\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0806 - accuracy: 0.9050 - val_loss: 0.0409 - val_accuracy: 0.8750\n",
      "Epoch 242/2000\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0521 - accuracy: 0.8960 - val_loss: 0.2413 - val_accuracy: 0.8750\n",
      "Epoch 243/2000\n",
      "1000/1000 [==============================] - 1s 563us/step - loss: 0.0892 - accuracy: 0.8870 - val_loss: 0.0585 - val_accuracy: 0.8750\n",
      "Epoch 244/2000\n",
      "1000/1000 [==============================] - 1s 578us/step - loss: 0.0616 - accuracy: 0.8990 - val_loss: 0.0621 - val_accuracy: 0.9000\n",
      "Epoch 245/2000\n",
      "1000/1000 [==============================] - 1s 574us/step - loss: 0.0746 - accuracy: 0.8990 - val_loss: 0.1041 - val_accuracy: 0.8500\n",
      "Epoch 246/2000\n",
      "1000/1000 [==============================] - 1s 571us/step - loss: 0.0617 - accuracy: 0.9040 - val_loss: 0.0673 - val_accuracy: 0.9000\n",
      "Epoch 247/2000\n",
      "1000/1000 [==============================] - 1s 569us/step - loss: 0.0780 - accuracy: 0.8920 - val_loss: 0.3476 - val_accuracy: 0.8500\n",
      "Epoch 248/2000\n",
      "1000/1000 [==============================] - 1s 562us/step - loss: 0.0659 - accuracy: 0.9050 - val_loss: 0.0814 - val_accuracy: 0.8250\n",
      "Epoch 249/2000\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.0730 - accuracy: 0.8970 - val_loss: 0.0850 - val_accuracy: 0.8750\n",
      "Epoch 250/2000\n",
      "1000/1000 [==============================] - 1s 569us/step - loss: 0.0888 - accuracy: 0.9030 - val_loss: 0.0424 - val_accuracy: 0.9000\n",
      "Epoch 251/2000\n",
      "1000/1000 [==============================] - 1s 574us/step - loss: 0.0787 - accuracy: 0.9090 - val_loss: 0.0654 - val_accuracy: 0.8250\n",
      "Epoch 252/2000\n",
      "1000/1000 [==============================] - 1s 689us/step - loss: 0.0597 - accuracy: 0.8940 - val_loss: 0.1881 - val_accuracy: 0.9000\n",
      "Epoch 253/2000\n",
      "1000/1000 [==============================] - 1s 649us/step - loss: 0.0650 - accuracy: 0.9020 - val_loss: 0.0593 - val_accuracy: 0.9000\n",
      "Epoch 254/2000\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 0.0729 - accuracy: 0.9110 - val_loss: 0.0615 - val_accuracy: 0.9250\n",
      "Epoch 255/2000\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0830 - accuracy: 0.9050 - val_loss: 0.0842 - val_accuracy: 0.9250\n",
      "Epoch 256/2000\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 0.0715 - accuracy: 0.8990 - val_loss: 0.0841 - val_accuracy: 0.9000\n",
      "Epoch 257/2000\n",
      "1000/1000 [==============================] - 1s 572us/step - loss: 0.1585 - accuracy: 0.9020 - val_loss: 0.0799 - val_accuracy: 0.9750\n",
      "Epoch 258/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0697 - accuracy: 0.9090 - val_loss: 0.1201 - val_accuracy: 0.8500\n",
      "Epoch 259/2000\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 0.0865 - accuracy: 0.9000 - val_loss: 0.1363 - val_accuracy: 0.9000\n",
      "Epoch 260/2000\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0805 - accuracy: 0.9030 - val_loss: 0.1009 - val_accuracy: 0.9250\n",
      "Epoch 261/2000\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0537 - accuracy: 0.9060 - val_loss: 0.0554 - val_accuracy: 0.8750\n",
      "Epoch 262/2000\n",
      "1000/1000 [==============================] - 1s 563us/step - loss: 0.0594 - accuracy: 0.8900 - val_loss: 0.2601 - val_accuracy: 0.8750\n",
      "Epoch 263/2000\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0476 - accuracy: 0.9150 - val_loss: 0.0775 - val_accuracy: 0.9000\n",
      "Epoch 264/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0473 - accuracy: 0.9100 - val_loss: 0.1295 - val_accuracy: 0.8750\n",
      "Epoch 265/2000\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 0.0634 - accuracy: 0.8970 - val_loss: 0.0688 - val_accuracy: 0.9250\n",
      "Epoch 266/2000\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 0.0650 - accuracy: 0.9050 - val_loss: 0.1422 - val_accuracy: 0.9250\n",
      "Epoch 267/2000\n",
      "1000/1000 [==============================] - 1s 564us/step - loss: 0.0498 - accuracy: 0.9030 - val_loss: 0.1471 - val_accuracy: 0.8500\n",
      "Epoch 268/2000\n",
      "1000/1000 [==============================] - 1s 564us/step - loss: 0.0670 - accuracy: 0.9040 - val_loss: 0.0674 - val_accuracy: 0.9250\n",
      "Epoch 269/2000\n",
      "1000/1000 [==============================] - 1s 570us/step - loss: 0.0819 - accuracy: 0.8990 - val_loss: 0.4757 - val_accuracy: 0.9000\n",
      "Epoch 270/2000\n",
      "1000/1000 [==============================] - 1s 570us/step - loss: 0.0641 - accuracy: 0.9090 - val_loss: 0.0631 - val_accuracy: 0.8750\n",
      "Epoch 271/2000\n",
      "1000/1000 [==============================] - 1s 576us/step - loss: 0.0740 - accuracy: 0.9070 - val_loss: 0.1597 - val_accuracy: 0.9000\n",
      "Epoch 272/2000\n",
      "1000/1000 [==============================] - 1s 561us/step - loss: 0.0563 - accuracy: 0.9010 - val_loss: 0.1507 - val_accuracy: 0.8750\n",
      "Epoch 273/2000\n",
      "1000/1000 [==============================] - 1s 615us/step - loss: 0.0989 - accuracy: 0.9010 - val_loss: 0.0954 - val_accuracy: 0.8750\n",
      "Epoch 274/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 617us/step - loss: 0.0828 - accuracy: 0.8940 - val_loss: 0.0635 - val_accuracy: 0.8750\n",
      "Epoch 275/2000\n",
      "1000/1000 [==============================] - 1s 643us/step - loss: 0.0609 - accuracy: 0.9070 - val_loss: 0.0606 - val_accuracy: 0.8500\n",
      "Epoch 276/2000\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0465 - accuracy: 0.9170 - val_loss: 0.0954 - val_accuracy: 0.9250\n",
      "Epoch 277/2000\n",
      "1000/1000 [==============================] - 1s 564us/step - loss: 0.0543 - accuracy: 0.9070 - val_loss: 0.0524 - val_accuracy: 0.9500\n",
      "Epoch 278/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0730 - accuracy: 0.9060 - val_loss: 0.0943 - val_accuracy: 0.8750\n",
      "Epoch 279/2000\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0865 - accuracy: 0.9000 - val_loss: 0.1721 - val_accuracy: 0.8000\n",
      "Epoch 280/2000\n",
      "1000/1000 [==============================] - 1s 613us/step - loss: 0.0710 - accuracy: 0.9060 - val_loss: 0.0670 - val_accuracy: 0.9000\n",
      "Epoch 281/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0560 - accuracy: 0.8960 - val_loss: 0.1230 - val_accuracy: 0.8500\n",
      "Epoch 282/2000\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 0.0542 - accuracy: 0.8920 - val_loss: 0.0359 - val_accuracy: 0.8750\n",
      "Epoch 283/2000\n",
      "1000/1000 [==============================] - 1s 619us/step - loss: 0.0729 - accuracy: 0.9010 - val_loss: 0.0405 - val_accuracy: 0.9250\n",
      "Epoch 284/2000\n",
      "1000/1000 [==============================] - 1s 669us/step - loss: 0.0655 - accuracy: 0.8970 - val_loss: 0.0495 - val_accuracy: 0.9250\n",
      "Epoch 285/2000\n",
      "1000/1000 [==============================] - 1s 666us/step - loss: 0.2131 - accuracy: 0.8930 - val_loss: 0.1020 - val_accuracy: 0.8750\n",
      "Epoch 286/2000\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0796 - accuracy: 0.9050 - val_loss: 0.0718 - val_accuracy: 0.9000\n",
      "Epoch 287/2000\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.1250 - accuracy: 0.9070 - val_loss: 0.0401 - val_accuracy: 0.9000\n",
      "Epoch 288/2000\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0781 - accuracy: 0.9000 - val_loss: 0.1188 - val_accuracy: 0.8750\n",
      "Epoch 289/2000\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 0.0551 - accuracy: 0.9070 - val_loss: 0.0885 - val_accuracy: 0.8500\n",
      "Epoch 290/2000\n",
      "1000/1000 [==============================] - 1s 555us/step - loss: 0.0671 - accuracy: 0.9140 - val_loss: 0.0562 - val_accuracy: 0.8500\n",
      "Epoch 291/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0626 - accuracy: 0.8980 - val_loss: 0.0970 - val_accuracy: 0.8500\n",
      "Epoch 292/2000\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 0.0629 - accuracy: 0.8900 - val_loss: 0.0695 - val_accuracy: 0.9000\n",
      "Epoch 293/2000\n",
      "1000/1000 [==============================] - 1s 525us/step - loss: 0.0556 - accuracy: 0.8850 - val_loss: 0.0746 - val_accuracy: 0.9000\n",
      "Epoch 294/2000\n",
      "1000/1000 [==============================] - 1s 529us/step - loss: 0.0501 - accuracy: 0.8990 - val_loss: 0.0536 - val_accuracy: 0.9250\n",
      "Epoch 295/2000\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 0.0975 - accuracy: 0.9010 - val_loss: 0.8875 - val_accuracy: 0.8500\n",
      "Epoch 296/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.1450 - accuracy: 0.8960 - val_loss: 0.0833 - val_accuracy: 0.8000\n",
      "Epoch 297/2000\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 0.0684 - accuracy: 0.8970 - val_loss: 0.0729 - val_accuracy: 0.8250\n",
      "Epoch 298/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0455 - accuracy: 0.9010 - val_loss: 0.0904 - val_accuracy: 0.9000\n",
      "Epoch 299/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.0865 - accuracy: 0.9010 - val_loss: 0.2399 - val_accuracy: 0.8250\n",
      "Epoch 300/2000\n",
      "1000/1000 [==============================] - 1s 510us/step - loss: 0.0685 - accuracy: 0.8980 - val_loss: 0.0563 - val_accuracy: 0.8500\n",
      "Epoch 301/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0414 - accuracy: 0.8900 - val_loss: 0.1284 - val_accuracy: 0.8750\n",
      "Epoch 302/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.0787 - accuracy: 0.9100 - val_loss: 0.0511 - val_accuracy: 0.9000\n",
      "Epoch 303/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0544 - accuracy: 0.8900 - val_loss: 0.0508 - val_accuracy: 0.9000\n",
      "Epoch 304/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.0457 - accuracy: 0.9050 - val_loss: 0.1103 - val_accuracy: 0.8750\n",
      "Epoch 305/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0521 - accuracy: 0.9030 - val_loss: 0.0799 - val_accuracy: 0.8750\n",
      "Epoch 306/2000\n",
      "1000/1000 [==============================] - 1s 523us/step - loss: 0.0498 - accuracy: 0.9120 - val_loss: 0.0508 - val_accuracy: 0.8750\n",
      "Epoch 307/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.1869 - accuracy: 0.9010 - val_loss: 0.1134 - val_accuracy: 0.8000\n",
      "Epoch 308/2000\n",
      "1000/1000 [==============================] - 1s 526us/step - loss: 0.0832 - accuracy: 0.8970 - val_loss: 0.0742 - val_accuracy: 0.8000\n",
      "Epoch 309/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0522 - accuracy: 0.9060 - val_loss: 0.1093 - val_accuracy: 0.8750\n",
      "Epoch 310/2000\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.0653 - accuracy: 0.8990 - val_loss: 0.0505 - val_accuracy: 0.8750\n",
      "Epoch 311/2000\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0553 - accuracy: 0.9030 - val_loss: 0.1228 - val_accuracy: 0.9000\n",
      "Epoch 312/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0535 - accuracy: 0.9020 - val_loss: 0.1011 - val_accuracy: 0.8750\n",
      "Epoch 313/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.1000 - accuracy: 0.8910 - val_loss: 0.0587 - val_accuracy: 0.8750\n",
      "Epoch 314/2000\n",
      "1000/1000 [==============================] - 1s 633us/step - loss: 0.0605 - accuracy: 0.9140 - val_loss: 0.0391 - val_accuracy: 0.8750\n",
      "Epoch 315/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0514 - accuracy: 0.9010 - val_loss: 0.0781 - val_accuracy: 0.8000\n",
      "Epoch 316/2000\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 0.0398 - accuracy: 0.9140 - val_loss: 0.0657 - val_accuracy: 0.9000\n",
      "Epoch 317/2000\n",
      "1000/1000 [==============================] - 1s 599us/step - loss: 0.0813 - accuracy: 0.8900 - val_loss: 0.3129 - val_accuracy: 0.8500\n",
      "Epoch 318/2000\n",
      "1000/1000 [==============================] - 1s 523us/step - loss: 0.0499 - accuracy: 0.9010 - val_loss: 0.0630 - val_accuracy: 0.9000\n",
      "Epoch 319/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0422 - accuracy: 0.9100 - val_loss: 0.0432 - val_accuracy: 0.8750\n",
      "Epoch 320/2000\n",
      "1000/1000 [==============================] - 1s 569us/step - loss: 0.0432 - accuracy: 0.9040 - val_loss: 0.0821 - val_accuracy: 0.8750\n",
      "Epoch 321/2000\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0491 - accuracy: 0.9020 - val_loss: 0.0867 - val_accuracy: 0.8750\n",
      "Epoch 322/2000\n",
      "1000/1000 [==============================] - 1s 573us/step - loss: 0.0698 - accuracy: 0.8980 - val_loss: 0.0550 - val_accuracy: 0.9250\n",
      "Epoch 323/2000\n",
      "1000/1000 [==============================] - 1s 616us/step - loss: 0.0612 - accuracy: 0.9050 - val_loss: 0.0793 - val_accuracy: 0.8750\n",
      "Epoch 324/2000\n",
      "1000/1000 [==============================] - 1s 599us/step - loss: 0.0603 - accuracy: 0.9120 - val_loss: 0.0572 - val_accuracy: 0.8750\n",
      "Epoch 325/2000\n",
      "1000/1000 [==============================] - 1s 669us/step - loss: 0.0553 - accuracy: 0.9050 - val_loss: 0.0346 - val_accuracy: 0.8500\n",
      "Epoch 326/2000\n",
      "1000/1000 [==============================] - 1s 743us/step - loss: 0.0587 - accuracy: 0.9090 - val_loss: 0.0993 - val_accuracy: 0.8750\n",
      "Epoch 327/2000\n",
      "1000/1000 [==============================] - 1s 847us/step - loss: 0.0764 - accuracy: 0.9000 - val_loss: 0.0518 - val_accuracy: 0.8250\n",
      "Epoch 328/2000\n",
      "1000/1000 [==============================] - 1s 677us/step - loss: 0.0542 - accuracy: 0.9120 - val_loss: 0.0682 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/2000\n",
      "1000/1000 [==============================] - 1s 577us/step - loss: 0.0533 - accuracy: 0.9050 - val_loss: 0.0609 - val_accuracy: 0.8750\n",
      "Epoch 330/2000\n",
      "1000/1000 [==============================] - 1s 643us/step - loss: 0.0432 - accuracy: 0.9080 - val_loss: 0.0647 - val_accuracy: 0.9000\n",
      "Epoch 331/2000\n",
      "1000/1000 [==============================] - 1s 641us/step - loss: 0.0467 - accuracy: 0.9070 - val_loss: 0.0633 - val_accuracy: 0.9000\n",
      "Epoch 332/2000\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0429 - accuracy: 0.9270 - val_loss: 0.0942 - val_accuracy: 0.8500\n",
      "Epoch 333/2000\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0549 - accuracy: 0.9110 - val_loss: 0.0866 - val_accuracy: 0.8750\n",
      "Epoch 334/2000\n",
      "1000/1000 [==============================] - 1s 582us/step - loss: 0.0522 - accuracy: 0.9190 - val_loss: 0.0583 - val_accuracy: 0.9000\n",
      "Epoch 335/2000\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.0493 - accuracy: 0.9100 - val_loss: 0.1331 - val_accuracy: 0.8500\n",
      "Epoch 336/2000\n",
      "1000/1000 [==============================] - 1s 562us/step - loss: 0.0715 - accuracy: 0.9130 - val_loss: 0.2345 - val_accuracy: 0.9250\n",
      "Epoch 337/2000\n",
      "1000/1000 [==============================] - 1s 569us/step - loss: 0.0725 - accuracy: 0.9070 - val_loss: 0.0520 - val_accuracy: 0.8750\n",
      "Epoch 338/2000\n",
      "1000/1000 [==============================] - 1s 569us/step - loss: 0.0369 - accuracy: 0.9100 - val_loss: 0.0729 - val_accuracy: 0.9000\n",
      "Epoch 339/2000\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0658 - accuracy: 0.9050 - val_loss: 0.0464 - val_accuracy: 0.9000\n",
      "Epoch 340/2000\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0750 - accuracy: 0.9080 - val_loss: 0.1957 - val_accuracy: 0.8750\n",
      "Epoch 341/2000\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 0.1757 - accuracy: 0.9010 - val_loss: 0.0443 - val_accuracy: 0.9000\n",
      "Epoch 342/2000\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0467 - accuracy: 0.9170 - val_loss: 0.0447 - val_accuracy: 0.9250\n",
      "Epoch 343/2000\n",
      "1000/1000 [==============================] - 1s 622us/step - loss: 0.0830 - accuracy: 0.8970 - val_loss: 0.0719 - val_accuracy: 0.9000\n",
      "Epoch 344/2000\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 0.0384 - accuracy: 0.9040 - val_loss: 0.0631 - val_accuracy: 0.9250\n",
      "Epoch 345/2000\n",
      "1000/1000 [==============================] - 1s 569us/step - loss: 0.0613 - accuracy: 0.9000 - val_loss: 0.0669 - val_accuracy: 0.9500\n",
      "Epoch 346/2000\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0593 - accuracy: 0.9070 - val_loss: 0.4106 - val_accuracy: 0.8750\n",
      "Epoch 347/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.1322 - accuracy: 0.9010 - val_loss: 0.0786 - val_accuracy: 0.8750\n",
      "Epoch 348/2000\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.0526 - accuracy: 0.9050 - val_loss: 0.0459 - val_accuracy: 0.9250\n",
      "Epoch 349/2000\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0541 - accuracy: 0.9100 - val_loss: 0.0490 - val_accuracy: 0.8750\n",
      "Epoch 350/2000\n",
      "1000/1000 [==============================] - 1s 572us/step - loss: 0.0492 - accuracy: 0.9290 - val_loss: 0.0594 - val_accuracy: 0.9000\n",
      "Epoch 351/2000\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0505 - accuracy: 0.9140 - val_loss: 0.1284 - val_accuracy: 0.8750\n",
      "Epoch 352/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0877 - accuracy: 0.9070 - val_loss: 0.0903 - val_accuracy: 0.9000\n",
      "Epoch 353/2000\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 0.0600 - accuracy: 0.9070 - val_loss: 0.0333 - val_accuracy: 0.9000\n",
      "Epoch 354/2000\n",
      "1000/1000 [==============================] - 1s 569us/step - loss: 0.0387 - accuracy: 0.9110 - val_loss: 0.0692 - val_accuracy: 0.9000\n",
      "Epoch 355/2000\n",
      "1000/1000 [==============================] - 1s 573us/step - loss: 0.0584 - accuracy: 0.9090 - val_loss: 0.0722 - val_accuracy: 0.8750\n",
      "Epoch 356/2000\n",
      "1000/1000 [==============================] - 1s 564us/step - loss: 0.1066 - accuracy: 0.8990 - val_loss: 0.1325 - val_accuracy: 0.8250\n",
      "Epoch 357/2000\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 0.0489 - accuracy: 0.9170 - val_loss: 0.0361 - val_accuracy: 0.9250\n",
      "Epoch 358/2000\n",
      "1000/1000 [==============================] - 1s 563us/step - loss: 0.0590 - accuracy: 0.9120 - val_loss: 0.0436 - val_accuracy: 0.9000\n",
      "Epoch 359/2000\n",
      "1000/1000 [==============================] - 1s 567us/step - loss: 0.0515 - accuracy: 0.9070 - val_loss: 0.0940 - val_accuracy: 0.8750\n",
      "Epoch 360/2000\n",
      "1000/1000 [==============================] - 1s 574us/step - loss: 0.0592 - accuracy: 0.9020 - val_loss: 0.0342 - val_accuracy: 0.9500\n",
      "Epoch 361/2000\n",
      "1000/1000 [==============================] - 1s 582us/step - loss: 0.0446 - accuracy: 0.9160 - val_loss: 0.0805 - val_accuracy: 0.9000\n",
      "Epoch 362/2000\n",
      "1000/1000 [==============================] - 1s 561us/step - loss: 0.0676 - accuracy: 0.8960 - val_loss: 0.0383 - val_accuracy: 0.8750\n",
      "Epoch 363/2000\n",
      "1000/1000 [==============================] - 1s 564us/step - loss: 0.0495 - accuracy: 0.8980 - val_loss: 0.0961 - val_accuracy: 0.8250\n",
      "Epoch 364/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0478 - accuracy: 0.9000 - val_loss: 0.0493 - val_accuracy: 0.8500\n",
      "Epoch 365/2000\n",
      "1000/1000 [==============================] - 1s 579us/step - loss: 0.0477 - accuracy: 0.9060 - val_loss: 0.0972 - val_accuracy: 0.8500\n",
      "Epoch 366/2000\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.0411 - accuracy: 0.9150 - val_loss: 0.0790 - val_accuracy: 0.8500\n",
      "Epoch 367/2000\n",
      "1000/1000 [==============================] - 1s 581us/step - loss: 0.0365 - accuracy: 0.9010 - val_loss: 0.0881 - val_accuracy: 0.8750\n",
      "Epoch 368/2000\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0434 - accuracy: 0.9150 - val_loss: 0.0423 - val_accuracy: 0.9250\n",
      "Epoch 369/2000\n",
      "1000/1000 [==============================] - 1s 576us/step - loss: 0.0426 - accuracy: 0.9030 - val_loss: 0.0710 - val_accuracy: 0.9250\n",
      "Epoch 370/2000\n",
      "1000/1000 [==============================] - 1s 567us/step - loss: 0.0414 - accuracy: 0.9150 - val_loss: 0.0455 - val_accuracy: 0.9250\n",
      "Epoch 371/2000\n",
      "1000/1000 [==============================] - 1s 576us/step - loss: 0.0563 - accuracy: 0.9170 - val_loss: 0.1616 - val_accuracy: 0.8750\n",
      "Epoch 372/2000\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 0.0458 - accuracy: 0.8990 - val_loss: 0.0420 - val_accuracy: 0.9000\n",
      "Epoch 373/2000\n",
      "1000/1000 [==============================] - 1s 572us/step - loss: 0.1057 - accuracy: 0.9080 - val_loss: 0.0354 - val_accuracy: 0.9000\n",
      "Epoch 374/2000\n",
      "1000/1000 [==============================] - 1s 568us/step - loss: 0.0543 - accuracy: 0.9120 - val_loss: 0.0765 - val_accuracy: 0.9000\n",
      "Epoch 375/2000\n",
      "1000/1000 [==============================] - 1s 561us/step - loss: 0.0409 - accuracy: 0.9060 - val_loss: 0.0460 - val_accuracy: 0.9000\n",
      "Epoch 376/2000\n",
      "1000/1000 [==============================] - 1s 567us/step - loss: 0.0693 - accuracy: 0.9230 - val_loss: 0.0487 - val_accuracy: 0.9000\n",
      "Epoch 377/2000\n",
      "1000/1000 [==============================] - 1s 573us/step - loss: 0.0354 - accuracy: 0.9110 - val_loss: 0.1097 - val_accuracy: 0.8500\n",
      "Epoch 378/2000\n",
      "1000/1000 [==============================] - 1s 581us/step - loss: 0.0532 - accuracy: 0.9160 - val_loss: 0.0869 - val_accuracy: 0.9000\n",
      "Epoch 379/2000\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0368 - accuracy: 0.9120 - val_loss: 0.0307 - val_accuracy: 0.9000\n",
      "Epoch 380/2000\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.0539 - accuracy: 0.9220 - val_loss: 0.0910 - val_accuracy: 0.8500\n",
      "Epoch 381/2000\n",
      "1000/1000 [==============================] - 1s 571us/step - loss: 0.0337 - accuracy: 0.9040 - val_loss: 0.0330 - val_accuracy: 0.8750\n",
      "Epoch 382/2000\n",
      "1000/1000 [==============================] - 1s 659us/step - loss: 0.0643 - accuracy: 0.9200 - val_loss: 0.0476 - val_accuracy: 0.8500\n",
      "Epoch 383/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 649us/step - loss: 0.0422 - accuracy: 0.9220 - val_loss: 0.0546 - val_accuracy: 0.9000\n",
      "Epoch 384/2000\n",
      "1000/1000 [==============================] - 1s 619us/step - loss: 0.0340 - accuracy: 0.9080 - val_loss: 0.0413 - val_accuracy: 0.9000\n",
      "Epoch 385/2000\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0345 - accuracy: 0.9260 - val_loss: 0.0640 - val_accuracy: 0.8750\n",
      "Epoch 386/2000\n",
      "1000/1000 [==============================] - 1s 571us/step - loss: 0.0425 - accuracy: 0.9150 - val_loss: 0.0464 - val_accuracy: 0.8750\n",
      "Epoch 387/2000\n",
      "1000/1000 [==============================] - 1s 557us/step - loss: 0.0557 - accuracy: 0.9060 - val_loss: 0.0679 - val_accuracy: 0.9250\n",
      "Epoch 388/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0397 - accuracy: 0.9100 - val_loss: 0.0696 - val_accuracy: 0.9500\n",
      "Epoch 389/2000\n",
      "1000/1000 [==============================] - 1s 559us/step - loss: 0.0371 - accuracy: 0.9240 - val_loss: 0.0512 - val_accuracy: 0.8750\n",
      "Epoch 390/2000\n",
      "1000/1000 [==============================] - 1s 688us/step - loss: 0.0489 - accuracy: 0.9170 - val_loss: 0.0434 - val_accuracy: 0.8750\n",
      "Epoch 391/2000\n",
      "1000/1000 [==============================] - 1s 615us/step - loss: 0.0347 - accuracy: 0.9230 - val_loss: 0.0426 - val_accuracy: 0.8750\n",
      "Epoch 392/2000\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0334 - accuracy: 0.9220 - val_loss: 0.0466 - val_accuracy: 0.8750\n",
      "Epoch 393/2000\n",
      "1000/1000 [==============================] - 1s 579us/step - loss: 0.0361 - accuracy: 0.9230 - val_loss: 0.0410 - val_accuracy: 0.9000\n",
      "Epoch 394/2000\n",
      "1000/1000 [==============================] - 1s 576us/step - loss: 0.0310 - accuracy: 0.9290 - val_loss: 0.0354 - val_accuracy: 0.8750\n",
      "Epoch 395/2000\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0375 - accuracy: 0.9070 - val_loss: 0.0886 - val_accuracy: 0.9000\n",
      "Epoch 396/2000\n",
      "1000/1000 [==============================] - 1s 672us/step - loss: 0.0579 - accuracy: 0.9110 - val_loss: 0.0333 - val_accuracy: 0.9000\n",
      "Epoch 397/2000\n",
      "1000/1000 [==============================] - 1s 861us/step - loss: 0.0359 - accuracy: 0.8980 - val_loss: 0.0450 - val_accuracy: 0.9000\n",
      "Epoch 398/2000\n",
      "1000/1000 [==============================] - 1s 692us/step - loss: 0.0284 - accuracy: 0.9130 - val_loss: 0.0812 - val_accuracy: 0.8500\n",
      "Epoch 399/2000\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.0337 - accuracy: 0.9180 - val_loss: 0.0584 - val_accuracy: 0.9000\n",
      "Epoch 400/2000\n",
      "1000/1000 [==============================] - 1s 611us/step - loss: 0.0440 - accuracy: 0.9250 - val_loss: 0.0670 - val_accuracy: 0.8750\n",
      "Epoch 401/2000\n",
      "1000/1000 [==============================] - 1s 637us/step - loss: 0.0358 - accuracy: 0.9180 - val_loss: 0.0431 - val_accuracy: 0.9000\n",
      "Epoch 402/2000\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0483 - accuracy: 0.9080 - val_loss: 0.0593 - val_accuracy: 0.9250\n",
      "Epoch 403/2000\n",
      "1000/1000 [==============================] - 1s 574us/step - loss: 0.1341 - accuracy: 0.9130 - val_loss: 0.0689 - val_accuracy: 0.8500\n",
      "Epoch 404/2000\n",
      "1000/1000 [==============================] - 1s 574us/step - loss: 0.0596 - accuracy: 0.9170 - val_loss: 0.0843 - val_accuracy: 0.8500\n",
      "Epoch 405/2000\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0472 - accuracy: 0.9210 - val_loss: 0.0499 - val_accuracy: 0.8750\n",
      "Epoch 406/2000\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0462 - accuracy: 0.9240 - val_loss: 0.0333 - val_accuracy: 0.8750\n",
      "Epoch 407/2000\n",
      "1000/1000 [==============================] - 1s 567us/step - loss: 0.0431 - accuracy: 0.9220 - val_loss: 0.1391 - val_accuracy: 0.8750\n",
      "Epoch 408/2000\n",
      "1000/1000 [==============================] - 1s 576us/step - loss: 0.0404 - accuracy: 0.9110 - val_loss: 0.0714 - val_accuracy: 0.9250\n",
      "Epoch 409/2000\n",
      "1000/1000 [==============================] - 1s 563us/step - loss: 0.0862 - accuracy: 0.9220 - val_loss: 0.1395 - val_accuracy: 0.8500\n",
      "Epoch 410/2000\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 0.0436 - accuracy: 0.9230 - val_loss: 0.1122 - val_accuracy: 0.9250\n",
      "Epoch 411/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0313 - accuracy: 0.9300 - val_loss: 0.0376 - val_accuracy: 0.9250\n",
      "Epoch 412/2000\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.0354 - accuracy: 0.9310 - val_loss: 0.0305 - val_accuracy: 0.9250\n",
      "Epoch 413/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0467 - accuracy: 0.9220 - val_loss: 0.0545 - val_accuracy: 0.9000\n",
      "Epoch 414/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0751 - accuracy: 0.9100 - val_loss: 0.0459 - val_accuracy: 0.9000\n",
      "Epoch 415/2000\n",
      "1000/1000 [==============================] - 1s 578us/step - loss: 0.0491 - accuracy: 0.9080 - val_loss: 0.1000 - val_accuracy: 0.9000\n",
      "Epoch 416/2000\n",
      "1000/1000 [==============================] - 1s 572us/step - loss: 0.0395 - accuracy: 0.9270 - val_loss: 0.0897 - val_accuracy: 0.9000\n",
      "Epoch 417/2000\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 0.0504 - accuracy: 0.9290 - val_loss: 0.0610 - val_accuracy: 0.9250\n",
      "Epoch 418/2000\n",
      "1000/1000 [==============================] - 1s 577us/step - loss: 0.0637 - accuracy: 0.9180 - val_loss: 0.0983 - val_accuracy: 0.9000\n",
      "Epoch 419/2000\n",
      "1000/1000 [==============================] - 1s 579us/step - loss: 0.0411 - accuracy: 0.9030 - val_loss: 0.0909 - val_accuracy: 0.9000\n",
      "Epoch 420/2000\n",
      "1000/1000 [==============================] - 1s 572us/step - loss: 0.0423 - accuracy: 0.9220 - val_loss: 0.0603 - val_accuracy: 0.9250\n",
      "Epoch 421/2000\n",
      "1000/1000 [==============================] - 1s 563us/step - loss: 0.0580 - accuracy: 0.9360 - val_loss: 0.0470 - val_accuracy: 0.9250\n",
      "Epoch 422/2000\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 0.0588 - accuracy: 0.9150 - val_loss: 0.0394 - val_accuracy: 0.8500\n",
      "Epoch 423/2000\n",
      "1000/1000 [==============================] - 1s 630us/step - loss: 0.0322 - accuracy: 0.9230 - val_loss: 0.0390 - val_accuracy: 0.9000\n",
      "Epoch 424/2000\n",
      "1000/1000 [==============================] - 1s 647us/step - loss: 0.0333 - accuracy: 0.9230 - val_loss: 0.0966 - val_accuracy: 0.8750\n",
      "Epoch 425/2000\n",
      "1000/1000 [==============================] - 1s 617us/step - loss: 0.0408 - accuracy: 0.9120 - val_loss: 0.0681 - val_accuracy: 0.9250\n",
      "Epoch 426/2000\n",
      "1000/1000 [==============================] - 1s 572us/step - loss: 0.0459 - accuracy: 0.9250 - val_loss: 0.0614 - val_accuracy: 0.9000\n",
      "Epoch 427/2000\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0391 - accuracy: 0.9200 - val_loss: 0.1526 - val_accuracy: 0.9250\n",
      "Epoch 428/2000\n",
      "1000/1000 [==============================] - 1s 578us/step - loss: 0.0597 - accuracy: 0.9160 - val_loss: 0.0406 - val_accuracy: 0.9500\n",
      "Epoch 429/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0488 - accuracy: 0.9110 - val_loss: 0.0691 - val_accuracy: 0.9500\n",
      "Epoch 430/2000\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 0.0584 - accuracy: 0.9110 - val_loss: 0.0666 - val_accuracy: 0.9500\n",
      "Epoch 431/2000\n",
      "1000/1000 [==============================] - 1s 544us/step - loss: 0.0406 - accuracy: 0.9250 - val_loss: 0.0378 - val_accuracy: 0.9000\n",
      "Epoch 432/2000\n",
      "1000/1000 [==============================] - 1s 562us/step - loss: 0.1189 - accuracy: 0.9280 - val_loss: 0.0590 - val_accuracy: 0.8500\n",
      "Epoch 433/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0344 - accuracy: 0.9290 - val_loss: 0.0288 - val_accuracy: 0.9250\n",
      "Epoch 434/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0397 - accuracy: 0.9270 - val_loss: 0.0894 - val_accuracy: 0.9000\n",
      "Epoch 435/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0584 - accuracy: 0.9230 - val_loss: 0.0842 - val_accuracy: 0.9250\n",
      "Epoch 436/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0483 - accuracy: 0.9160 - val_loss: 0.0421 - val_accuracy: 0.9000\n",
      "Epoch 437/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0354 - accuracy: 0.9320 - val_loss: 0.0393 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438/2000\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 0.0464 - accuracy: 0.9290 - val_loss: 0.0519 - val_accuracy: 0.8750\n",
      "Epoch 439/2000\n",
      "1000/1000 [==============================] - 1s 507us/step - loss: 0.0386 - accuracy: 0.9000 - val_loss: 0.0211 - val_accuracy: 0.8750\n",
      "Epoch 440/2000\n",
      "1000/1000 [==============================] - 1s 507us/step - loss: 0.0516 - accuracy: 0.9220 - val_loss: 0.1127 - val_accuracy: 0.9500\n",
      "Epoch 441/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0401 - accuracy: 0.9220 - val_loss: 0.0591 - val_accuracy: 0.9000\n",
      "Epoch 442/2000\n",
      "1000/1000 [==============================] - 1s 557us/step - loss: 0.0337 - accuracy: 0.9120 - val_loss: 0.0381 - val_accuracy: 0.8750\n",
      "Epoch 443/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0330 - accuracy: 0.9330 - val_loss: 0.0757 - val_accuracy: 0.8750\n",
      "Epoch 444/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0343 - accuracy: 0.9200 - val_loss: 0.0883 - val_accuracy: 0.9000\n",
      "Epoch 445/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0480 - accuracy: 0.9200 - val_loss: 0.0624 - val_accuracy: 0.8500\n",
      "Epoch 446/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0298 - accuracy: 0.9250 - val_loss: 0.0348 - val_accuracy: 0.9000\n",
      "Epoch 447/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0501 - accuracy: 0.9190 - val_loss: 0.0926 - val_accuracy: 0.8750\n",
      "Epoch 448/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0505 - accuracy: 0.9240 - val_loss: 0.0552 - val_accuracy: 0.8750\n",
      "Epoch 449/2000\n",
      "1000/1000 [==============================] - 1s 533us/step - loss: 0.0290 - accuracy: 0.9210 - val_loss: 0.0405 - val_accuracy: 0.9500\n",
      "Epoch 450/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0283 - accuracy: 0.9250 - val_loss: 0.0544 - val_accuracy: 0.8750\n",
      "Epoch 451/2000\n",
      "1000/1000 [==============================] - 1s 510us/step - loss: 0.0338 - accuracy: 0.9180 - val_loss: 0.0395 - val_accuracy: 0.9500\n",
      "Epoch 452/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0550 - accuracy: 0.9200 - val_loss: 0.0787 - val_accuracy: 0.9000\n",
      "Epoch 453/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0380 - accuracy: 0.9350 - val_loss: 0.0502 - val_accuracy: 0.9000\n",
      "Epoch 454/2000\n",
      "1000/1000 [==============================] - 1s 523us/step - loss: 0.0435 - accuracy: 0.9250 - val_loss: 0.0439 - val_accuracy: 0.9250\n",
      "Epoch 455/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0478 - accuracy: 0.9150 - val_loss: 0.0811 - val_accuracy: 0.8750\n",
      "Epoch 456/2000\n",
      "1000/1000 [==============================] - 1s 525us/step - loss: 0.0334 - accuracy: 0.9270 - val_loss: 0.0410 - val_accuracy: 0.9000\n",
      "Epoch 457/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0446 - accuracy: 0.9280 - val_loss: 0.0641 - val_accuracy: 0.9000\n",
      "Epoch 458/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.0476 - accuracy: 0.9170 - val_loss: 0.0887 - val_accuracy: 0.9250\n",
      "Epoch 459/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.0396 - accuracy: 0.9160 - val_loss: 0.0741 - val_accuracy: 0.9000\n",
      "Epoch 460/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0487 - accuracy: 0.9190 - val_loss: 0.0495 - val_accuracy: 0.8500\n",
      "Epoch 461/2000\n",
      "1000/1000 [==============================] - 1s 529us/step - loss: 0.0272 - accuracy: 0.9190 - val_loss: 0.0468 - val_accuracy: 0.9000\n",
      "Epoch 462/2000\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 0.0517 - accuracy: 0.9220 - val_loss: 0.0554 - val_accuracy: 0.9000\n",
      "Epoch 463/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0359 - accuracy: 0.9250 - val_loss: 0.1132 - val_accuracy: 0.9000\n",
      "Epoch 464/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.0298 - accuracy: 0.9340 - val_loss: 0.0695 - val_accuracy: 0.8750\n",
      "Epoch 465/2000\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 0.0355 - accuracy: 0.9230 - val_loss: 0.0708 - val_accuracy: 0.9000\n",
      "Epoch 466/2000\n",
      "1000/1000 [==============================] - 1s 523us/step - loss: 0.0729 - accuracy: 0.9160 - val_loss: 0.0674 - val_accuracy: 0.9000\n",
      "Epoch 467/2000\n",
      "1000/1000 [==============================] - 1s 531us/step - loss: 0.0462 - accuracy: 0.9230 - val_loss: 0.0525 - val_accuracy: 0.9000\n",
      "Epoch 468/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0577 - accuracy: 0.9160 - val_loss: 0.0912 - val_accuracy: 0.8750\n",
      "Epoch 469/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0391 - accuracy: 0.9350 - val_loss: 0.0507 - val_accuracy: 0.8750\n",
      "Epoch 470/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0548 - accuracy: 0.9280 - val_loss: 0.0724 - val_accuracy: 0.9250\n",
      "Epoch 471/2000\n",
      "1000/1000 [==============================] - 1s 510us/step - loss: 0.0311 - accuracy: 0.9290 - val_loss: 0.0607 - val_accuracy: 0.8500\n",
      "Epoch 472/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0349 - accuracy: 0.9210 - val_loss: 0.0355 - val_accuracy: 0.9250\n",
      "Epoch 473/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0350 - accuracy: 0.9290 - val_loss: 0.0515 - val_accuracy: 0.8500\n",
      "Epoch 474/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0324 - accuracy: 0.9220 - val_loss: 0.0453 - val_accuracy: 0.9000\n",
      "Epoch 475/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0343 - accuracy: 0.9290 - val_loss: 0.0434 - val_accuracy: 0.9500\n",
      "Epoch 476/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0309 - accuracy: 0.9270 - val_loss: 0.0629 - val_accuracy: 0.8750\n",
      "Epoch 477/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0447 - accuracy: 0.9260 - val_loss: 0.0614 - val_accuracy: 0.9250\n",
      "Epoch 478/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0445 - accuracy: 0.9290 - val_loss: 0.0673 - val_accuracy: 0.9000\n",
      "Epoch 479/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0310 - accuracy: 0.9310 - val_loss: 0.0843 - val_accuracy: 0.9250\n",
      "Epoch 480/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0389 - accuracy: 0.9230 - val_loss: 0.0338 - val_accuracy: 0.9250\n",
      "Epoch 481/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0302 - accuracy: 0.9250 - val_loss: 0.0395 - val_accuracy: 0.9250\n",
      "Epoch 482/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0445 - accuracy: 0.9330 - val_loss: 0.0933 - val_accuracy: 0.9000\n",
      "Epoch 483/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0455 - accuracy: 0.9210 - val_loss: 0.0549 - val_accuracy: 0.9250\n",
      "Epoch 484/2000\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 0.0361 - accuracy: 0.9210 - val_loss: 0.0524 - val_accuracy: 0.8500\n",
      "Epoch 485/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0405 - accuracy: 0.9170 - val_loss: 0.0468 - val_accuracy: 0.8750\n",
      "Epoch 486/2000\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 0.0383 - accuracy: 0.9260 - val_loss: 0.0362 - val_accuracy: 0.9500\n",
      "Epoch 487/2000\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 0.0272 - accuracy: 0.9180 - val_loss: 0.0360 - val_accuracy: 0.9500\n",
      "Epoch 488/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0362 - accuracy: 0.9260 - val_loss: 0.0503 - val_accuracy: 0.9250\n",
      "Epoch 489/2000\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 0.0423 - accuracy: 0.9320 - val_loss: 0.0321 - val_accuracy: 0.9000\n",
      "Epoch 490/2000\n",
      "1000/1000 [==============================] - 1s 557us/step - loss: 0.0306 - accuracy: 0.9330 - val_loss: 0.0310 - val_accuracy: 0.8750\n",
      "Epoch 491/2000\n",
      "1000/1000 [==============================] - 1s 555us/step - loss: 0.0303 - accuracy: 0.9360 - val_loss: 0.0457 - val_accuracy: 0.9500\n",
      "Epoch 492/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.0390 - accuracy: 0.9190 - val_loss: 0.1544 - val_accuracy: 0.9000\n",
      "Epoch 493/2000\n",
      "1000/1000 [==============================] - 1s 504us/step - loss: 0.0364 - accuracy: 0.9270 - val_loss: 0.0739 - val_accuracy: 0.9000\n",
      "Epoch 494/2000\n",
      "1000/1000 [==============================] - 1s 504us/step - loss: 0.0254 - accuracy: 0.9380 - val_loss: 0.0626 - val_accuracy: 0.9250\n",
      "Epoch 495/2000\n",
      "1000/1000 [==============================] - 1s 502us/step - loss: 0.0521 - accuracy: 0.9470 - val_loss: 0.1464 - val_accuracy: 0.8500\n",
      "Epoch 496/2000\n",
      "1000/1000 [==============================] - 1s 504us/step - loss: 0.0337 - accuracy: 0.9310 - val_loss: 0.0376 - val_accuracy: 0.9250\n",
      "Epoch 497/2000\n",
      "1000/1000 [==============================] - 1s 510us/step - loss: 0.0385 - accuracy: 0.9270 - val_loss: 0.0378 - val_accuracy: 0.9250\n",
      "Epoch 498/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0324 - accuracy: 0.9200 - val_loss: 0.0367 - val_accuracy: 0.9250\n",
      "Epoch 499/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0519 - accuracy: 0.9300 - val_loss: 0.0406 - val_accuracy: 0.9750\n",
      "Epoch 500/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0399 - accuracy: 0.9200 - val_loss: 0.0405 - val_accuracy: 0.9000\n",
      "Epoch 501/2000\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.0300 - accuracy: 0.9260 - val_loss: 0.0440 - val_accuracy: 0.9000\n",
      "Epoch 502/2000\n",
      "1000/1000 [==============================] - 1s 525us/step - loss: 0.0535 - accuracy: 0.9290 - val_loss: 0.1627 - val_accuracy: 0.8250\n",
      "Epoch 503/2000\n",
      "1000/1000 [==============================] - 1s 531us/step - loss: 0.0288 - accuracy: 0.9310 - val_loss: 0.0585 - val_accuracy: 0.9250\n",
      "Epoch 504/2000\n",
      "1000/1000 [==============================] - 1s 529us/step - loss: 0.0298 - accuracy: 0.9300 - val_loss: 0.0570 - val_accuracy: 0.8750\n",
      "Epoch 505/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0255 - accuracy: 0.9310 - val_loss: 0.0633 - val_accuracy: 0.9250\n",
      "Epoch 506/2000\n",
      "1000/1000 [==============================] - 1s 506us/step - loss: 0.0324 - accuracy: 0.9350 - val_loss: 0.0586 - val_accuracy: 0.9250\n",
      "Epoch 507/2000\n",
      "1000/1000 [==============================] - 1s 510us/step - loss: 0.0921 - accuracy: 0.9230 - val_loss: 0.0539 - val_accuracy: 0.9500\n",
      "Epoch 508/2000\n",
      "1000/1000 [==============================] - 1s 505us/step - loss: 0.0310 - accuracy: 0.9270 - val_loss: 0.0537 - val_accuracy: 0.9000\n",
      "Epoch 509/2000\n",
      "1000/1000 [==============================] - 1s 506us/step - loss: 0.0456 - accuracy: 0.9340 - val_loss: 0.0672 - val_accuracy: 0.8500\n",
      "Epoch 510/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0587 - accuracy: 0.9100 - val_loss: 0.0608 - val_accuracy: 0.8750\n",
      "Epoch 511/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0449 - accuracy: 0.9220 - val_loss: 0.0331 - val_accuracy: 0.9750\n",
      "Epoch 512/2000\n",
      "1000/1000 [==============================] - 1s 563us/step - loss: 0.0860 - accuracy: 0.9120 - val_loss: 0.0353 - val_accuracy: 0.9250\n",
      "Epoch 513/2000\n",
      "1000/1000 [==============================] - 1s 564us/step - loss: 0.0406 - accuracy: 0.9290 - val_loss: 0.0499 - val_accuracy: 0.9250\n",
      "Epoch 514/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0288 - accuracy: 0.9230 - val_loss: 0.0858 - val_accuracy: 0.9000\n",
      "Epoch 515/2000\n",
      "1000/1000 [==============================] - 1s 507us/step - loss: 0.0322 - accuracy: 0.9140 - val_loss: 0.0479 - val_accuracy: 0.9000\n",
      "Epoch 516/2000\n",
      "1000/1000 [==============================] - 1s 507us/step - loss: 0.0323 - accuracy: 0.9290 - val_loss: 0.0403 - val_accuracy: 0.9500\n",
      "Epoch 517/2000\n",
      "1000/1000 [==============================] - 1s 505us/step - loss: 0.0306 - accuracy: 0.9340 - val_loss: 0.0561 - val_accuracy: 0.9500\n",
      "Epoch 518/2000\n",
      "1000/1000 [==============================] - 1s 505us/step - loss: 0.0629 - accuracy: 0.9220 - val_loss: 0.0684 - val_accuracy: 0.8250\n",
      "Epoch 519/2000\n",
      "1000/1000 [==============================] - 1s 542us/step - loss: 0.0250 - accuracy: 0.9200 - val_loss: 0.0810 - val_accuracy: 0.9000\n",
      "Epoch 520/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0440 - accuracy: 0.9320 - val_loss: 0.0578 - val_accuracy: 0.9500\n",
      "Epoch 521/2000\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0260 - accuracy: 0.9310 - val_loss: 0.0646 - val_accuracy: 0.9250\n",
      "Epoch 522/2000\n",
      "1000/1000 [==============================] - 1s 577us/step - loss: 0.0353 - accuracy: 0.9350 - val_loss: 0.0398 - val_accuracy: 0.8750\n",
      "Epoch 523/2000\n",
      "1000/1000 [==============================] - 1s 544us/step - loss: 0.0427 - accuracy: 0.9220 - val_loss: 0.0651 - val_accuracy: 0.8750\n",
      "Epoch 524/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0639 - accuracy: 0.9300 - val_loss: 0.0783 - val_accuracy: 0.9000\n",
      "Epoch 525/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0237 - accuracy: 0.9230 - val_loss: 0.0333 - val_accuracy: 0.9000\n",
      "Epoch 526/2000\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 0.0404 - accuracy: 0.9320 - val_loss: 0.0244 - val_accuracy: 0.9250\n",
      "Epoch 527/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0301 - accuracy: 0.9190 - val_loss: 0.0955 - val_accuracy: 0.9000\n",
      "Epoch 528/2000\n",
      "1000/1000 [==============================] - 1s 578us/step - loss: 0.0431 - accuracy: 0.9090 - val_loss: 0.0808 - val_accuracy: 0.9500\n",
      "Epoch 529/2000\n",
      "1000/1000 [==============================] - 1s 610us/step - loss: 0.0336 - accuracy: 0.9260 - val_loss: 0.0565 - val_accuracy: 0.8750\n",
      "Epoch 530/2000\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0383 - accuracy: 0.9180 - val_loss: 0.0942 - val_accuracy: 0.8750\n",
      "Epoch 531/2000\n",
      "1000/1000 [==============================] - 1s 621us/step - loss: 0.0309 - accuracy: 0.9200 - val_loss: 0.0598 - val_accuracy: 0.9250\n",
      "Epoch 532/2000\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0853 - accuracy: 0.9170 - val_loss: 0.0840 - val_accuracy: 0.9000\n",
      "Epoch 533/2000\n",
      "1000/1000 [==============================] - 1s 607us/step - loss: 0.0380 - accuracy: 0.9250 - val_loss: 0.2099 - val_accuracy: 0.9250\n",
      "Epoch 534/2000\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0563 - accuracy: 0.9260 - val_loss: 0.0423 - val_accuracy: 0.9500\n",
      "Epoch 535/2000\n",
      "1000/1000 [==============================] - 1s 578us/step - loss: 0.0261 - accuracy: 0.9240 - val_loss: 0.0410 - val_accuracy: 0.8500\n",
      "Epoch 536/2000\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 0.0323 - accuracy: 0.9230 - val_loss: 0.0548 - val_accuracy: 0.9000\n",
      "Epoch 537/2000\n",
      "1000/1000 [==============================] - 1s 577us/step - loss: 0.0246 - accuracy: 0.9300 - val_loss: 0.0486 - val_accuracy: 0.9000\n",
      "Epoch 538/2000\n",
      "1000/1000 [==============================] - 1s 621us/step - loss: 0.0512 - accuracy: 0.9290 - val_loss: 0.0448 - val_accuracy: 0.9000\n",
      "Epoch 539/2000\n",
      "1000/1000 [==============================] - 1s 636us/step - loss: 0.0269 - accuracy: 0.9240 - val_loss: 0.0543 - val_accuracy: 0.9000\n",
      "Epoch 540/2000\n",
      "1000/1000 [==============================] - 1s 656us/step - loss: 0.0286 - accuracy: 0.9330 - val_loss: 0.0765 - val_accuracy: 0.9000\n",
      "Epoch 541/2000\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0431 - accuracy: 0.9300 - val_loss: 0.0899 - val_accuracy: 0.8500\n",
      "Epoch 542/2000\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0298 - accuracy: 0.9250 - val_loss: 0.0456 - val_accuracy: 0.9000\n",
      "Epoch 543/2000\n",
      "1000/1000 [==============================] - 1s 808us/step - loss: 0.0309 - accuracy: 0.9200 - val_loss: 0.0827 - val_accuracy: 0.9250\n",
      "Epoch 544/2000\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0433 - accuracy: 0.9120 - val_loss: 0.0332 - val_accuracy: 0.9250\n",
      "Epoch 545/2000\n",
      "1000/1000 [==============================] - 1s 639us/step - loss: 0.0420 - accuracy: 0.9310 - val_loss: 0.0671 - val_accuracy: 0.9000\n",
      "Epoch 546/2000\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0344 - accuracy: 0.9210 - val_loss: 0.0799 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 547/2000\n",
      "1000/1000 [==============================] - 1s 569us/step - loss: 0.0779 - accuracy: 0.9180 - val_loss: 0.0483 - val_accuracy: 0.9250\n",
      "Epoch 548/2000\n",
      "1000/1000 [==============================] - 1s 573us/step - loss: 0.0383 - accuracy: 0.9310 - val_loss: 0.0885 - val_accuracy: 0.8750\n",
      "Epoch 549/2000\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 0.0470 - accuracy: 0.9330 - val_loss: 0.0893 - val_accuracy: 0.9250\n",
      "Epoch 550/2000\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.0796 - accuracy: 0.9340 - val_loss: 0.0428 - val_accuracy: 0.9500\n",
      "Epoch 551/2000\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0399 - accuracy: 0.9260 - val_loss: 0.0490 - val_accuracy: 0.8750\n",
      "Epoch 552/2000\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0342 - accuracy: 0.9210 - val_loss: 0.0998 - val_accuracy: 0.9000\n",
      "Epoch 553/2000\n",
      "1000/1000 [==============================] - 1s 573us/step - loss: 0.0338 - accuracy: 0.9300 - val_loss: 0.0633 - val_accuracy: 0.9000\n",
      "Epoch 554/2000\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0355 - accuracy: 0.9190 - val_loss: 0.0295 - val_accuracy: 0.8750\n",
      "Epoch 555/2000\n",
      "1000/1000 [==============================] - 1s 655us/step - loss: 0.0836 - accuracy: 0.9170 - val_loss: 0.0298 - val_accuracy: 0.9250\n",
      "Epoch 556/2000\n",
      "1000/1000 [==============================] - 1s 656us/step - loss: 0.0322 - accuracy: 0.9340 - val_loss: 0.0527 - val_accuracy: 0.9000\n",
      "Epoch 557/2000\n",
      "1000/1000 [==============================] - 1s 618us/step - loss: 0.0292 - accuracy: 0.9200 - val_loss: 0.0648 - val_accuracy: 0.9500\n",
      "Epoch 558/2000\n",
      "1000/1000 [==============================] - 1s 742us/step - loss: 0.0334 - accuracy: 0.9320 - val_loss: 0.0434 - val_accuracy: 0.9500\n",
      "Epoch 559/2000\n",
      "1000/1000 [==============================] - 1s 631us/step - loss: 0.0316 - accuracy: 0.9320 - val_loss: 0.0379 - val_accuracy: 0.8750\n",
      "Epoch 560/2000\n",
      "1000/1000 [==============================] - 1s 697us/step - loss: 0.0375 - accuracy: 0.9320 - val_loss: 0.0496 - val_accuracy: 0.9250\n",
      "Epoch 561/2000\n",
      "1000/1000 [==============================] - 1s 732us/step - loss: 0.0310 - accuracy: 0.9430 - val_loss: 0.0843 - val_accuracy: 0.9250\n",
      "Epoch 562/2000\n",
      "1000/1000 [==============================] - 1s 637us/step - loss: 0.0297 - accuracy: 0.9200 - val_loss: 0.0335 - val_accuracy: 0.9500\n",
      "Epoch 563/2000\n",
      "1000/1000 [==============================] - 1s 662us/step - loss: 0.0308 - accuracy: 0.9270 - val_loss: 0.0870 - val_accuracy: 0.9000\n",
      "Epoch 564/2000\n",
      "1000/1000 [==============================] - 1s 679us/step - loss: 0.0397 - accuracy: 0.9290 - val_loss: 0.0627 - val_accuracy: 0.9000\n",
      "Epoch 565/2000\n",
      "1000/1000 [==============================] - 1s 638us/step - loss: 0.0397 - accuracy: 0.9310 - val_loss: 0.0555 - val_accuracy: 0.9250\n",
      "Epoch 566/2000\n",
      "1000/1000 [==============================] - 1s 627us/step - loss: 0.0276 - accuracy: 0.9370 - val_loss: 0.0464 - val_accuracy: 0.8750\n",
      "Epoch 567/2000\n",
      "1000/1000 [==============================] - 1s 624us/step - loss: 0.0312 - accuracy: 0.9290 - val_loss: 0.0404 - val_accuracy: 0.9000\n",
      "Epoch 568/2000\n",
      "1000/1000 [==============================] - 1s 634us/step - loss: 0.0279 - accuracy: 0.9370 - val_loss: 0.0305 - val_accuracy: 0.9000\n",
      "Epoch 569/2000\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0340 - accuracy: 0.9260 - val_loss: 0.0372 - val_accuracy: 0.9500\n",
      "Epoch 570/2000\n",
      "1000/1000 [==============================] - 1s 617us/step - loss: 0.0345 - accuracy: 0.9340 - val_loss: 0.0334 - val_accuracy: 0.9000\n",
      "Epoch 571/2000\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0326 - accuracy: 0.9220 - val_loss: 0.0269 - val_accuracy: 0.9500\n",
      "Epoch 572/2000\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0252 - accuracy: 0.9350 - val_loss: 0.0413 - val_accuracy: 0.9250\n",
      "Epoch 573/2000\n",
      "1000/1000 [==============================] - 1s 599us/step - loss: 0.0278 - accuracy: 0.9260 - val_loss: 0.0250 - val_accuracy: 0.9000\n",
      "Epoch 574/2000\n",
      "1000/1000 [==============================] - 1s 617us/step - loss: 0.0318 - accuracy: 0.9320 - val_loss: 0.0231 - val_accuracy: 0.9000\n",
      "Epoch 575/2000\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0286 - accuracy: 0.9230 - val_loss: 0.0790 - val_accuracy: 0.9250\n",
      "Epoch 576/2000\n",
      "1000/1000 [==============================] - 1s 577us/step - loss: 0.0348 - accuracy: 0.9290 - val_loss: 0.0543 - val_accuracy: 0.8750\n",
      "Epoch 577/2000\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0254 - accuracy: 0.9390 - val_loss: 0.0530 - val_accuracy: 0.9000\n",
      "Epoch 578/2000\n",
      "1000/1000 [==============================] - 1s 648us/step - loss: 0.0238 - accuracy: 0.9360 - val_loss: 0.0253 - val_accuracy: 0.9500\n",
      "Epoch 579/2000\n",
      "1000/1000 [==============================] - 1s 667us/step - loss: 0.0416 - accuracy: 0.9360 - val_loss: 0.0384 - val_accuracy: 0.9000\n",
      "Epoch 580/2000\n",
      "1000/1000 [==============================] - 1s 635us/step - loss: 0.0257 - accuracy: 0.9250 - val_loss: 0.0452 - val_accuracy: 0.9250\n",
      "Epoch 581/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0219 - accuracy: 0.9320 - val_loss: 0.0708 - val_accuracy: 0.9000\n",
      "Epoch 582/2000\n",
      "1000/1000 [==============================] - 1s 577us/step - loss: 0.0341 - accuracy: 0.9300 - val_loss: 0.0620 - val_accuracy: 0.9250\n",
      "Epoch 583/2000\n",
      "1000/1000 [==============================] - 1s 610us/step - loss: 0.0310 - accuracy: 0.9470 - val_loss: 0.0376 - val_accuracy: 0.9000\n",
      "Epoch 584/2000\n",
      "1000/1000 [==============================] - 1s 552us/step - loss: 0.0483 - accuracy: 0.9330 - val_loss: 0.2666 - val_accuracy: 0.9000\n",
      "Epoch 585/2000\n",
      "1000/1000 [==============================] - 1s 569us/step - loss: 0.0282 - accuracy: 0.9390 - val_loss: 0.0500 - val_accuracy: 0.9500\n",
      "Epoch 586/2000\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0341 - accuracy: 0.9190 - val_loss: 0.0478 - val_accuracy: 0.9500\n",
      "Epoch 587/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0419 - accuracy: 0.9370 - val_loss: 0.1639 - val_accuracy: 0.9000\n",
      "Epoch 588/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.0350 - accuracy: 0.9240 - val_loss: 0.0370 - val_accuracy: 0.9250\n",
      "Epoch 589/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0341 - accuracy: 0.9270 - val_loss: 0.0392 - val_accuracy: 0.9500\n",
      "Epoch 590/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.0256 - accuracy: 0.9330 - val_loss: 0.0488 - val_accuracy: 0.9500\n",
      "Epoch 591/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0372 - accuracy: 0.9330 - val_loss: 0.0201 - val_accuracy: 0.9250\n",
      "Epoch 592/2000\n",
      "1000/1000 [==============================] - 1s 503us/step - loss: 0.0279 - accuracy: 0.9320 - val_loss: 0.0317 - val_accuracy: 0.9250\n",
      "Epoch 593/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0471 - accuracy: 0.9370 - val_loss: 0.0759 - val_accuracy: 0.9000\n",
      "Epoch 594/2000\n",
      "1000/1000 [==============================] - 1s 564us/step - loss: 0.0365 - accuracy: 0.9280 - val_loss: 0.0428 - val_accuracy: 0.9250\n",
      "Epoch 595/2000\n",
      "1000/1000 [==============================] - 1s 543us/step - loss: 0.0349 - accuracy: 0.9400 - val_loss: 0.0823 - val_accuracy: 0.9250\n",
      "Epoch 596/2000\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 0.0312 - accuracy: 0.9430 - val_loss: 0.0344 - val_accuracy: 0.9500\n",
      "Epoch 597/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0219 - accuracy: 0.9390 - val_loss: 0.0409 - val_accuracy: 0.9000\n",
      "Epoch 598/2000\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0260 - accuracy: 0.9280 - val_loss: 0.0277 - val_accuracy: 0.9500\n",
      "Epoch 599/2000\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0536 - accuracy: 0.9120 - val_loss: 0.0628 - val_accuracy: 0.8750\n",
      "Epoch 600/2000\n",
      "1000/1000 [==============================] - 1s 571us/step - loss: 0.0284 - accuracy: 0.9130 - val_loss: 0.0514 - val_accuracy: 0.9250\n",
      "Epoch 601/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 544us/step - loss: 0.0262 - accuracy: 0.9350 - val_loss: 0.0645 - val_accuracy: 0.9250\n",
      "Epoch 602/2000\n",
      "1000/1000 [==============================] - 1s 505us/step - loss: 0.0225 - accuracy: 0.9320 - val_loss: 0.0300 - val_accuracy: 0.9750\n",
      "Epoch 603/2000\n",
      "1000/1000 [==============================] - 1s 572us/step - loss: 0.0199 - accuracy: 0.9370 - val_loss: 0.0349 - val_accuracy: 0.9500\n",
      "Epoch 604/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0276 - accuracy: 0.9330 - val_loss: 0.0292 - val_accuracy: 0.9500\n",
      "Epoch 605/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0415 - accuracy: 0.9240 - val_loss: 0.0501 - val_accuracy: 0.9250\n",
      "Epoch 606/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0228 - accuracy: 0.9380 - val_loss: 0.0670 - val_accuracy: 0.8250\n",
      "Epoch 607/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.0204 - accuracy: 0.9420 - val_loss: 0.0382 - val_accuracy: 0.9000\n",
      "Epoch 608/2000\n",
      "1000/1000 [==============================] - 1s 505us/step - loss: 0.0254 - accuracy: 0.9410 - val_loss: 0.0358 - val_accuracy: 0.9250\n",
      "Epoch 609/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0250 - accuracy: 0.9420 - val_loss: 0.0454 - val_accuracy: 0.9000\n",
      "Epoch 610/2000\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 0.0332 - accuracy: 0.9320 - val_loss: 0.0369 - val_accuracy: 0.9250\n",
      "Epoch 611/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0238 - accuracy: 0.9220 - val_loss: 0.0388 - val_accuracy: 0.9250\n",
      "Epoch 612/2000\n",
      "1000/1000 [==============================] - 1s 599us/step - loss: 0.0359 - accuracy: 0.9180 - val_loss: 0.0429 - val_accuracy: 0.9000\n",
      "Epoch 613/2000\n",
      "1000/1000 [==============================] - 1s 544us/step - loss: 0.0221 - accuracy: 0.9310 - val_loss: 0.1110 - val_accuracy: 0.9250\n",
      "Epoch 614/2000\n",
      "1000/1000 [==============================] - 1s 576us/step - loss: 0.0344 - accuracy: 0.9330 - val_loss: 0.0417 - val_accuracy: 0.8750\n",
      "Epoch 615/2000\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0314 - accuracy: 0.9370 - val_loss: 0.0830 - val_accuracy: 0.8750\n",
      "Epoch 616/2000\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0291 - accuracy: 0.9280 - val_loss: 0.0467 - val_accuracy: 0.9000\n",
      "Epoch 617/2000\n",
      "1000/1000 [==============================] - 1s 567us/step - loss: 0.0316 - accuracy: 0.9250 - val_loss: 0.0533 - val_accuracy: 0.8750\n",
      "Epoch 618/2000\n",
      "1000/1000 [==============================] - 1s 568us/step - loss: 0.0273 - accuracy: 0.9250 - val_loss: 0.0832 - val_accuracy: 0.9250\n",
      "Epoch 619/2000\n",
      "1000/1000 [==============================] - 1s 503us/step - loss: 0.0427 - accuracy: 0.9360 - val_loss: 0.0781 - val_accuracy: 0.9000\n",
      "Epoch 620/2000\n",
      "1000/1000 [==============================] - 1s 503us/step - loss: 0.0236 - accuracy: 0.9370 - val_loss: 0.0355 - val_accuracy: 0.9000\n",
      "Epoch 621/2000\n",
      "1000/1000 [==============================] - 1s 526us/step - loss: 0.0289 - accuracy: 0.9190 - val_loss: 0.0383 - val_accuracy: 0.9500\n",
      "Epoch 622/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0290 - accuracy: 0.9210 - val_loss: 0.0363 - val_accuracy: 0.9000\n",
      "Epoch 623/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.0303 - accuracy: 0.9300 - val_loss: 0.0356 - val_accuracy: 0.9000\n",
      "Epoch 624/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0343 - accuracy: 0.9210 - val_loss: 0.0536 - val_accuracy: 0.9000\n",
      "Epoch 625/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0334 - accuracy: 0.9380 - val_loss: 0.0544 - val_accuracy: 0.9000\n",
      "Epoch 626/2000\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.0217 - accuracy: 0.9350 - val_loss: 0.0437 - val_accuracy: 0.9000\n",
      "Epoch 627/2000\n",
      "1000/1000 [==============================] - 1s 507us/step - loss: 0.0449 - accuracy: 0.9190 - val_loss: 0.0535 - val_accuracy: 0.8750\n",
      "Epoch 628/2000\n",
      "1000/1000 [==============================] - 1s 505us/step - loss: 0.0281 - accuracy: 0.9300 - val_loss: 0.0532 - val_accuracy: 0.9000\n",
      "Epoch 629/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0306 - accuracy: 0.9270 - val_loss: 0.0444 - val_accuracy: 0.9000\n",
      "Epoch 630/2000\n",
      "1000/1000 [==============================] - 1s 543us/step - loss: 0.0238 - accuracy: 0.9310 - val_loss: 0.0347 - val_accuracy: 0.9000\n",
      "Epoch 631/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0246 - accuracy: 0.9310 - val_loss: 0.0512 - val_accuracy: 0.9750\n",
      "Epoch 632/2000\n",
      "1000/1000 [==============================] - 1s 570us/step - loss: 0.0197 - accuracy: 0.9460 - val_loss: 0.0253 - val_accuracy: 0.9250\n",
      "Epoch 633/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0243 - accuracy: 0.9270 - val_loss: 0.0319 - val_accuracy: 0.9500\n",
      "Epoch 634/2000\n",
      "1000/1000 [==============================] - 1s 504us/step - loss: 0.0226 - accuracy: 0.9460 - val_loss: 0.0410 - val_accuracy: 0.9500\n",
      "Epoch 635/2000\n",
      "1000/1000 [==============================] - 1s 506us/step - loss: 0.0376 - accuracy: 0.9430 - val_loss: 0.0373 - val_accuracy: 0.9250\n",
      "Epoch 636/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0303 - accuracy: 0.9380 - val_loss: 0.0295 - val_accuracy: 0.9500\n",
      "Epoch 637/2000\n",
      "1000/1000 [==============================] - 1s 543us/step - loss: 0.0401 - accuracy: 0.9320 - val_loss: 0.0638 - val_accuracy: 0.9250\n",
      "Epoch 638/2000\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0240 - accuracy: 0.9460 - val_loss: 0.0356 - val_accuracy: 0.9500\n",
      "Epoch 639/2000\n",
      "1000/1000 [==============================] - 1s 579us/step - loss: 0.0330 - accuracy: 0.9270 - val_loss: 0.0338 - val_accuracy: 0.9500\n",
      "Epoch 640/2000\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0354 - accuracy: 0.9340 - val_loss: 0.0544 - val_accuracy: 0.9250\n",
      "Epoch 641/2000\n",
      "1000/1000 [==============================] - 1s 626us/step - loss: 0.0199 - accuracy: 0.9300 - val_loss: 0.0409 - val_accuracy: 0.9000\n",
      "Epoch 642/2000\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0292 - accuracy: 0.9320 - val_loss: 0.0232 - val_accuracy: 0.9750\n",
      "Epoch 643/2000\n",
      "1000/1000 [==============================] - 1s 624us/step - loss: 0.0248 - accuracy: 0.9350 - val_loss: 0.0616 - val_accuracy: 0.9500\n",
      "Epoch 644/2000\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0283 - accuracy: 0.9420 - val_loss: 0.0440 - val_accuracy: 0.9000\n",
      "Epoch 645/2000\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 0.0284 - accuracy: 0.9380 - val_loss: 0.0399 - val_accuracy: 0.9000\n",
      "Epoch 646/2000\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.0197 - accuracy: 0.9260 - val_loss: 0.0210 - val_accuracy: 0.9000\n",
      "Epoch 647/2000\n",
      "1000/1000 [==============================] - 1s 507us/step - loss: 0.0332 - accuracy: 0.9370 - val_loss: 0.0309 - val_accuracy: 0.9250\n",
      "Epoch 648/2000\n",
      "1000/1000 [==============================] - 1s 506us/step - loss: 0.0230 - accuracy: 0.9430 - val_loss: 0.0218 - val_accuracy: 0.9500\n",
      "Epoch 649/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0355 - accuracy: 0.9290 - val_loss: 0.1199 - val_accuracy: 0.8750\n",
      "Epoch 650/2000\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 0.0348 - accuracy: 0.9200 - val_loss: 0.0804 - val_accuracy: 0.9250\n",
      "Epoch 651/2000\n",
      "1000/1000 [==============================] - 1s 556us/step - loss: 0.0301 - accuracy: 0.9360 - val_loss: 0.0244 - val_accuracy: 0.9750\n",
      "Epoch 652/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0433 - accuracy: 0.9310 - val_loss: 0.0248 - val_accuracy: 0.9000\n",
      "Epoch 653/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0205 - accuracy: 0.9420 - val_loss: 0.0269 - val_accuracy: 0.9500\n",
      "Epoch 654/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.0191 - accuracy: 0.9450 - val_loss: 0.0294 - val_accuracy: 0.9000\n",
      "Epoch 655/2000\n",
      "1000/1000 [==============================] - 1s 559us/step - loss: 0.0259 - accuracy: 0.9260 - val_loss: 0.0806 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 656/2000\n",
      "1000/1000 [==============================] - 1s 552us/step - loss: 0.0252 - accuracy: 0.9300 - val_loss: 0.0178 - val_accuracy: 0.9250\n",
      "Epoch 657/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0270 - accuracy: 0.9320 - val_loss: 0.0615 - val_accuracy: 0.9500\n",
      "Epoch 658/2000\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0447 - accuracy: 0.9290 - val_loss: 0.0791 - val_accuracy: 0.9250\n",
      "Epoch 659/2000\n",
      "1000/1000 [==============================] - 1s 507us/step - loss: 0.0273 - accuracy: 0.9290 - val_loss: 0.0597 - val_accuracy: 0.9250\n",
      "Epoch 660/2000\n",
      "1000/1000 [==============================] - 1s 507us/step - loss: 0.0325 - accuracy: 0.9300 - val_loss: 0.0503 - val_accuracy: 0.9000\n",
      "Epoch 661/2000\n",
      "1000/1000 [==============================] - 1s 504us/step - loss: 0.0266 - accuracy: 0.9270 - val_loss: 0.0671 - val_accuracy: 0.9250\n",
      "Epoch 662/2000\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0306 - accuracy: 0.9300 - val_loss: 0.0330 - val_accuracy: 0.9500\n",
      "Epoch 663/2000\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0289 - accuracy: 0.9320 - val_loss: 0.0732 - val_accuracy: 0.9250\n",
      "Epoch 664/2000\n",
      "1000/1000 [==============================] - 1s 507us/step - loss: 0.0287 - accuracy: 0.9400 - val_loss: 0.0370 - val_accuracy: 0.9000\n",
      "Epoch 665/2000\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 0.0248 - accuracy: 0.9280 - val_loss: 0.0763 - val_accuracy: 0.9250\n",
      "Epoch 666/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0243 - accuracy: 0.9470 - val_loss: 0.0222 - val_accuracy: 0.9500\n",
      "Epoch 667/2000\n",
      "1000/1000 [==============================] - 1s 507us/step - loss: 0.0254 - accuracy: 0.9360 - val_loss: 0.0370 - val_accuracy: 0.9000\n",
      "Epoch 668/2000\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.0370 - accuracy: 0.9300 - val_loss: 0.0594 - val_accuracy: 0.9250\n",
      "Epoch 669/2000\n",
      "1000/1000 [==============================] - 1s 510us/step - loss: 0.0214 - accuracy: 0.9430 - val_loss: 0.0413 - val_accuracy: 0.8750\n",
      "Epoch 670/2000\n",
      "1000/1000 [==============================] - 1s 504us/step - loss: 0.0258 - accuracy: 0.9330 - val_loss: 0.0520 - val_accuracy: 0.8750\n",
      "Epoch 671/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0307 - accuracy: 0.9250 - val_loss: 0.0342 - val_accuracy: 0.9250\n",
      "Epoch 672/2000\n",
      "1000/1000 [==============================] - 1s 560us/step - loss: 0.0381 - accuracy: 0.9380 - val_loss: 0.0317 - val_accuracy: 0.9250\n",
      "Epoch 673/2000\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 0.0260 - accuracy: 0.9360 - val_loss: 0.0325 - val_accuracy: 0.9250\n",
      "Epoch 674/2000\n",
      "1000/1000 [==============================] - 1s 560us/step - loss: 0.0172 - accuracy: 0.9340 - val_loss: 0.0743 - val_accuracy: 0.9000\n",
      "Epoch 675/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0233 - accuracy: 0.9390 - val_loss: 0.0892 - val_accuracy: 0.9000\n",
      "Epoch 676/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0274 - accuracy: 0.9350 - val_loss: 0.1117 - val_accuracy: 0.8500\n",
      "Epoch 677/2000\n",
      "1000/1000 [==============================] - 1s 562us/step - loss: 0.0328 - accuracy: 0.9460 - val_loss: 0.0301 - val_accuracy: 0.9500\n",
      "Epoch 678/2000\n",
      "1000/1000 [==============================] - 1s 574us/step - loss: 0.0290 - accuracy: 0.9330 - val_loss: 0.0260 - val_accuracy: 0.9250\n",
      "Epoch 679/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0286 - accuracy: 0.9360 - val_loss: 0.0709 - val_accuracy: 0.9250\n",
      "Epoch 680/2000\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.0306 - accuracy: 0.9420 - val_loss: 0.0213 - val_accuracy: 0.9000\n",
      "Epoch 681/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0263 - accuracy: 0.9470 - val_loss: 0.0579 - val_accuracy: 0.9250\n",
      "Epoch 682/2000\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 0.0243 - accuracy: 0.9410 - val_loss: 0.0348 - val_accuracy: 0.9500\n",
      "Epoch 683/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0231 - accuracy: 0.9450 - val_loss: 0.1386 - val_accuracy: 0.9250\n",
      "Epoch 684/2000\n",
      "1000/1000 [==============================] - 1s 525us/step - loss: 0.0327 - accuracy: 0.9410 - val_loss: 0.0453 - val_accuracy: 0.9250\n",
      "Epoch 685/2000\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.0219 - accuracy: 0.9400 - val_loss: 0.0773 - val_accuracy: 0.9000\n",
      "Epoch 686/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0247 - accuracy: 0.9320 - val_loss: 0.0362 - val_accuracy: 0.9500\n",
      "Epoch 687/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0403 - accuracy: 0.9360 - val_loss: 0.0298 - val_accuracy: 0.9500\n",
      "Epoch 688/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0282 - accuracy: 0.9410 - val_loss: 0.0966 - val_accuracy: 0.9000\n",
      "Epoch 689/2000\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0321 - accuracy: 0.9350 - val_loss: 0.0441 - val_accuracy: 0.9250\n",
      "Epoch 690/2000\n",
      "1000/1000 [==============================] - 1s 555us/step - loss: 0.0309 - accuracy: 0.9430 - val_loss: 0.0473 - val_accuracy: 0.9250\n",
      "Epoch 691/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0190 - accuracy: 0.9440 - val_loss: 0.0509 - val_accuracy: 0.9750\n",
      "Epoch 692/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0218 - accuracy: 0.9370 - val_loss: 0.0639 - val_accuracy: 0.9000\n",
      "Epoch 693/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0263 - accuracy: 0.9370 - val_loss: 0.0902 - val_accuracy: 0.9500\n",
      "Epoch 694/2000\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 0.0203 - accuracy: 0.9490 - val_loss: 0.0449 - val_accuracy: 0.9000\n",
      "Epoch 695/2000\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 0.0212 - accuracy: 0.9520 - val_loss: 0.0437 - val_accuracy: 0.9250\n",
      "Epoch 696/2000\n",
      "1000/1000 [==============================] - 1s 534us/step - loss: 0.0270 - accuracy: 0.9350 - val_loss: 0.0583 - val_accuracy: 0.9000\n",
      "Epoch 697/2000\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 0.0250 - accuracy: 0.9470 - val_loss: 0.0567 - val_accuracy: 0.9000\n",
      "Epoch 698/2000\n",
      "1000/1000 [==============================] - 1s 533us/step - loss: 0.0356 - accuracy: 0.9350 - val_loss: 0.0262 - val_accuracy: 0.9250\n",
      "Epoch 699/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0305 - accuracy: 0.9300 - val_loss: 0.0443 - val_accuracy: 0.9250\n",
      "Epoch 700/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.0268 - accuracy: 0.9420 - val_loss: 0.0394 - val_accuracy: 0.9000\n",
      "Epoch 701/2000\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0312 - accuracy: 0.9460 - val_loss: 0.0581 - val_accuracy: 0.9000\n",
      "Epoch 702/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0230 - accuracy: 0.9480 - val_loss: 0.0493 - val_accuracy: 0.9250\n",
      "Epoch 703/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0267 - accuracy: 0.9360 - val_loss: 0.0507 - val_accuracy: 0.8750\n",
      "Epoch 704/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0208 - accuracy: 0.9460 - val_loss: 0.0339 - val_accuracy: 0.9250\n",
      "Epoch 705/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0185 - accuracy: 0.9480 - val_loss: 0.0235 - val_accuracy: 0.9000\n",
      "Epoch 706/2000\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0281 - accuracy: 0.9310 - val_loss: 0.0269 - val_accuracy: 0.9250\n",
      "Epoch 707/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0302 - accuracy: 0.9340 - val_loss: 0.0365 - val_accuracy: 0.9250\n",
      "Epoch 708/2000\n",
      "1000/1000 [==============================] - 1s 531us/step - loss: 0.0314 - accuracy: 0.9200 - val_loss: 0.0346 - val_accuracy: 0.9500\n",
      "Epoch 709/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0312 - accuracy: 0.9420 - val_loss: 0.0359 - val_accuracy: 0.8500\n",
      "Epoch 710/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.0282 - accuracy: 0.9300 - val_loss: 0.0780 - val_accuracy: 0.9000\n",
      "Epoch 711/2000\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 0.0343 - accuracy: 0.9410 - val_loss: 0.0484 - val_accuracy: 0.9000\n",
      "Epoch 712/2000\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 0.0285 - accuracy: 0.9400 - val_loss: 0.0708 - val_accuracy: 0.9000\n",
      "Epoch 713/2000\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0197 - accuracy: 0.9450 - val_loss: 0.0494 - val_accuracy: 0.9000\n",
      "Epoch 714/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0207 - accuracy: 0.9390 - val_loss: 0.0340 - val_accuracy: 0.9000\n",
      "Epoch 715/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0201 - accuracy: 0.9480 - val_loss: 0.0350 - val_accuracy: 0.8750\n",
      "Epoch 716/2000\n",
      "1000/1000 [==============================] - 1s 526us/step - loss: 0.0208 - accuracy: 0.9260 - val_loss: 0.0441 - val_accuracy: 0.8750\n",
      "Epoch 717/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0230 - accuracy: 0.9350 - val_loss: 0.0292 - val_accuracy: 0.9500\n",
      "Epoch 718/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0220 - accuracy: 0.9420 - val_loss: 0.0266 - val_accuracy: 0.9250\n",
      "Epoch 719/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0413 - accuracy: 0.9310 - val_loss: 0.0456 - val_accuracy: 0.8750\n",
      "Epoch 720/2000\n",
      "1000/1000 [==============================] - 1s 526us/step - loss: 0.0199 - accuracy: 0.9250 - val_loss: 0.0346 - val_accuracy: 0.9500\n",
      "Epoch 721/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0337 - accuracy: 0.9380 - val_loss: 0.0676 - val_accuracy: 0.9000\n",
      "Epoch 722/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0377 - accuracy: 0.9290 - val_loss: 0.1013 - val_accuracy: 0.9000\n",
      "Epoch 723/2000\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 0.0313 - accuracy: 0.9350 - val_loss: 0.0285 - val_accuracy: 0.9250\n",
      "Epoch 724/2000\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 0.0232 - accuracy: 0.9300 - val_loss: 0.0350 - val_accuracy: 0.9500\n",
      "Epoch 725/2000\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 0.0313 - accuracy: 0.9390 - val_loss: 0.0628 - val_accuracy: 0.8750\n",
      "Epoch 726/2000\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 0.0187 - accuracy: 0.9270 - val_loss: 0.0253 - val_accuracy: 0.9000\n",
      "Epoch 727/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0197 - accuracy: 0.9330 - val_loss: 0.0566 - val_accuracy: 0.9000\n",
      "Epoch 728/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0269 - accuracy: 0.9320 - val_loss: 0.0362 - val_accuracy: 0.9000\n",
      "Epoch 729/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0254 - accuracy: 0.9330 - val_loss: 0.0260 - val_accuracy: 0.9000\n",
      "Epoch 730/2000\n",
      "1000/1000 [==============================] - 1s 533us/step - loss: 0.0169 - accuracy: 0.9270 - val_loss: 0.0527 - val_accuracy: 0.9000\n",
      "Epoch 731/2000\n",
      "1000/1000 [==============================] - 1s 533us/step - loss: 0.0267 - accuracy: 0.9330 - val_loss: 0.0379 - val_accuracy: 0.8750\n",
      "Epoch 732/2000\n",
      "1000/1000 [==============================] - 1s 582us/step - loss: 0.0259 - accuracy: 0.9300 - val_loss: 0.2420 - val_accuracy: 0.9250\n",
      "Epoch 733/2000\n",
      "1000/1000 [==============================] - 1s 533us/step - loss: 0.0266 - accuracy: 0.9380 - val_loss: 0.0329 - val_accuracy: 0.8500\n",
      "Epoch 734/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0191 - accuracy: 0.9240 - val_loss: 0.0771 - val_accuracy: 0.9250\n",
      "Epoch 735/2000\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.0457 - accuracy: 0.9320 - val_loss: 0.1015 - val_accuracy: 0.9000\n",
      "Epoch 736/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0255 - accuracy: 0.9320 - val_loss: 0.0419 - val_accuracy: 0.8750\n",
      "Epoch 737/2000\n",
      "1000/1000 [==============================] - 1s 526us/step - loss: 0.0269 - accuracy: 0.9300 - val_loss: 0.0510 - val_accuracy: 0.8750\n",
      "Epoch 738/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0194 - accuracy: 0.9320 - val_loss: 0.0447 - val_accuracy: 0.9250\n",
      "Epoch 739/2000\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 0.0411 - accuracy: 0.9310 - val_loss: 0.1936 - val_accuracy: 0.9000\n",
      "Epoch 740/2000\n",
      "1000/1000 [==============================] - 1s 506us/step - loss: 0.0319 - accuracy: 0.9210 - val_loss: 0.0516 - val_accuracy: 0.8750\n",
      "Epoch 741/2000\n",
      "1000/1000 [==============================] - 1s 542us/step - loss: 0.0205 - accuracy: 0.9250 - val_loss: 0.0436 - val_accuracy: 0.9500\n",
      "Epoch 742/2000\n",
      "1000/1000 [==============================] - 1s 542us/step - loss: 0.0304 - accuracy: 0.9370 - val_loss: 0.0804 - val_accuracy: 0.9500\n",
      "Epoch 743/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0251 - accuracy: 0.9440 - val_loss: 0.0324 - val_accuracy: 0.9250\n",
      "Epoch 744/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0347 - accuracy: 0.9380 - val_loss: 0.0439 - val_accuracy: 0.9000\n",
      "Epoch 745/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0335 - accuracy: 0.9330 - val_loss: 0.0211 - val_accuracy: 0.9000\n",
      "Epoch 746/2000\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 0.0226 - accuracy: 0.9330 - val_loss: 0.0346 - val_accuracy: 0.9000\n",
      "Epoch 747/2000\n",
      "1000/1000 [==============================] - 1s 529us/step - loss: 0.0351 - accuracy: 0.9290 - val_loss: 0.0438 - val_accuracy: 0.9000\n",
      "Epoch 748/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0320 - accuracy: 0.9370 - val_loss: 0.0563 - val_accuracy: 0.9250\n",
      "Epoch 749/2000\n",
      "1000/1000 [==============================] - 1s 525us/step - loss: 0.0304 - accuracy: 0.9350 - val_loss: 0.0293 - val_accuracy: 0.9000\n",
      "Epoch 750/2000\n",
      "1000/1000 [==============================] - 1s 534us/step - loss: 0.0227 - accuracy: 0.9280 - val_loss: 0.0541 - val_accuracy: 0.8500\n",
      "Epoch 751/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0239 - accuracy: 0.9240 - val_loss: 0.0426 - val_accuracy: 0.8750\n",
      "Epoch 752/2000\n",
      "1000/1000 [==============================] - 1s 562us/step - loss: 0.0236 - accuracy: 0.9310 - val_loss: 0.0245 - val_accuracy: 0.9500\n",
      "Epoch 753/2000\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 0.0228 - accuracy: 0.9400 - val_loss: 0.0354 - val_accuracy: 0.9250\n",
      "Epoch 754/2000\n",
      "1000/1000 [==============================] - 1s 544us/step - loss: 0.0167 - accuracy: 0.9430 - val_loss: 0.0616 - val_accuracy: 0.9000\n",
      "Epoch 755/2000\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 0.0185 - accuracy: 0.9350 - val_loss: 0.0429 - val_accuracy: 0.9250\n",
      "Epoch 756/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.0252 - accuracy: 0.9290 - val_loss: 0.0707 - val_accuracy: 0.9000\n",
      "Epoch 757/2000\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 0.0194 - accuracy: 0.9320 - val_loss: 0.0355 - val_accuracy: 0.9000\n",
      "Epoch 758/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.0239 - accuracy: 0.9270 - val_loss: 0.0409 - val_accuracy: 0.9000\n",
      "Epoch 759/2000\n",
      "1000/1000 [==============================] - 1s 523us/step - loss: 0.0283 - accuracy: 0.9470 - val_loss: 0.0449 - val_accuracy: 0.9250\n",
      "Epoch 760/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0287 - accuracy: 0.9390 - val_loss: 0.0198 - val_accuracy: 0.9000\n",
      "Epoch 761/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0238 - accuracy: 0.9370 - val_loss: 0.1216 - val_accuracy: 0.9000\n",
      "Epoch 762/2000\n",
      "1000/1000 [==============================] - 1s 523us/step - loss: 0.0315 - accuracy: 0.9360 - val_loss: 0.0279 - val_accuracy: 0.9250\n",
      "Epoch 763/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.0330 - accuracy: 0.9260 - val_loss: 0.0445 - val_accuracy: 0.9250\n",
      "Epoch 764/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0257 - accuracy: 0.9330 - val_loss: 0.0197 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 765/2000\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 0.0270 - accuracy: 0.9430 - val_loss: 0.0247 - val_accuracy: 0.9500\n",
      "Epoch 766/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.0200 - accuracy: 0.9270 - val_loss: 0.0268 - val_accuracy: 0.9250\n",
      "Epoch 767/2000\n",
      "1000/1000 [==============================] - 1s 510us/step - loss: 0.0228 - accuracy: 0.9420 - val_loss: 0.0377 - val_accuracy: 0.9000\n",
      "Epoch 768/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.0324 - accuracy: 0.9330 - val_loss: 0.0464 - val_accuracy: 0.9250\n",
      "Epoch 769/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0204 - accuracy: 0.9380 - val_loss: 0.0810 - val_accuracy: 0.9250\n",
      "Epoch 770/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0277 - accuracy: 0.9400 - val_loss: 0.0407 - val_accuracy: 0.9000\n",
      "Epoch 771/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0179 - accuracy: 0.9320 - val_loss: 0.0436 - val_accuracy: 0.9250\n",
      "Epoch 772/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0460 - accuracy: 0.9360 - val_loss: 0.0318 - val_accuracy: 0.9000\n",
      "Epoch 773/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0261 - accuracy: 0.9360 - val_loss: 0.0795 - val_accuracy: 0.9000\n",
      "Epoch 774/2000\n",
      "1000/1000 [==============================] - 1s 526us/step - loss: 0.0210 - accuracy: 0.9470 - val_loss: 0.0242 - val_accuracy: 0.8750\n",
      "Epoch 775/2000\n",
      "1000/1000 [==============================] - 1s 502us/step - loss: 0.0304 - accuracy: 0.9310 - val_loss: 0.0253 - val_accuracy: 0.9250\n",
      "Epoch 776/2000\n",
      "1000/1000 [==============================] - 1s 529us/step - loss: 0.0186 - accuracy: 0.9360 - val_loss: 0.0223 - val_accuracy: 0.9250\n",
      "Epoch 777/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0255 - accuracy: 0.9380 - val_loss: 0.2571 - val_accuracy: 0.9250\n",
      "Epoch 778/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0221 - accuracy: 0.9390 - val_loss: 0.0774 - val_accuracy: 0.9250\n",
      "Epoch 779/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.0287 - accuracy: 0.9390 - val_loss: 0.0380 - val_accuracy: 0.9250\n",
      "Epoch 780/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0281 - accuracy: 0.9450 - val_loss: 0.0388 - val_accuracy: 0.8750\n",
      "Epoch 781/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0350 - accuracy: 0.9260 - val_loss: 0.0285 - val_accuracy: 0.8750\n",
      "Epoch 782/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0363 - accuracy: 0.9390 - val_loss: 0.0584 - val_accuracy: 0.9250\n",
      "Epoch 783/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.0230 - accuracy: 0.9510 - val_loss: 0.0242 - val_accuracy: 0.9250\n",
      "Epoch 784/2000\n",
      "1000/1000 [==============================] - 1s 530us/step - loss: 0.0339 - accuracy: 0.9470 - val_loss: 0.0329 - val_accuracy: 0.9000\n",
      "Epoch 785/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0429 - accuracy: 0.9130 - val_loss: 0.0355 - val_accuracy: 0.9500\n",
      "Epoch 786/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0215 - accuracy: 0.9330 - val_loss: 0.0536 - val_accuracy: 0.9250\n",
      "Epoch 787/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0222 - accuracy: 0.9470 - val_loss: 0.0564 - val_accuracy: 0.8500\n",
      "Epoch 788/2000\n",
      "1000/1000 [==============================] - 1s 502us/step - loss: 0.0363 - accuracy: 0.9320 - val_loss: 0.0489 - val_accuracy: 0.9000\n",
      "Epoch 789/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.0354 - accuracy: 0.9270 - val_loss: 0.0263 - val_accuracy: 0.9250\n",
      "Epoch 790/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0245 - accuracy: 0.9360 - val_loss: 0.0370 - val_accuracy: 0.9000\n",
      "Epoch 791/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0212 - accuracy: 0.9390 - val_loss: 0.0195 - val_accuracy: 0.9250\n",
      "Epoch 792/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0347 - accuracy: 0.9380 - val_loss: 0.0773 - val_accuracy: 0.9500\n",
      "Epoch 793/2000\n",
      "1000/1000 [==============================] - 1s 526us/step - loss: 0.0223 - accuracy: 0.9360 - val_loss: 0.0347 - val_accuracy: 0.9000\n",
      "Epoch 794/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0224 - accuracy: 0.9390 - val_loss: 0.0524 - val_accuracy: 0.9000\n",
      "Epoch 795/2000\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 0.0169 - accuracy: 0.9360 - val_loss: 0.0190 - val_accuracy: 0.9500\n",
      "Epoch 796/2000\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 0.0193 - accuracy: 0.9370 - val_loss: 0.0183 - val_accuracy: 0.9000\n",
      "Epoch 797/2000\n",
      "1000/1000 [==============================] - 1s 556us/step - loss: 0.0309 - accuracy: 0.9330 - val_loss: 0.0484 - val_accuracy: 0.9250\n",
      "Epoch 798/2000\n",
      "1000/1000 [==============================] - 1s 632us/step - loss: 0.0178 - accuracy: 0.9390 - val_loss: 0.0567 - val_accuracy: 0.9250\n",
      "Epoch 799/2000\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0222 - accuracy: 0.9340 - val_loss: 0.1053 - val_accuracy: 0.8750\n",
      "Epoch 800/2000\n",
      "1000/1000 [==============================] - 1s 611us/step - loss: 0.0245 - accuracy: 0.9470 - val_loss: 0.0529 - val_accuracy: 0.9250\n",
      "Epoch 801/2000\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0358 - accuracy: 0.9360 - val_loss: 0.1250 - val_accuracy: 0.9500\n",
      "Epoch 802/2000\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0213 - accuracy: 0.9480 - val_loss: 0.0400 - val_accuracy: 0.9750\n",
      "Epoch 803/2000\n",
      "1000/1000 [==============================] - 1s 609us/step - loss: 0.0193 - accuracy: 0.9340 - val_loss: 0.0267 - val_accuracy: 0.9250\n",
      "Epoch 804/2000\n",
      "1000/1000 [==============================] - 1s 580us/step - loss: 0.0213 - accuracy: 0.9300 - val_loss: 0.0344 - val_accuracy: 0.9000\n",
      "Epoch 805/2000\n",
      "1000/1000 [==============================] - 1s 614us/step - loss: 0.0265 - accuracy: 0.9430 - val_loss: 0.0231 - val_accuracy: 0.9000\n",
      "Epoch 806/2000\n",
      "1000/1000 [==============================] - 1s 643us/step - loss: 0.0279 - accuracy: 0.9470 - val_loss: 0.0267 - val_accuracy: 0.9250\n",
      "Epoch 807/2000\n",
      "1000/1000 [==============================] - 1s 612us/step - loss: 0.0185 - accuracy: 0.9370 - val_loss: 0.0166 - val_accuracy: 0.9500\n",
      "Epoch 808/2000\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0181 - accuracy: 0.9530 - val_loss: 0.0265 - val_accuracy: 0.9250\n",
      "Epoch 809/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0540 - accuracy: 0.9320 - val_loss: 0.0375 - val_accuracy: 0.9000\n",
      "Epoch 810/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0223 - accuracy: 0.9400 - val_loss: 0.0363 - val_accuracy: 0.9250\n",
      "Epoch 811/2000\n",
      "1000/1000 [==============================] - 1s 529us/step - loss: 0.0238 - accuracy: 0.9420 - val_loss: 0.0256 - val_accuracy: 0.9250\n",
      "Epoch 812/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0356 - accuracy: 0.9310 - val_loss: 0.0804 - val_accuracy: 0.8750\n",
      "Epoch 813/2000\n",
      "1000/1000 [==============================] - 1s 530us/step - loss: 0.0159 - accuracy: 0.9360 - val_loss: 0.0321 - val_accuracy: 0.8750\n",
      "Epoch 814/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.0204 - accuracy: 0.9410 - val_loss: 0.0613 - val_accuracy: 0.9000\n",
      "Epoch 815/2000\n",
      "1000/1000 [==============================] - 1s 556us/step - loss: 0.0163 - accuracy: 0.9420 - val_loss: 0.0526 - val_accuracy: 0.9750\n",
      "Epoch 816/2000\n",
      "1000/1000 [==============================] - 1s 564us/step - loss: 0.0199 - accuracy: 0.9420 - val_loss: 0.0424 - val_accuracy: 0.9250\n",
      "Epoch 817/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0264 - accuracy: 0.9420 - val_loss: 0.0146 - val_accuracy: 0.9500\n",
      "Epoch 818/2000\n",
      "1000/1000 [==============================] - 1s 538us/step - loss: 0.0222 - accuracy: 0.9380 - val_loss: 0.0194 - val_accuracy: 0.9250\n",
      "Epoch 819/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.0238 - accuracy: 0.9440 - val_loss: 0.0606 - val_accuracy: 0.9250\n",
      "Epoch 820/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0266 - accuracy: 0.9430 - val_loss: 0.0387 - val_accuracy: 0.9000\n",
      "Epoch 821/2000\n",
      "1000/1000 [==============================] - 1s 505us/step - loss: 0.0218 - accuracy: 0.9460 - val_loss: 0.0432 - val_accuracy: 0.9500\n",
      "Epoch 822/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0297 - accuracy: 0.9360 - val_loss: 0.0279 - val_accuracy: 0.9500\n",
      "Epoch 823/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.0243 - accuracy: 0.9420 - val_loss: 0.0240 - val_accuracy: 0.9000\n",
      "Epoch 824/2000\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 0.0210 - accuracy: 0.9370 - val_loss: 0.0452 - val_accuracy: 0.9250\n",
      "Epoch 825/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0215 - accuracy: 0.9390 - val_loss: 0.0405 - val_accuracy: 0.9250\n",
      "Epoch 826/2000\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 0.0259 - accuracy: 0.9410 - val_loss: 0.0708 - val_accuracy: 0.8750\n",
      "Epoch 827/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.0249 - accuracy: 0.9530 - val_loss: 0.0231 - val_accuracy: 0.9000\n",
      "Epoch 828/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0225 - accuracy: 0.9400 - val_loss: 0.0204 - val_accuracy: 0.9500\n",
      "Epoch 829/2000\n",
      "1000/1000 [==============================] - 1s 552us/step - loss: 0.0184 - accuracy: 0.9400 - val_loss: 0.0256 - val_accuracy: 0.9250\n",
      "Epoch 830/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0164 - accuracy: 0.9450 - val_loss: 0.0312 - val_accuracy: 0.9250\n",
      "Epoch 831/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0162 - accuracy: 0.9410 - val_loss: 0.0308 - val_accuracy: 0.9000\n",
      "Epoch 832/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0211 - accuracy: 0.9410 - val_loss: 0.0259 - val_accuracy: 0.9250\n",
      "Epoch 833/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0198 - accuracy: 0.9430 - val_loss: 0.0326 - val_accuracy: 0.9250\n",
      "Epoch 834/2000\n",
      "1000/1000 [==============================] - 1s 559us/step - loss: 0.0365 - accuracy: 0.9410 - val_loss: 0.1186 - val_accuracy: 0.9250\n",
      "Epoch 835/2000\n",
      "1000/1000 [==============================] - 1s 570us/step - loss: 0.0288 - accuracy: 0.9540 - val_loss: 0.0382 - val_accuracy: 0.9250\n",
      "Epoch 836/2000\n",
      "1000/1000 [==============================] - 1s 700us/step - loss: 0.0195 - accuracy: 0.9330 - val_loss: 0.0551 - val_accuracy: 0.9250\n",
      "Epoch 837/2000\n",
      "1000/1000 [==============================] - 1s 650us/step - loss: 0.0245 - accuracy: 0.9500 - val_loss: 0.0479 - val_accuracy: 0.9000\n",
      "Epoch 838/2000\n",
      "1000/1000 [==============================] - 1s 725us/step - loss: 0.0152 - accuracy: 0.9450 - val_loss: 0.0623 - val_accuracy: 0.8500\n",
      "Epoch 839/2000\n",
      "1000/1000 [==============================] - 1s 654us/step - loss: 0.0259 - accuracy: 0.9340 - val_loss: 0.0349 - val_accuracy: 0.9500\n",
      "Epoch 840/2000\n",
      "1000/1000 [==============================] - 1s 662us/step - loss: 0.0176 - accuracy: 0.9440 - val_loss: 0.0799 - val_accuracy: 0.9000\n",
      "Epoch 841/2000\n",
      "1000/1000 [==============================] - 1s 682us/step - loss: 0.0233 - accuracy: 0.9430 - val_loss: 0.0323 - val_accuracy: 0.9250\n",
      "Epoch 842/2000\n",
      "1000/1000 [==============================] - 1s 639us/step - loss: 0.0224 - accuracy: 0.9370 - val_loss: 0.0437 - val_accuracy: 0.9500\n",
      "Epoch 843/2000\n",
      "1000/1000 [==============================] - 1s 698us/step - loss: 0.0182 - accuracy: 0.9350 - val_loss: 0.0287 - val_accuracy: 0.9250\n",
      "Epoch 844/2000\n",
      "1000/1000 [==============================] - 1s 582us/step - loss: 0.0285 - accuracy: 0.9350 - val_loss: 0.0385 - val_accuracy: 0.9000\n",
      "Epoch 845/2000\n",
      "1000/1000 [==============================] - 1s 707us/step - loss: 0.0260 - accuracy: 0.9410 - val_loss: 0.0499 - val_accuracy: 0.9250\n",
      "Epoch 846/2000\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0146 - accuracy: 0.9320 - val_loss: 0.0280 - val_accuracy: 0.9000\n",
      "Epoch 847/2000\n",
      "1000/1000 [==============================] - 1s 644us/step - loss: 0.0270 - accuracy: 0.9320 - val_loss: 0.0347 - val_accuracy: 0.9500\n",
      "Epoch 848/2000\n",
      "1000/1000 [==============================] - 1s 623us/step - loss: 0.0291 - accuracy: 0.9250 - val_loss: 0.0333 - val_accuracy: 0.9250\n",
      "Epoch 849/2000\n",
      "1000/1000 [==============================] - 1s 740us/step - loss: 0.0237 - accuracy: 0.9400 - val_loss: 0.1912 - val_accuracy: 0.8750\n",
      "Epoch 850/2000\n",
      "1000/1000 [==============================] - 1s 627us/step - loss: 0.0425 - accuracy: 0.9370 - val_loss: 0.0304 - val_accuracy: 0.9000\n",
      "Epoch 851/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0217 - accuracy: 0.9330 - val_loss: 0.0176 - val_accuracy: 0.9000\n",
      "Epoch 852/2000\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 0.0247 - accuracy: 0.9460 - val_loss: 0.0976 - val_accuracy: 0.8500\n",
      "Epoch 853/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0281 - accuracy: 0.9390 - val_loss: 0.0265 - val_accuracy: 0.8750\n",
      "Epoch 854/2000\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 0.0235 - accuracy: 0.9460 - val_loss: 0.0228 - val_accuracy: 0.9000\n",
      "Epoch 855/2000\n",
      "1000/1000 [==============================] - 1s 570us/step - loss: 0.0265 - accuracy: 0.9430 - val_loss: 0.0185 - val_accuracy: 0.9250\n",
      "Epoch 856/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.0158 - accuracy: 0.9270 - val_loss: 0.0282 - val_accuracy: 0.9250\n",
      "Epoch 857/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0168 - accuracy: 0.9410 - val_loss: 0.0984 - val_accuracy: 0.9250\n",
      "Epoch 858/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0284 - accuracy: 0.9430 - val_loss: 0.0517 - val_accuracy: 0.9250\n",
      "Epoch 859/2000\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 0.0229 - accuracy: 0.9280 - val_loss: 0.0172 - val_accuracy: 0.9250\n",
      "Epoch 860/2000\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 0.0182 - accuracy: 0.9490 - val_loss: 0.0319 - val_accuracy: 0.9000\n",
      "Epoch 861/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0143 - accuracy: 0.9420 - val_loss: 0.0527 - val_accuracy: 0.9000\n",
      "Epoch 862/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0231 - accuracy: 0.9290 - val_loss: 0.0432 - val_accuracy: 0.9000\n",
      "Epoch 863/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0353 - accuracy: 0.9360 - val_loss: 0.0916 - val_accuracy: 0.9000\n",
      "Epoch 864/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0211 - accuracy: 0.9400 - val_loss: 0.0233 - val_accuracy: 0.9250\n",
      "Epoch 865/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0252 - accuracy: 0.9300 - val_loss: 0.0182 - val_accuracy: 0.9250\n",
      "Epoch 866/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0266 - accuracy: 0.9320 - val_loss: 0.0478 - val_accuracy: 0.9000\n",
      "Epoch 867/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0233 - accuracy: 0.9420 - val_loss: 0.0297 - val_accuracy: 0.9000\n",
      "Epoch 868/2000\n",
      "1000/1000 [==============================] - 1s 526us/step - loss: 0.0233 - accuracy: 0.9430 - val_loss: 0.0369 - val_accuracy: 0.9250\n",
      "Epoch 869/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0306 - accuracy: 0.9350 - val_loss: 0.0223 - val_accuracy: 0.9000\n",
      "Epoch 870/2000\n",
      "1000/1000 [==============================] - 1s 580us/step - loss: 0.0205 - accuracy: 0.9440 - val_loss: 0.0385 - val_accuracy: 0.9250\n",
      "Epoch 871/2000\n",
      "1000/1000 [==============================] - 1s 526us/step - loss: 0.0231 - accuracy: 0.9420 - val_loss: 0.0734 - val_accuracy: 0.8750\n",
      "Epoch 872/2000\n",
      "1000/1000 [==============================] - 1s 552us/step - loss: 0.0188 - accuracy: 0.9460 - val_loss: 0.0532 - val_accuracy: 0.9000\n",
      "Epoch 873/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0169 - accuracy: 0.9320 - val_loss: 0.0387 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 874/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0212 - accuracy: 0.9520 - val_loss: 0.0293 - val_accuracy: 0.9000\n",
      "Epoch 875/2000\n",
      "1000/1000 [==============================] - 1s 523us/step - loss: 0.0172 - accuracy: 0.9380 - val_loss: 0.0390 - val_accuracy: 0.9250\n",
      "Epoch 876/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0219 - accuracy: 0.9460 - val_loss: 0.0312 - val_accuracy: 0.9500\n",
      "Epoch 877/2000\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 0.0304 - accuracy: 0.9410 - val_loss: 0.0169 - val_accuracy: 0.9500\n",
      "Epoch 878/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.0229 - accuracy: 0.9450 - val_loss: 0.0413 - val_accuracy: 0.9000\n",
      "Epoch 879/2000\n",
      "1000/1000 [==============================] - 1s 523us/step - loss: 0.0232 - accuracy: 0.9400 - val_loss: 0.0487 - val_accuracy: 0.8750\n",
      "Epoch 880/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0217 - accuracy: 0.9440 - val_loss: 0.0660 - val_accuracy: 0.9250\n",
      "Epoch 881/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0225 - accuracy: 0.9460 - val_loss: 0.0165 - val_accuracy: 0.9500\n",
      "Epoch 882/2000\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 0.0193 - accuracy: 0.9380 - val_loss: 0.0422 - val_accuracy: 0.9250\n",
      "Epoch 883/2000\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 0.0306 - accuracy: 0.9410 - val_loss: 0.0230 - val_accuracy: 0.9750\n",
      "Epoch 884/2000\n",
      "1000/1000 [==============================] - 1s 557us/step - loss: 0.0209 - accuracy: 0.9380 - val_loss: 0.0276 - val_accuracy: 0.9250\n",
      "Epoch 885/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0128 - accuracy: 0.9400 - val_loss: 0.0159 - val_accuracy: 0.8750\n",
      "Epoch 886/2000\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 0.0166 - accuracy: 0.9230 - val_loss: 0.0406 - val_accuracy: 0.9000\n",
      "Epoch 887/2000\n",
      "1000/1000 [==============================] - 1s 526us/step - loss: 0.0453 - accuracy: 0.9350 - val_loss: 0.0238 - val_accuracy: 0.9000\n",
      "Epoch 888/2000\n",
      "1000/1000 [==============================] - 1s 510us/step - loss: 0.0188 - accuracy: 0.9290 - val_loss: 0.0507 - val_accuracy: 0.9000\n",
      "Epoch 889/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0221 - accuracy: 0.9350 - val_loss: 0.0215 - val_accuracy: 0.9500\n",
      "Epoch 890/2000\n",
      "1000/1000 [==============================] - 1s 510us/step - loss: 0.0153 - accuracy: 0.9450 - val_loss: 0.0165 - val_accuracy: 0.9500\n",
      "Epoch 891/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0218 - accuracy: 0.9310 - val_loss: 0.0246 - val_accuracy: 0.9250\n",
      "Epoch 892/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0220 - accuracy: 0.9290 - val_loss: 0.0182 - val_accuracy: 0.9250\n",
      "Epoch 893/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0239 - accuracy: 0.9480 - val_loss: 0.0568 - val_accuracy: 0.9250\n",
      "Epoch 894/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0240 - accuracy: 0.9490 - val_loss: 0.0197 - val_accuracy: 0.9000\n",
      "Epoch 895/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0196 - accuracy: 0.9380 - val_loss: 0.0196 - val_accuracy: 0.9500\n",
      "Epoch 896/2000\n",
      "1000/1000 [==============================] - 1s 559us/step - loss: 0.0164 - accuracy: 0.9380 - val_loss: 0.0207 - val_accuracy: 0.9000\n",
      "Epoch 897/2000\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 0.0158 - accuracy: 0.9310 - val_loss: 0.0190 - val_accuracy: 0.9500\n",
      "Epoch 898/2000\n",
      "1000/1000 [==============================] - 1s 505us/step - loss: 0.0208 - accuracy: 0.9340 - val_loss: 0.0199 - val_accuracy: 0.9250\n",
      "Epoch 899/2000\n",
      "1000/1000 [==============================] - 1s 567us/step - loss: 0.0222 - accuracy: 0.9300 - val_loss: 0.0533 - val_accuracy: 0.9250\n",
      "Epoch 900/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0215 - accuracy: 0.9440 - val_loss: 0.0210 - val_accuracy: 0.9000\n",
      "Epoch 901/2000\n",
      "1000/1000 [==============================] - 1s 530us/step - loss: 0.0143 - accuracy: 0.9440 - val_loss: 0.0269 - val_accuracy: 0.9000\n",
      "Epoch 902/2000\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 0.0173 - accuracy: 0.9330 - val_loss: 0.0532 - val_accuracy: 0.9000\n",
      "Epoch 903/2000\n",
      "1000/1000 [==============================] - 1s 552us/step - loss: 0.0172 - accuracy: 0.9390 - val_loss: 0.0579 - val_accuracy: 0.9000\n",
      "Epoch 904/2000\n",
      "1000/1000 [==============================] - 1s 610us/step - loss: 0.0170 - accuracy: 0.9420 - val_loss: 0.0379 - val_accuracy: 0.9000\n",
      "Epoch 905/2000\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0218 - accuracy: 0.9390 - val_loss: 0.0250 - val_accuracy: 0.9000\n",
      "Epoch 906/2000\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0209 - accuracy: 0.9300 - val_loss: 0.0278 - val_accuracy: 0.8750\n",
      "Epoch 907/2000\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 0.0247 - accuracy: 0.9340 - val_loss: 0.0470 - val_accuracy: 0.9250\n",
      "Epoch 908/2000\n",
      "1000/1000 [==============================] - 1s 563us/step - loss: 0.0255 - accuracy: 0.9390 - val_loss: 0.1012 - val_accuracy: 0.9000\n",
      "Epoch 909/2000\n",
      "1000/1000 [==============================] - 1s 549us/step - loss: 0.0188 - accuracy: 0.9300 - val_loss: 0.0450 - val_accuracy: 0.9000\n",
      "Epoch 910/2000\n",
      "1000/1000 [==============================] - 1s 559us/step - loss: 0.0223 - accuracy: 0.9260 - val_loss: 0.0192 - val_accuracy: 0.8750\n",
      "Epoch 911/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0190 - accuracy: 0.9410 - val_loss: 0.0241 - val_accuracy: 0.9500\n",
      "Epoch 912/2000\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 0.0261 - accuracy: 0.9340 - val_loss: 0.0784 - val_accuracy: 0.9000\n",
      "Epoch 913/2000\n",
      "1000/1000 [==============================] - 1s 533us/step - loss: 0.0245 - accuracy: 0.9420 - val_loss: 0.0240 - val_accuracy: 0.9500\n",
      "Epoch 914/2000\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0192 - accuracy: 0.9390 - val_loss: 0.0219 - val_accuracy: 0.8750\n",
      "Epoch 915/2000\n",
      "1000/1000 [==============================] - 1s 691us/step - loss: 0.0156 - accuracy: 0.9430 - val_loss: 0.0649 - val_accuracy: 0.9500\n",
      "Epoch 916/2000\n",
      "1000/1000 [==============================] - 1s 725us/step - loss: 0.0178 - accuracy: 0.9360 - val_loss: 0.0302 - val_accuracy: 0.9250\n",
      "Epoch 917/2000\n",
      "1000/1000 [==============================] - 1s 688us/step - loss: 0.0229 - accuracy: 0.9420 - val_loss: 0.0546 - val_accuracy: 0.8750\n",
      "Epoch 918/2000\n",
      "1000/1000 [==============================] - 1s 640us/step - loss: 0.0162 - accuracy: 0.9370 - val_loss: 0.0402 - val_accuracy: 0.9000\n",
      "Epoch 919/2000\n",
      "1000/1000 [==============================] - 1s 622us/step - loss: 0.0299 - accuracy: 0.9440 - val_loss: 0.0488 - val_accuracy: 0.9500\n",
      "Epoch 920/2000\n",
      "1000/1000 [==============================] - 1s 581us/step - loss: 0.0173 - accuracy: 0.9360 - val_loss: 0.0472 - val_accuracy: 0.9000\n",
      "Epoch 921/2000\n",
      "1000/1000 [==============================] - 1s 634us/step - loss: 0.0150 - accuracy: 0.9390 - val_loss: 0.0199 - val_accuracy: 0.9500\n",
      "Epoch 922/2000\n",
      "1000/1000 [==============================] - 1s 632us/step - loss: 0.0140 - accuracy: 0.9520 - val_loss: 0.0294 - val_accuracy: 0.9750\n",
      "Epoch 923/2000\n",
      "1000/1000 [==============================] - 1s 685us/step - loss: 0.0154 - accuracy: 0.9450 - val_loss: 0.0271 - val_accuracy: 0.9750\n",
      "Epoch 924/2000\n",
      "1000/1000 [==============================] - 1s 570us/step - loss: 0.0190 - accuracy: 0.9540 - val_loss: 0.0315 - val_accuracy: 0.9500\n",
      "Epoch 925/2000\n",
      "1000/1000 [==============================] - 1s 855us/step - loss: 0.0170 - accuracy: 0.9470 - val_loss: 0.0360 - val_accuracy: 0.9250\n",
      "Epoch 926/2000\n",
      "1000/1000 [==============================] - 1s 618us/step - loss: 0.0229 - accuracy: 0.9420 - val_loss: 0.0266 - val_accuracy: 0.9500\n",
      "Epoch 927/2000\n",
      "1000/1000 [==============================] - 1s 622us/step - loss: 0.0200 - accuracy: 0.9500 - val_loss: 0.0194 - val_accuracy: 0.9500\n",
      "Epoch 928/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 541us/step - loss: 0.0132 - accuracy: 0.9390 - val_loss: 0.0184 - val_accuracy: 0.9000\n",
      "Epoch 929/2000\n",
      "1000/1000 [==============================] - 1s 544us/step - loss: 0.0218 - accuracy: 0.9350 - val_loss: 0.0504 - val_accuracy: 0.9250\n",
      "Epoch 930/2000\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.0177 - accuracy: 0.9410 - val_loss: 0.0201 - val_accuracy: 0.9250\n",
      "Epoch 931/2000\n",
      "1000/1000 [==============================] - 1s 568us/step - loss: 0.0218 - accuracy: 0.9380 - val_loss: 0.0559 - val_accuracy: 0.9250\n",
      "Epoch 932/2000\n",
      "1000/1000 [==============================] - 1s 615us/step - loss: 0.0207 - accuracy: 0.9470 - val_loss: 0.0366 - val_accuracy: 0.9250\n",
      "Epoch 933/2000\n",
      "1000/1000 [==============================] - 1s 578us/step - loss: 0.0250 - accuracy: 0.9500 - val_loss: 0.0418 - val_accuracy: 0.9250\n",
      "Epoch 934/2000\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 0.0213 - accuracy: 0.9460 - val_loss: 0.0249 - val_accuracy: 0.9250\n",
      "Epoch 935/2000\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0204 - accuracy: 0.9360 - val_loss: 0.0262 - val_accuracy: 0.9500\n",
      "Epoch 936/2000\n",
      "1000/1000 [==============================] - 1s 538us/step - loss: 0.0170 - accuracy: 0.9560 - val_loss: 0.0258 - val_accuracy: 0.9500\n",
      "Epoch 937/2000\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.0185 - accuracy: 0.9370 - val_loss: 0.0719 - val_accuracy: 0.9000\n",
      "Epoch 938/2000\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0182 - accuracy: 0.9300 - val_loss: 0.0230 - val_accuracy: 0.9000\n",
      "Epoch 939/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0246 - accuracy: 0.9270 - val_loss: 0.0375 - val_accuracy: 0.9250\n",
      "Epoch 940/2000\n",
      "1000/1000 [==============================] - 1s 552us/step - loss: 0.0174 - accuracy: 0.9210 - val_loss: 0.0357 - val_accuracy: 0.9250\n",
      "Epoch 941/2000\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 0.0199 - accuracy: 0.9190 - val_loss: 0.0155 - val_accuracy: 0.9000\n",
      "Epoch 942/2000\n",
      "1000/1000 [==============================] - 1s 556us/step - loss: 0.0246 - accuracy: 0.9450 - val_loss: 0.0178 - val_accuracy: 0.9250\n",
      "Epoch 943/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0175 - accuracy: 0.9320 - val_loss: 0.0255 - val_accuracy: 0.9000\n",
      "Epoch 944/2000\n",
      "1000/1000 [==============================] - 1s 538us/step - loss: 0.0207 - accuracy: 0.9340 - val_loss: 0.0307 - val_accuracy: 0.9000\n",
      "Epoch 945/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0169 - accuracy: 0.9290 - val_loss: 0.0818 - val_accuracy: 0.9000\n",
      "Epoch 946/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0333 - accuracy: 0.9390 - val_loss: 0.0351 - val_accuracy: 0.9500\n",
      "Epoch 947/2000\n",
      "1000/1000 [==============================] - 1s 538us/step - loss: 0.0254 - accuracy: 0.9250 - val_loss: 0.0432 - val_accuracy: 0.9500\n",
      "Epoch 948/2000\n",
      "1000/1000 [==============================] - 1s 556us/step - loss: 0.0153 - accuracy: 0.9450 - val_loss: 0.0217 - val_accuracy: 0.9250\n",
      "Epoch 949/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0158 - accuracy: 0.9300 - val_loss: 0.0290 - val_accuracy: 0.8750\n",
      "Epoch 950/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0301 - accuracy: 0.9370 - val_loss: 0.0213 - val_accuracy: 0.9500\n",
      "Epoch 951/2000\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0210 - accuracy: 0.9390 - val_loss: 0.0318 - val_accuracy: 0.8500\n",
      "Epoch 952/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0181 - accuracy: 0.9300 - val_loss: 0.0349 - val_accuracy: 0.9250\n",
      "Epoch 953/2000\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0294 - accuracy: 0.9140 - val_loss: 0.0306 - val_accuracy: 0.9250\n",
      "Epoch 954/2000\n",
      "1000/1000 [==============================] - 1s 543us/step - loss: 0.0207 - accuracy: 0.9370 - val_loss: 0.0355 - val_accuracy: 0.9000\n",
      "Epoch 955/2000\n",
      "1000/1000 [==============================] - 1s 561us/step - loss: 0.0233 - accuracy: 0.9290 - val_loss: 0.0516 - val_accuracy: 0.9000\n",
      "Epoch 956/2000\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 0.0145 - accuracy: 0.9440 - val_loss: 0.0173 - val_accuracy: 0.9000\n",
      "Epoch 957/2000\n",
      "1000/1000 [==============================] - 1s 538us/step - loss: 0.0153 - accuracy: 0.9430 - val_loss: 0.0408 - val_accuracy: 0.9500\n",
      "Epoch 958/2000\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.0170 - accuracy: 0.9440 - val_loss: 0.0267 - val_accuracy: 0.9000\n",
      "Epoch 959/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0217 - accuracy: 0.9330 - val_loss: 0.0425 - val_accuracy: 0.9500\n",
      "Epoch 960/2000\n",
      "1000/1000 [==============================] - 1s 552us/step - loss: 0.0223 - accuracy: 0.9400 - val_loss: 0.0281 - val_accuracy: 0.9250\n",
      "Epoch 961/2000\n",
      "1000/1000 [==============================] - 1s 577us/step - loss: 0.0132 - accuracy: 0.9440 - val_loss: 0.0185 - val_accuracy: 0.9500\n",
      "Epoch 962/2000\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 0.0170 - accuracy: 0.9380 - val_loss: 0.0340 - val_accuracy: 0.9250\n",
      "Epoch 963/2000\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 0.0245 - accuracy: 0.9390 - val_loss: 0.0124 - val_accuracy: 0.9000\n",
      "Epoch 964/2000\n",
      "1000/1000 [==============================] - 1s 580us/step - loss: 0.0177 - accuracy: 0.9350 - val_loss: 0.0220 - val_accuracy: 0.9000\n",
      "Epoch 965/2000\n",
      "1000/1000 [==============================] - 1s 579us/step - loss: 0.0275 - accuracy: 0.9330 - val_loss: 0.0357 - val_accuracy: 0.9500\n",
      "Epoch 966/2000\n",
      "1000/1000 [==============================] - 1s 544us/step - loss: 0.0175 - accuracy: 0.9240 - val_loss: 0.0532 - val_accuracy: 0.9500\n",
      "Epoch 967/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0186 - accuracy: 0.9290 - val_loss: 0.0461 - val_accuracy: 0.9000\n",
      "Epoch 968/2000\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0218 - accuracy: 0.9420 - val_loss: 0.0181 - val_accuracy: 0.9000\n",
      "Epoch 969/2000\n",
      "1000/1000 [==============================] - 1s 576us/step - loss: 0.0208 - accuracy: 0.9380 - val_loss: 0.0269 - val_accuracy: 0.9000\n",
      "Epoch 970/2000\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.0149 - accuracy: 0.9440 - val_loss: 0.0219 - val_accuracy: 0.9750\n",
      "Epoch 971/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0177 - accuracy: 0.9390 - val_loss: 0.0437 - val_accuracy: 0.9250\n",
      "Epoch 972/2000\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0261 - accuracy: 0.9400 - val_loss: 0.0582 - val_accuracy: 0.9250\n",
      "Epoch 973/2000\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0282 - accuracy: 0.9270 - val_loss: 0.0295 - val_accuracy: 0.9250\n",
      "Epoch 974/2000\n",
      "1000/1000 [==============================] - 1s 556us/step - loss: 0.0147 - accuracy: 0.9390 - val_loss: 0.0353 - val_accuracy: 0.9250\n",
      "Epoch 975/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0184 - accuracy: 0.9520 - val_loss: 0.0276 - val_accuracy: 0.9250\n",
      "Epoch 976/2000\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 0.0207 - accuracy: 0.9420 - val_loss: 0.0409 - val_accuracy: 0.9000\n",
      "Epoch 977/2000\n",
      "1000/1000 [==============================] - 1s 557us/step - loss: 0.0219 - accuracy: 0.9430 - val_loss: 0.0230 - val_accuracy: 0.9250\n",
      "Epoch 978/2000\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.0120 - accuracy: 0.9400 - val_loss: 0.0231 - val_accuracy: 0.9250\n",
      "Epoch 979/2000\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.0127 - accuracy: 0.9280 - val_loss: 0.0281 - val_accuracy: 0.9250\n",
      "Epoch 980/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0195 - accuracy: 0.9350 - val_loss: 0.0269 - val_accuracy: 0.9250\n",
      "Epoch 981/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0122 - accuracy: 0.9450 - val_loss: 0.0269 - val_accuracy: 0.9250\n",
      "Epoch 982/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0204 - accuracy: 0.9400 - val_loss: 0.0168 - val_accuracy: 0.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 983/2000\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 0.0165 - accuracy: 0.9340 - val_loss: 0.0296 - val_accuracy: 0.9500\n",
      "Epoch 984/2000\n",
      "1000/1000 [==============================] - 1s 563us/step - loss: 0.0226 - accuracy: 0.9370 - val_loss: 0.0596 - val_accuracy: 0.8750\n",
      "Epoch 985/2000\n",
      "1000/1000 [==============================] - 1s 542us/step - loss: 0.0218 - accuracy: 0.9320 - val_loss: 0.0191 - val_accuracy: 0.9250\n",
      "Epoch 986/2000\n",
      "1000/1000 [==============================] - 1s 563us/step - loss: 0.0190 - accuracy: 0.9280 - val_loss: 0.0427 - val_accuracy: 0.9250\n",
      "Epoch 987/2000\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.0168 - accuracy: 0.9240 - val_loss: 0.0352 - val_accuracy: 0.8750\n",
      "Epoch 988/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0280 - accuracy: 0.9240 - val_loss: 0.0292 - val_accuracy: 0.9000\n",
      "Epoch 989/2000\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 0.0191 - accuracy: 0.9300 - val_loss: 0.0490 - val_accuracy: 0.9000\n",
      "Epoch 990/2000\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 0.0193 - accuracy: 0.9310 - val_loss: 0.0269 - val_accuracy: 0.9250\n",
      "Epoch 991/2000\n",
      "1000/1000 [==============================] - 1s 538us/step - loss: 0.0229 - accuracy: 0.9300 - val_loss: 0.0366 - val_accuracy: 0.9000\n",
      "Epoch 992/2000\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 0.0259 - accuracy: 0.9280 - val_loss: 0.0359 - val_accuracy: 0.9000\n",
      "Epoch 993/2000\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.0169 - accuracy: 0.9310 - val_loss: 0.0196 - val_accuracy: 0.9250\n",
      "Epoch 994/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0240 - accuracy: 0.9310 - val_loss: 0.0555 - val_accuracy: 0.9250\n",
      "Epoch 995/2000\n",
      "1000/1000 [==============================] - 1s 549us/step - loss: 0.0187 - accuracy: 0.9370 - val_loss: 0.0373 - val_accuracy: 0.9000\n",
      "Epoch 996/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0150 - accuracy: 0.9490 - val_loss: 0.0242 - val_accuracy: 0.8750\n",
      "Epoch 997/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0260 - accuracy: 0.9290 - val_loss: 0.0293 - val_accuracy: 0.9750\n",
      "Epoch 998/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0213 - accuracy: 0.9420 - val_loss: 0.1145 - val_accuracy: 0.8750\n",
      "Epoch 999/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0221 - accuracy: 0.9250 - val_loss: 0.0321 - val_accuracy: 0.9250\n",
      "Epoch 1000/2000\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.0208 - accuracy: 0.9440 - val_loss: 0.0327 - val_accuracy: 0.9500\n",
      "Epoch 1001/2000\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 0.0210 - accuracy: 0.9420 - val_loss: 0.0231 - val_accuracy: 0.9000\n",
      "Epoch 1002/2000\n",
      "1000/1000 [==============================] - 1s 561us/step - loss: 0.0298 - accuracy: 0.9440 - val_loss: 0.0284 - val_accuracy: 0.9000\n",
      "Epoch 1003/2000\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 0.0147 - accuracy: 0.9360 - val_loss: 0.0449 - val_accuracy: 0.9500\n",
      "Epoch 1004/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0200 - accuracy: 0.9350 - val_loss: 0.1133 - val_accuracy: 0.9000\n",
      "Epoch 1005/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0199 - accuracy: 0.9300 - val_loss: 0.0371 - val_accuracy: 0.9250\n",
      "Epoch 1006/2000\n",
      "1000/1000 [==============================] - 1s 549us/step - loss: 0.0158 - accuracy: 0.9240 - val_loss: 0.0181 - val_accuracy: 0.9250\n",
      "Epoch 1007/2000\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 0.0245 - accuracy: 0.9330 - val_loss: 0.0294 - val_accuracy: 0.9250\n",
      "Epoch 1008/2000\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 0.0218 - accuracy: 0.9310 - val_loss: 0.0417 - val_accuracy: 0.8500\n",
      "Epoch 1009/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0145 - accuracy: 0.9310 - val_loss: 0.0264 - val_accuracy: 0.9250\n",
      "Epoch 1010/2000\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 0.0241 - accuracy: 0.9340 - val_loss: 0.0242 - val_accuracy: 0.9250\n",
      "Epoch 1011/2000\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.0171 - accuracy: 0.9270 - val_loss: 0.0709 - val_accuracy: 0.9500\n",
      "Epoch 1012/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0251 - accuracy: 0.9360 - val_loss: 0.0490 - val_accuracy: 0.8500\n",
      "Epoch 1013/2000\n",
      "1000/1000 [==============================] - 1s 549us/step - loss: 0.0158 - accuracy: 0.9390 - val_loss: 0.0469 - val_accuracy: 0.9000\n",
      "Epoch 1014/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0174 - accuracy: 0.9530 - val_loss: 0.0669 - val_accuracy: 0.9000\n",
      "Epoch 1015/2000\n",
      "1000/1000 [==============================] - 1s 549us/step - loss: 0.0237 - accuracy: 0.9230 - val_loss: 0.0463 - val_accuracy: 0.9250\n",
      "Epoch 1016/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0322 - accuracy: 0.9430 - val_loss: 0.0318 - val_accuracy: 0.8750\n",
      "Epoch 1017/2000\n",
      "1000/1000 [==============================] - 1s 560us/step - loss: 0.0131 - accuracy: 0.9290 - val_loss: 0.0139 - val_accuracy: 0.9250\n",
      "Epoch 1018/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0192 - accuracy: 0.9370 - val_loss: 0.0246 - val_accuracy: 0.9250\n",
      "Epoch 1019/2000\n",
      "1000/1000 [==============================] - 1s 544us/step - loss: 0.0171 - accuracy: 0.9310 - val_loss: 0.0190 - val_accuracy: 0.9500\n",
      "Epoch 1020/2000\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.0135 - accuracy: 0.9410 - val_loss: 0.0197 - val_accuracy: 0.9000\n",
      "Epoch 1021/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0265 - accuracy: 0.9310 - val_loss: 0.0382 - val_accuracy: 0.9250\n",
      "Epoch 1022/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0161 - accuracy: 0.9430 - val_loss: 0.0420 - val_accuracy: 0.9500\n",
      "Epoch 1023/2000\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 0.0226 - accuracy: 0.9420 - val_loss: 0.0294 - val_accuracy: 0.9250\n",
      "Epoch 1024/2000\n",
      "1000/1000 [==============================] - 1s 552us/step - loss: 0.0130 - accuracy: 0.9330 - val_loss: 0.0367 - val_accuracy: 0.9250\n",
      "Epoch 1025/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0203 - accuracy: 0.9430 - val_loss: 0.0223 - val_accuracy: 0.9000\n",
      "Epoch 1026/2000\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 0.0137 - accuracy: 0.9300 - val_loss: 0.0224 - val_accuracy: 0.9000\n",
      "Epoch 1027/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0123 - accuracy: 0.9330 - val_loss: 0.0371 - val_accuracy: 0.9500\n",
      "Epoch 1028/2000\n",
      "1000/1000 [==============================] - 1s 562us/step - loss: 0.0278 - accuracy: 0.9260 - val_loss: 0.0155 - val_accuracy: 0.9500\n",
      "Epoch 1029/2000\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.0187 - accuracy: 0.9390 - val_loss: 0.0339 - val_accuracy: 0.9250\n",
      "Epoch 1030/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0187 - accuracy: 0.9270 - val_loss: 0.0210 - val_accuracy: 0.9250\n",
      "Epoch 1031/2000\n",
      "1000/1000 [==============================] - 1s 544us/step - loss: 0.0241 - accuracy: 0.9310 - val_loss: 0.0591 - val_accuracy: 0.9000\n",
      "Epoch 1032/2000\n",
      "1000/1000 [==============================] - 1s 555us/step - loss: 0.0143 - accuracy: 0.9340 - val_loss: 0.0553 - val_accuracy: 0.9250\n",
      "Epoch 1033/2000\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.0133 - accuracy: 0.9360 - val_loss: 0.0336 - val_accuracy: 0.9000\n",
      "Epoch 1034/2000\n",
      "1000/1000 [==============================] - 1s 542us/step - loss: 0.0197 - accuracy: 0.9320 - val_loss: 0.0189 - val_accuracy: 0.9250\n",
      "Epoch 1035/2000\n",
      "1000/1000 [==============================] - 1s 544us/step - loss: 0.0288 - accuracy: 0.9290 - val_loss: 0.0319 - val_accuracy: 0.9250\n",
      "Epoch 1036/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0182 - accuracy: 0.9220 - val_loss: 0.0511 - val_accuracy: 0.9000\n",
      "Epoch 1037/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 555us/step - loss: 0.0183 - accuracy: 0.9270 - val_loss: 0.0343 - val_accuracy: 0.9250\n",
      "Epoch 1038/2000\n",
      "1000/1000 [==============================] - 1s 567us/step - loss: 0.0268 - accuracy: 0.9350 - val_loss: 0.0150 - val_accuracy: 0.9250\n",
      "Epoch 1039/2000\n",
      "1000/1000 [==============================] - 1s 543us/step - loss: 0.0208 - accuracy: 0.9300 - val_loss: 0.0248 - val_accuracy: 0.9250\n",
      "Epoch 1040/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0180 - accuracy: 0.9310 - val_loss: 0.0259 - val_accuracy: 0.9500\n",
      "Epoch 1041/2000\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.0209 - accuracy: 0.9360 - val_loss: 0.0246 - val_accuracy: 0.9250\n",
      "Epoch 1042/2000\n",
      "1000/1000 [==============================] - 1s 552us/step - loss: 0.0240 - accuracy: 0.9310 - val_loss: 0.0342 - val_accuracy: 0.9500\n",
      "Epoch 1043/2000\n",
      "1000/1000 [==============================] - 1s 552us/step - loss: 0.0133 - accuracy: 0.9290 - val_loss: 0.0441 - val_accuracy: 0.9750\n",
      "Epoch 1044/2000\n",
      "1000/1000 [==============================] - 1s 561us/step - loss: 0.0195 - accuracy: 0.9440 - val_loss: 0.0402 - val_accuracy: 0.8750\n",
      "Epoch 1045/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0184 - accuracy: 0.9330 - val_loss: 0.0464 - val_accuracy: 0.9500\n",
      "Epoch 1046/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0144 - accuracy: 0.9290 - val_loss: 0.0409 - val_accuracy: 0.9750\n",
      "Epoch 1047/2000\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 0.0102 - accuracy: 0.9260 - val_loss: 0.0266 - val_accuracy: 0.9250\n",
      "Epoch 1048/2000\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.0169 - accuracy: 0.9360 - val_loss: 0.0443 - val_accuracy: 0.9250\n",
      "Epoch 1049/2000\n",
      "1000/1000 [==============================] - 1s 538us/step - loss: 0.0134 - accuracy: 0.9290 - val_loss: 0.0473 - val_accuracy: 0.9000\n",
      "Epoch 1050/2000\n",
      "1000/1000 [==============================] - 1s 559us/step - loss: 0.0201 - accuracy: 0.9380 - val_loss: 0.0349 - val_accuracy: 0.9250\n",
      "Epoch 1051/2000\n",
      "1000/1000 [==============================] - 1s 578us/step - loss: 0.0152 - accuracy: 0.9340 - val_loss: 0.0322 - val_accuracy: 0.9250\n",
      "Epoch 1052/2000\n",
      "1000/1000 [==============================] - 1s 562us/step - loss: 0.0171 - accuracy: 0.9430 - val_loss: 0.0434 - val_accuracy: 0.9000\n",
      "Epoch 1053/2000\n",
      "1000/1000 [==============================] - 1s 580us/step - loss: 0.0123 - accuracy: 0.9220 - val_loss: 0.0163 - val_accuracy: 0.8750\n",
      "Epoch 1054/2000\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0183 - accuracy: 0.9200 - val_loss: 0.0316 - val_accuracy: 0.9250\n",
      "Epoch 1055/2000\n",
      "1000/1000 [==============================] - 1s 557us/step - loss: 0.0135 - accuracy: 0.9320 - val_loss: 0.0221 - val_accuracy: 0.9000\n",
      "Epoch 1056/2000\n",
      "1000/1000 [==============================] - 1s 577us/step - loss: 0.0145 - accuracy: 0.9310 - val_loss: 0.0221 - val_accuracy: 0.8750\n",
      "Epoch 1057/2000\n",
      "1000/1000 [==============================] - 1s 561us/step - loss: 0.0177 - accuracy: 0.9350 - val_loss: 0.0244 - val_accuracy: 0.9500\n",
      "Epoch 1058/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0260 - accuracy: 0.9320 - val_loss: 0.0917 - val_accuracy: 0.9250\n",
      "Epoch 1059/2000\n",
      "1000/1000 [==============================] - 1s 560us/step - loss: 0.0148 - accuracy: 0.9290 - val_loss: 0.0308 - val_accuracy: 0.9000\n",
      "Epoch 1060/2000\n",
      "1000/1000 [==============================] - 1s 560us/step - loss: 0.0215 - accuracy: 0.9310 - val_loss: 0.0123 - val_accuracy: 0.9000\n",
      "Epoch 1061/2000\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 0.0229 - accuracy: 0.9220 - val_loss: 0.0224 - val_accuracy: 0.9250\n",
      "Epoch 1062/2000\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 0.0153 - accuracy: 0.9320 - val_loss: 0.0358 - val_accuracy: 0.9500\n",
      "Epoch 1063/2000\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0138 - accuracy: 0.9330 - val_loss: 0.0176 - val_accuracy: 0.9250\n",
      "Epoch 1064/2000\n",
      "1000/1000 [==============================] - 1s 562us/step - loss: 0.0155 - accuracy: 0.9470 - val_loss: 0.0252 - val_accuracy: 0.9500\n",
      "Epoch 1065/2000\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 0.0185 - accuracy: 0.9400 - val_loss: 0.0170 - val_accuracy: 0.9250\n",
      "Epoch 1066/2000\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 0.0149 - accuracy: 0.9430 - val_loss: 0.0203 - val_accuracy: 0.9500\n",
      "Epoch 1067/2000\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 0.0122 - accuracy: 0.9290 - val_loss: 0.0203 - val_accuracy: 0.9000\n",
      "Epoch 1068/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0166 - accuracy: 0.9260 - val_loss: 0.0399 - val_accuracy: 0.9750\n",
      "Epoch 1069/2000\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 0.0165 - accuracy: 0.9320 - val_loss: 0.0506 - val_accuracy: 0.9250\n",
      "Epoch 1070/2000\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0365 - accuracy: 0.9290 - val_loss: 0.0178 - val_accuracy: 0.9250\n",
      "Epoch 1071/2000\n",
      "1000/1000 [==============================] - 1s 573us/step - loss: 0.0236 - accuracy: 0.9170 - val_loss: 0.0181 - val_accuracy: 0.9000\n",
      "Epoch 1072/2000\n",
      "1000/1000 [==============================] - 1s 570us/step - loss: 0.0180 - accuracy: 0.9360 - val_loss: 0.0268 - val_accuracy: 0.8750\n",
      "Epoch 1073/2000\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0156 - accuracy: 0.9340 - val_loss: 0.0265 - val_accuracy: 0.9000\n",
      "Epoch 1074/2000\n",
      "1000/1000 [==============================] - 1s 606us/step - loss: 0.0283 - accuracy: 0.9430 - val_loss: 0.0377 - val_accuracy: 0.9250\n",
      "Epoch 1075/2000\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0366 - accuracy: 0.9350 - val_loss: 0.0556 - val_accuracy: 0.9500\n",
      "Epoch 1076/2000\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0269 - accuracy: 0.9250 - val_loss: 0.0213 - val_accuracy: 0.9250\n",
      "Epoch 1077/2000\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0225 - accuracy: 0.9270 - val_loss: 0.0202 - val_accuracy: 0.9750\n",
      "Epoch 1078/2000\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0164 - accuracy: 0.9360 - val_loss: 0.0199 - val_accuracy: 0.9000\n",
      "Epoch 1079/2000\n",
      "1000/1000 [==============================] - 1s 619us/step - loss: 0.0229 - accuracy: 0.9340 - val_loss: 0.0267 - val_accuracy: 0.9500\n",
      "Epoch 1080/2000\n",
      "1000/1000 [==============================] - 1s 623us/step - loss: 0.0445 - accuracy: 0.9220 - val_loss: 0.0668 - val_accuracy: 0.9500\n",
      "Epoch 1081/2000\n",
      "1000/1000 [==============================] - 1s 784us/step - loss: 0.0268 - accuracy: 0.9440 - val_loss: 0.0416 - val_accuracy: 0.9250\n",
      "Epoch 1082/2000\n",
      "1000/1000 [==============================] - 1s 820us/step - loss: 0.0293 - accuracy: 0.9390 - val_loss: 0.0595 - val_accuracy: 0.8750\n",
      "Epoch 1083/2000\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0197 - accuracy: 0.9340 - val_loss: 0.0325 - val_accuracy: 0.9000\n",
      "Epoch 1084/2000\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0360 - accuracy: 0.9380 - val_loss: 0.0388 - val_accuracy: 0.9250\n",
      "Epoch 1085/2000\n",
      "1000/1000 [==============================] - 1s 549us/step - loss: 0.0156 - accuracy: 0.9460 - val_loss: 0.0207 - val_accuracy: 0.9250\n",
      "Epoch 1086/2000\n",
      "1000/1000 [==============================] - 1s 606us/step - loss: 0.0178 - accuracy: 0.9390 - val_loss: 0.0270 - val_accuracy: 0.9000\n",
      "Epoch 1087/2000\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0295 - accuracy: 0.9390 - val_loss: 0.0391 - val_accuracy: 0.9250\n",
      "Epoch 1088/2000\n",
      "1000/1000 [==============================] - 1s 580us/step - loss: 0.0140 - accuracy: 0.9390 - val_loss: 0.0216 - val_accuracy: 0.9000\n",
      "Epoch 1089/2000\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 0.0161 - accuracy: 0.9370 - val_loss: 0.0379 - val_accuracy: 0.9250\n",
      "Epoch 1090/2000\n",
      "1000/1000 [==============================] - 1s 611us/step - loss: 0.0185 - accuracy: 0.9290 - val_loss: 0.0205 - val_accuracy: 0.9000\n",
      "Epoch 1091/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 638us/step - loss: 0.0261 - accuracy: 0.9350 - val_loss: 0.0182 - val_accuracy: 0.9250\n",
      "Epoch 1092/2000\n",
      "1000/1000 [==============================] - 1s 742us/step - loss: 0.0131 - accuracy: 0.9370 - val_loss: 0.0359 - val_accuracy: 0.9000\n",
      "Epoch 1093/2000\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0246 - accuracy: 0.9460 - val_loss: 0.0365 - val_accuracy: 0.9000\n",
      "Epoch 1094/2000\n",
      "1000/1000 [==============================] - 1s 604us/step - loss: 0.0237 - accuracy: 0.9390 - val_loss: 0.0138 - val_accuracy: 0.9250\n",
      "Epoch 1095/2000\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0244 - accuracy: 0.9440 - val_loss: 0.0191 - val_accuracy: 0.9250\n",
      "Epoch 1096/2000\n",
      "1000/1000 [==============================] - 1s 640us/step - loss: 0.0184 - accuracy: 0.9420 - val_loss: 0.0784 - val_accuracy: 0.9500\n",
      "Epoch 1097/2000\n",
      "1000/1000 [==============================] - 1s 564us/step - loss: 0.0144 - accuracy: 0.9520 - val_loss: 0.0417 - val_accuracy: 0.9250\n",
      "Epoch 1098/2000\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.0276 - accuracy: 0.9400 - val_loss: 0.0416 - val_accuracy: 0.9250\n",
      "Epoch 1099/2000\n",
      "1000/1000 [==============================] - 1s 561us/step - loss: 0.0139 - accuracy: 0.9410 - val_loss: 0.0178 - val_accuracy: 0.9250\n",
      "Epoch 1100/2000\n",
      "1000/1000 [==============================] - 1s 562us/step - loss: 0.0143 - accuracy: 0.9480 - val_loss: 0.0183 - val_accuracy: 0.9250\n",
      "Epoch 1101/2000\n",
      "1000/1000 [==============================] - 1s 562us/step - loss: 0.0119 - accuracy: 0.9380 - val_loss: 0.0372 - val_accuracy: 0.9250\n",
      "Epoch 1102/2000\n",
      "1000/1000 [==============================] - 1s 555us/step - loss: 0.0161 - accuracy: 0.9350 - val_loss: 0.0326 - val_accuracy: 0.9500\n",
      "Epoch 1103/2000\n",
      "1000/1000 [==============================] - 1s 555us/step - loss: 0.0212 - accuracy: 0.9310 - val_loss: 0.0230 - val_accuracy: 0.9250\n",
      "Epoch 1104/2000\n",
      "1000/1000 [==============================] - 1s 561us/step - loss: 0.0160 - accuracy: 0.9310 - val_loss: 0.0267 - val_accuracy: 0.9250\n",
      "Epoch 1105/2000\n",
      "1000/1000 [==============================] - 1s 570us/step - loss: 0.0236 - accuracy: 0.9360 - val_loss: 0.0200 - val_accuracy: 0.9500\n",
      "Epoch 1106/2000\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 0.0201 - accuracy: 0.9400 - val_loss: 0.0124 - val_accuracy: 0.9750\n",
      "Epoch 1107/2000\n",
      "1000/1000 [==============================] - 1s 561us/step - loss: 0.0240 - accuracy: 0.9420 - val_loss: 0.0345 - val_accuracy: 0.9250\n",
      "Epoch 1108/2000\n",
      "1000/1000 [==============================] - 1s 559us/step - loss: 0.0205 - accuracy: 0.9450 - val_loss: 0.0282 - val_accuracy: 0.9500\n",
      "Epoch 1109/2000\n",
      "1000/1000 [==============================] - 1s 577us/step - loss: 0.0177 - accuracy: 0.9380 - val_loss: 0.0317 - val_accuracy: 0.9250\n",
      "Epoch 1110/2000\n",
      "1000/1000 [==============================] - 1s 561us/step - loss: 0.0170 - accuracy: 0.9410 - val_loss: 0.0299 - val_accuracy: 0.9500\n",
      "Epoch 1111/2000\n",
      "1000/1000 [==============================] - 1s 543us/step - loss: 0.0178 - accuracy: 0.9390 - val_loss: 0.0318 - val_accuracy: 0.9250\n",
      "Epoch 1112/2000\n",
      "1000/1000 [==============================] - 1s 557us/step - loss: 0.0171 - accuracy: 0.9490 - val_loss: 0.0364 - val_accuracy: 0.9250\n",
      "Epoch 1113/2000\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0154 - accuracy: 0.9480 - val_loss: 0.0243 - val_accuracy: 0.9750\n",
      "Epoch 1114/2000\n",
      "1000/1000 [==============================] - 1s 543us/step - loss: 0.0097 - accuracy: 0.9430 - val_loss: 0.0204 - val_accuracy: 0.8750\n",
      "Epoch 1115/2000\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 0.0154 - accuracy: 0.9550 - val_loss: 0.0226 - val_accuracy: 0.9250\n",
      "Epoch 1116/2000\n",
      "1000/1000 [==============================] - 1s 564us/step - loss: 0.0240 - accuracy: 0.9480 - val_loss: 0.0329 - val_accuracy: 0.9250\n",
      "Epoch 1117/2000\n",
      "1000/1000 [==============================] - 1s 560us/step - loss: 0.0179 - accuracy: 0.9530 - val_loss: 0.0264 - val_accuracy: 0.9250\n",
      "Epoch 1118/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0237 - accuracy: 0.9540 - val_loss: 0.0194 - val_accuracy: 0.9500\n",
      "Epoch 1119/2000\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0134 - accuracy: 0.9510 - val_loss: 0.0291 - val_accuracy: 0.9250\n",
      "Epoch 1120/2000\n",
      "1000/1000 [==============================] - 1s 534us/step - loss: 0.0159 - accuracy: 0.9500 - val_loss: 0.0244 - val_accuracy: 0.9250\n",
      "Epoch 1121/2000\n",
      "1000/1000 [==============================] - 1s 533us/step - loss: 0.0135 - accuracy: 0.9380 - val_loss: 0.0160 - val_accuracy: 0.9500\n",
      "Epoch 1122/2000\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 0.0236 - accuracy: 0.9360 - val_loss: 0.0246 - val_accuracy: 0.9500\n",
      "Epoch 1123/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0147 - accuracy: 0.9430 - val_loss: 0.0320 - val_accuracy: 0.9750\n",
      "Epoch 1124/2000\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.0150 - accuracy: 0.9430 - val_loss: 0.0472 - val_accuracy: 0.9500\n",
      "Epoch 1125/2000\n",
      "1000/1000 [==============================] - 1s 538us/step - loss: 0.0205 - accuracy: 0.9400 - val_loss: 0.0249 - val_accuracy: 0.9250\n",
      "Epoch 1126/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0218 - accuracy: 0.9350 - val_loss: 0.0216 - val_accuracy: 0.9250\n",
      "Epoch 1127/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0251 - accuracy: 0.9410 - val_loss: 0.0408 - val_accuracy: 0.9000\n",
      "Epoch 1128/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0154 - accuracy: 0.9480 - val_loss: 0.0321 - val_accuracy: 0.9250\n",
      "Epoch 1129/2000\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.0120 - accuracy: 0.9410 - val_loss: 0.0395 - val_accuracy: 0.8750\n",
      "Epoch 1130/2000\n",
      "1000/1000 [==============================] - 1s 556us/step - loss: 0.0156 - accuracy: 0.9420 - val_loss: 0.0114 - val_accuracy: 0.9250\n",
      "Epoch 1131/2000\n",
      "1000/1000 [==============================] - 1s 563us/step - loss: 0.0204 - accuracy: 0.9350 - val_loss: 0.0321 - val_accuracy: 0.9250\n",
      "Epoch 1132/2000\n",
      "1000/1000 [==============================] - 1s 577us/step - loss: 0.0151 - accuracy: 0.9420 - val_loss: 0.0176 - val_accuracy: 0.9500\n",
      "Epoch 1133/2000\n",
      "1000/1000 [==============================] - 1s 577us/step - loss: 0.0237 - accuracy: 0.9450 - val_loss: 0.0169 - val_accuracy: 0.9500\n",
      "Epoch 1134/2000\n",
      "1000/1000 [==============================] - 1s 577us/step - loss: 0.0199 - accuracy: 0.9420 - val_loss: 0.0347 - val_accuracy: 0.9250\n",
      "Epoch 1135/2000\n",
      "1000/1000 [==============================] - 1s 582us/step - loss: 0.0143 - accuracy: 0.9430 - val_loss: 0.0240 - val_accuracy: 0.9250\n",
      "Epoch 1136/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0215 - accuracy: 0.9300 - val_loss: 0.0163 - val_accuracy: 0.9250\n",
      "Epoch 1137/2000\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 0.0384 - accuracy: 0.9350 - val_loss: 0.0539 - val_accuracy: 0.9250\n",
      "Epoch 1138/2000\n",
      "1000/1000 [==============================] - 1s 542us/step - loss: 0.0276 - accuracy: 0.9330 - val_loss: 0.0316 - val_accuracy: 0.9250\n",
      "Epoch 1139/2000\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 0.0153 - accuracy: 0.9430 - val_loss: 0.0687 - val_accuracy: 0.8750\n",
      "Epoch 1140/2000\n",
      "1000/1000 [==============================] - 1s 556us/step - loss: 0.0256 - accuracy: 0.9340 - val_loss: 0.0292 - val_accuracy: 0.9000\n",
      "Epoch 1141/2000\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 0.0135 - accuracy: 0.9480 - val_loss: 0.0179 - val_accuracy: 0.9000\n",
      "Epoch 1142/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0158 - accuracy: 0.9410 - val_loss: 0.1135 - val_accuracy: 0.9000\n",
      "Epoch 1143/2000\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0176 - accuracy: 0.9400 - val_loss: 0.0146 - val_accuracy: 0.9000\n",
      "Epoch 1144/2000\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0175 - accuracy: 0.9320 - val_loss: 0.0849 - val_accuracy: 0.8750\n",
      "Epoch 1145/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 580us/step - loss: 0.0252 - accuracy: 0.9420 - val_loss: 0.0157 - val_accuracy: 0.9500\n",
      "Epoch 1146/2000\n",
      "1000/1000 [==============================] - 1s 567us/step - loss: 0.0178 - accuracy: 0.9470 - val_loss: 0.0380 - val_accuracy: 0.9250\n",
      "Epoch 1147/2000\n",
      "1000/1000 [==============================] - 1s 552us/step - loss: 0.0135 - accuracy: 0.9430 - val_loss: 0.0195 - val_accuracy: 0.9000\n",
      "Epoch 1148/2000\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0136 - accuracy: 0.9390 - val_loss: 0.0142 - val_accuracy: 0.8750\n",
      "Epoch 1149/2000\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0149 - accuracy: 0.9430 - val_loss: 0.0405 - val_accuracy: 0.9000\n",
      "Epoch 1150/2000\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0230 - accuracy: 0.9350 - val_loss: 0.0361 - val_accuracy: 0.9250\n",
      "Epoch 1151/2000\n",
      "1000/1000 [==============================] - 1s 607us/step - loss: 0.0138 - accuracy: 0.9400 - val_loss: 0.0193 - val_accuracy: 0.9250\n",
      "Epoch 1152/2000\n",
      "1000/1000 [==============================] - 1s 542us/step - loss: 0.0160 - accuracy: 0.9470 - val_loss: 0.0504 - val_accuracy: 0.9500\n",
      "Epoch 1153/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0165 - accuracy: 0.9490 - val_loss: 0.0385 - val_accuracy: 0.9000\n",
      "Epoch 1154/2000\n",
      "1000/1000 [==============================] - 1s 533us/step - loss: 0.0135 - accuracy: 0.9450 - val_loss: 0.0413 - val_accuracy: 0.9250\n",
      "Epoch 1155/2000\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 0.0140 - accuracy: 0.9480 - val_loss: 0.0206 - val_accuracy: 0.9000\n",
      "Epoch 1156/2000\n",
      "1000/1000 [==============================] - 1s 616us/step - loss: 0.0205 - accuracy: 0.9550 - val_loss: 0.0378 - val_accuracy: 0.9250\n",
      "Epoch 1157/2000\n",
      "1000/1000 [==============================] - 1s 607us/step - loss: 0.0275 - accuracy: 0.9470 - val_loss: 0.0197 - val_accuracy: 0.9250\n",
      "Epoch 1158/2000\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0210 - accuracy: 0.9360 - val_loss: 0.0142 - val_accuracy: 0.9500\n",
      "Epoch 1159/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0173 - accuracy: 0.9360 - val_loss: 0.0276 - val_accuracy: 0.9500\n",
      "Epoch 1160/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0180 - accuracy: 0.9410 - val_loss: 0.0294 - val_accuracy: 0.9250\n",
      "Epoch 1161/2000\n",
      "1000/1000 [==============================] - 1s 564us/step - loss: 0.0186 - accuracy: 0.9500 - val_loss: 0.0306 - val_accuracy: 0.9250\n",
      "Epoch 1162/2000\n",
      "1000/1000 [==============================] - 1s 555us/step - loss: 0.0142 - accuracy: 0.9460 - val_loss: 0.0288 - val_accuracy: 0.9250\n",
      "Epoch 1163/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0206 - accuracy: 0.9400 - val_loss: 0.0353 - val_accuracy: 0.9750\n",
      "Epoch 1164/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0243 - accuracy: 0.9400 - val_loss: 0.0305 - val_accuracy: 0.9500\n",
      "Epoch 1165/2000\n",
      "1000/1000 [==============================] - 1s 507us/step - loss: 0.0172 - accuracy: 0.9450 - val_loss: 0.0169 - val_accuracy: 0.9750\n",
      "Epoch 1166/2000\n",
      "1000/1000 [==============================] - 1s 504us/step - loss: 0.0202 - accuracy: 0.9440 - val_loss: 0.0485 - val_accuracy: 0.9250\n",
      "Epoch 1167/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0193 - accuracy: 0.9440 - val_loss: 0.0159 - val_accuracy: 0.9500\n",
      "Epoch 1168/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0143 - accuracy: 0.9360 - val_loss: 0.0453 - val_accuracy: 0.9500\n",
      "Epoch 1169/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.0163 - accuracy: 0.9410 - val_loss: 0.0230 - val_accuracy: 0.9250\n",
      "Epoch 1170/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0273 - accuracy: 0.9380 - val_loss: 0.0238 - val_accuracy: 0.9500\n",
      "Epoch 1171/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0137 - accuracy: 0.9420 - val_loss: 0.0509 - val_accuracy: 0.9000\n",
      "Epoch 1172/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0138 - accuracy: 0.9400 - val_loss: 0.0228 - val_accuracy: 0.9250\n",
      "Epoch 1173/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0131 - accuracy: 0.9400 - val_loss: 0.0175 - val_accuracy: 0.9250\n",
      "Epoch 1174/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0172 - accuracy: 0.9410 - val_loss: 0.0867 - val_accuracy: 0.9000\n",
      "Epoch 1175/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0182 - accuracy: 0.9390 - val_loss: 0.0138 - val_accuracy: 0.9500\n",
      "Epoch 1176/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0145 - accuracy: 0.9340 - val_loss: 0.0218 - val_accuracy: 0.9500\n",
      "Epoch 1177/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0159 - accuracy: 0.9500 - val_loss: 0.0190 - val_accuracy: 0.9250\n",
      "Epoch 1178/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0157 - accuracy: 0.9440 - val_loss: 0.0202 - val_accuracy: 0.9250\n",
      "Epoch 1179/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.0111 - accuracy: 0.9400 - val_loss: 0.0172 - val_accuracy: 0.9000\n",
      "Epoch 1180/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0143 - accuracy: 0.9340 - val_loss: 0.0211 - val_accuracy: 0.9250\n",
      "Epoch 1181/2000\n",
      "1000/1000 [==============================] - 1s 531us/step - loss: 0.0170 - accuracy: 0.9380 - val_loss: 0.0438 - val_accuracy: 0.9250\n",
      "Epoch 1182/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0126 - accuracy: 0.9350 - val_loss: 0.0265 - val_accuracy: 0.9500\n",
      "Epoch 1183/2000\n",
      "1000/1000 [==============================] - 1s 529us/step - loss: 0.0193 - accuracy: 0.9400 - val_loss: 0.0227 - val_accuracy: 0.9000\n",
      "Epoch 1184/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0135 - accuracy: 0.9320 - val_loss: 0.0252 - val_accuracy: 0.9500\n",
      "Epoch 1185/2000\n",
      "1000/1000 [==============================] - 1s 531us/step - loss: 0.0168 - accuracy: 0.9500 - val_loss: 0.0183 - val_accuracy: 0.9000\n",
      "Epoch 1186/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0128 - accuracy: 0.9330 - val_loss: 0.0183 - val_accuracy: 0.9500\n",
      "Epoch 1187/2000\n",
      "1000/1000 [==============================] - 1s 534us/step - loss: 0.0241 - accuracy: 0.9530 - val_loss: 0.0283 - val_accuracy: 0.8750\n",
      "Epoch 1188/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0196 - accuracy: 0.9350 - val_loss: 0.0609 - val_accuracy: 0.9000\n",
      "Epoch 1189/2000\n",
      "1000/1000 [==============================] - 1s 534us/step - loss: 0.0184 - accuracy: 0.9380 - val_loss: 0.0315 - val_accuracy: 0.9250\n",
      "Epoch 1190/2000\n",
      "1000/1000 [==============================] - 1s 552us/step - loss: 0.0148 - accuracy: 0.9320 - val_loss: 0.0390 - val_accuracy: 0.9500\n",
      "Epoch 1191/2000\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 0.0207 - accuracy: 0.9420 - val_loss: 0.0123 - val_accuracy: 0.9000\n",
      "Epoch 1192/2000\n",
      "1000/1000 [==============================] - 1s 549us/step - loss: 0.0129 - accuracy: 0.9460 - val_loss: 0.0223 - val_accuracy: 0.9500\n",
      "Epoch 1193/2000\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0105 - accuracy: 0.9370 - val_loss: 0.0290 - val_accuracy: 0.9500\n",
      "Epoch 1194/2000\n",
      "1000/1000 [==============================] - 1s 571us/step - loss: 0.0139 - accuracy: 0.9440 - val_loss: 0.0278 - val_accuracy: 0.9000\n",
      "Epoch 1195/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0203 - accuracy: 0.9370 - val_loss: 0.0135 - val_accuracy: 0.9500\n",
      "Epoch 1196/2000\n",
      "1000/1000 [==============================] - 1s 552us/step - loss: 0.0277 - accuracy: 0.9210 - val_loss: 0.0241 - val_accuracy: 0.9500\n",
      "Epoch 1197/2000\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0226 - accuracy: 0.9230 - val_loss: 0.0402 - val_accuracy: 0.9000\n",
      "Epoch 1198/2000\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.0121 - accuracy: 0.9240 - val_loss: 0.0145 - val_accuracy: 0.9250\n",
      "Epoch 1199/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 607us/step - loss: 0.0155 - accuracy: 0.9390 - val_loss: 0.0213 - val_accuracy: 0.9500\n",
      "Epoch 1200/2000\n",
      "1000/1000 [==============================] - 1s 544us/step - loss: 0.0177 - accuracy: 0.9330 - val_loss: 0.0181 - val_accuracy: 0.9250\n",
      "Epoch 1201/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0176 - accuracy: 0.9410 - val_loss: 0.0257 - val_accuracy: 0.9000\n",
      "Epoch 1202/2000\n",
      "1000/1000 [==============================] - 1s 542us/step - loss: 0.0108 - accuracy: 0.9490 - val_loss: 0.0189 - val_accuracy: 0.9250\n",
      "Epoch 1203/2000\n",
      "1000/1000 [==============================] - 1s 542us/step - loss: 0.0287 - accuracy: 0.9490 - val_loss: 0.0127 - val_accuracy: 0.9250\n",
      "Epoch 1204/2000\n",
      "1000/1000 [==============================] - 1s 531us/step - loss: 0.0172 - accuracy: 0.9400 - val_loss: 0.0291 - val_accuracy: 0.9000\n",
      "Epoch 1205/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0161 - accuracy: 0.9350 - val_loss: 0.0167 - val_accuracy: 0.9500\n",
      "Epoch 1206/2000\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0138 - accuracy: 0.9410 - val_loss: 0.0570 - val_accuracy: 0.9000\n",
      "Epoch 1207/2000\n",
      "1000/1000 [==============================] - 1s 577us/step - loss: 0.0219 - accuracy: 0.9470 - val_loss: 0.0152 - val_accuracy: 0.9250\n",
      "Epoch 1208/2000\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 0.0148 - accuracy: 0.9470 - val_loss: 0.0331 - val_accuracy: 0.9250\n",
      "Epoch 1209/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0215 - accuracy: 0.9310 - val_loss: 0.0173 - val_accuracy: 0.9250\n",
      "Epoch 1210/2000\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 0.0186 - accuracy: 0.9370 - val_loss: 0.1643 - val_accuracy: 0.8500\n",
      "Epoch 1211/2000\n",
      "1000/1000 [==============================] - 1s 580us/step - loss: 0.0278 - accuracy: 0.9370 - val_loss: 0.0274 - val_accuracy: 0.9000\n",
      "Epoch 1212/2000\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 0.0107 - accuracy: 0.9440 - val_loss: 0.0273 - val_accuracy: 0.9000\n",
      "Epoch 1213/2000\n",
      "1000/1000 [==============================] - 1s 549us/step - loss: 0.0246 - accuracy: 0.9330 - val_loss: 0.0176 - val_accuracy: 0.9500\n",
      "Epoch 1214/2000\n",
      "1000/1000 [==============================] - 1s 542us/step - loss: 0.0180 - accuracy: 0.9390 - val_loss: 0.0249 - val_accuracy: 0.9250\n",
      "Epoch 1215/2000\n",
      "1000/1000 [==============================] - 1s 557us/step - loss: 0.0155 - accuracy: 0.9430 - val_loss: 0.0203 - val_accuracy: 0.9500\n",
      "Epoch 1216/2000\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 0.0215 - accuracy: 0.9510 - val_loss: 0.0176 - val_accuracy: 0.9000\n",
      "Epoch 1217/2000\n",
      "1000/1000 [==============================] - 1s 560us/step - loss: 0.0134 - accuracy: 0.9400 - val_loss: 0.0298 - val_accuracy: 0.8750\n",
      "Epoch 1218/2000\n",
      "1000/1000 [==============================] - 1s 561us/step - loss: 0.0142 - accuracy: 0.9390 - val_loss: 0.0330 - val_accuracy: 0.9250\n",
      "Epoch 1219/2000\n",
      "1000/1000 [==============================] - 1s 580us/step - loss: 0.0194 - accuracy: 0.9290 - val_loss: 0.0392 - val_accuracy: 0.9250\n",
      "Epoch 1220/2000\n",
      "1000/1000 [==============================] - 1s 576us/step - loss: 0.0181 - accuracy: 0.9470 - val_loss: 0.0265 - val_accuracy: 0.9000\n",
      "Epoch 1221/2000\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 0.0226 - accuracy: 0.9360 - val_loss: 0.0214 - val_accuracy: 0.9250\n",
      "Epoch 1222/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0189 - accuracy: 0.9490 - val_loss: 0.0299 - val_accuracy: 0.9500\n",
      "Epoch 1223/2000\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0333 - accuracy: 0.9460 - val_loss: 0.0548 - val_accuracy: 0.9000\n",
      "Epoch 1224/2000\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0291 - accuracy: 0.9380 - val_loss: 0.2719 - val_accuracy: 0.9500\n",
      "Epoch 1225/2000\n",
      "1000/1000 [==============================] - 1s 572us/step - loss: 0.0148 - accuracy: 0.9450 - val_loss: 0.0129 - val_accuracy: 0.9500\n",
      "Epoch 1226/2000\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0167 - accuracy: 0.9390 - val_loss: 0.0176 - val_accuracy: 0.9000\n",
      "Epoch 1227/2000\n",
      "1000/1000 [==============================] - 1s 582us/step - loss: 0.0291 - accuracy: 0.9460 - val_loss: 0.0170 - val_accuracy: 0.9000\n",
      "Epoch 1228/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0161 - accuracy: 0.9480 - val_loss: 0.0138 - val_accuracy: 0.9500\n",
      "Epoch 1229/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0154 - accuracy: 0.9470 - val_loss: 0.0248 - val_accuracy: 0.9250\n",
      "Epoch 1230/2000\n",
      "1000/1000 [==============================] - 1s 538us/step - loss: 0.0118 - accuracy: 0.9390 - val_loss: 0.0159 - val_accuracy: 0.9250\n",
      "Epoch 1231/2000\n",
      "1000/1000 [==============================] - 1s 569us/step - loss: 0.0155 - accuracy: 0.9480 - val_loss: 0.0188 - val_accuracy: 0.9250\n",
      "Epoch 1232/2000\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.0120 - accuracy: 0.9490 - val_loss: 0.0288 - val_accuracy: 0.9250\n",
      "Epoch 1233/2000\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 0.0248 - accuracy: 0.9370 - val_loss: 0.0227 - val_accuracy: 0.8750\n",
      "Epoch 1234/2000\n",
      "1000/1000 [==============================] - 1s 628us/step - loss: 0.0262 - accuracy: 0.9420 - val_loss: 0.0350 - val_accuracy: 0.9500\n",
      "Epoch 1235/2000\n",
      "1000/1000 [==============================] - 1s 567us/step - loss: 0.0110 - accuracy: 0.9620 - val_loss: 0.0228 - val_accuracy: 0.9250\n",
      "Epoch 1236/2000\n",
      "1000/1000 [==============================] - 1s 555us/step - loss: 0.0168 - accuracy: 0.9450 - val_loss: 0.0218 - val_accuracy: 0.9250\n",
      "Epoch 1237/2000\n",
      "1000/1000 [==============================] - 1s 580us/step - loss: 0.0114 - accuracy: 0.9490 - val_loss: 0.0100 - val_accuracy: 0.9000\n",
      "Epoch 1238/2000\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 0.0172 - accuracy: 0.9470 - val_loss: 0.0209 - val_accuracy: 0.8750\n",
      "Epoch 1239/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0193 - accuracy: 0.9380 - val_loss: 0.0226 - val_accuracy: 0.9250\n",
      "Epoch 1240/2000\n",
      "1000/1000 [==============================] - 1s 569us/step - loss: 0.0154 - accuracy: 0.9450 - val_loss: 0.0297 - val_accuracy: 0.9000\n",
      "Epoch 1241/2000\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 0.0295 - accuracy: 0.9420 - val_loss: 0.0186 - val_accuracy: 0.9000\n",
      "Epoch 1242/2000\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0151 - accuracy: 0.9430 - val_loss: 0.0354 - val_accuracy: 0.8750\n",
      "Epoch 1243/2000\n",
      "1000/1000 [==============================] - 1s 564us/step - loss: 0.0199 - accuracy: 0.9470 - val_loss: 0.0417 - val_accuracy: 0.9000\n",
      "Epoch 1244/2000\n",
      "1000/1000 [==============================] - 1s 578us/step - loss: 0.0138 - accuracy: 0.9390 - val_loss: 0.0252 - val_accuracy: 0.9750\n",
      "Epoch 1245/2000\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0191 - accuracy: 0.9490 - val_loss: 0.0574 - val_accuracy: 0.9250\n",
      "Epoch 1246/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0372 - accuracy: 0.9360 - val_loss: 0.0160 - val_accuracy: 0.9250\n",
      "Epoch 1247/2000\n",
      "1000/1000 [==============================] - 1s 559us/step - loss: 0.0205 - accuracy: 0.9320 - val_loss: 0.0275 - val_accuracy: 0.9250\n",
      "Epoch 1248/2000\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0156 - accuracy: 0.9450 - val_loss: 0.0462 - val_accuracy: 0.9000\n",
      "Epoch 1249/2000\n",
      "1000/1000 [==============================] - 1s 559us/step - loss: 0.1024 - accuracy: 0.9250 - val_loss: 0.0323 - val_accuracy: 0.9250\n",
      "Epoch 1250/2000\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 0.0145 - accuracy: 0.9390 - val_loss: 0.0421 - val_accuracy: 0.9000\n",
      "Epoch 1251/2000\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0357 - accuracy: 0.9330 - val_loss: 0.0366 - val_accuracy: 0.9000\n",
      "Epoch 1252/2000\n",
      "1000/1000 [==============================] - 1s 567us/step - loss: 0.0267 - accuracy: 0.9460 - val_loss: 0.0164 - val_accuracy: 0.9500\n",
      "Epoch 1253/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 553us/step - loss: 0.0338 - accuracy: 0.9280 - val_loss: 0.0175 - val_accuracy: 0.9250\n",
      "Epoch 1254/2000\n",
      "1000/1000 [==============================] - 1s 562us/step - loss: 0.0135 - accuracy: 0.9400 - val_loss: 0.0927 - val_accuracy: 0.9500\n",
      "Epoch 1255/2000\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 0.0110 - accuracy: 0.9440 - val_loss: 0.0211 - val_accuracy: 0.9000\n",
      "Epoch 1256/2000\n",
      "1000/1000 [==============================] - 1s 549us/step - loss: 0.0241 - accuracy: 0.9420 - val_loss: 0.0254 - val_accuracy: 0.9000\n",
      "Epoch 1257/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0158 - accuracy: 0.9430 - val_loss: 0.0164 - val_accuracy: 0.9250\n",
      "Epoch 1258/2000\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 0.0123 - accuracy: 0.9420 - val_loss: 0.0402 - val_accuracy: 0.8750\n",
      "Epoch 1259/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0154 - accuracy: 0.9480 - val_loss: 0.0204 - val_accuracy: 0.9000\n",
      "Epoch 1260/2000\n",
      "1000/1000 [==============================] - 1s 573us/step - loss: 0.0220 - accuracy: 0.9430 - val_loss: 0.0798 - val_accuracy: 0.8750\n",
      "Epoch 1261/2000\n",
      "1000/1000 [==============================] - 1s 580us/step - loss: 0.0192 - accuracy: 0.9380 - val_loss: 0.0190 - val_accuracy: 0.9000\n",
      "Epoch 1262/2000\n",
      "1000/1000 [==============================] - 1s 569us/step - loss: 0.0172 - accuracy: 0.9380 - val_loss: 0.0543 - val_accuracy: 0.9250\n",
      "Epoch 1263/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0203 - accuracy: 0.9510 - val_loss: 0.0832 - val_accuracy: 0.9250\n",
      "Epoch 1264/2000\n",
      "1000/1000 [==============================] - 1s 549us/step - loss: 0.0196 - accuracy: 0.9390 - val_loss: 0.0511 - val_accuracy: 0.9250\n",
      "Epoch 1265/2000\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 0.0130 - accuracy: 0.9530 - val_loss: 0.0316 - val_accuracy: 0.9000\n",
      "Epoch 1266/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0246 - accuracy: 0.9450 - val_loss: 0.0442 - val_accuracy: 0.9000\n",
      "Epoch 1267/2000\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 0.0131 - accuracy: 0.9450 - val_loss: 0.0262 - val_accuracy: 0.9000\n",
      "Epoch 1268/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0171 - accuracy: 0.9490 - val_loss: 0.0191 - val_accuracy: 0.9500\n",
      "Epoch 1269/2000\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.0210 - accuracy: 0.9400 - val_loss: 0.0165 - val_accuracy: 0.9000\n",
      "Epoch 1270/2000\n",
      "1000/1000 [==============================] - 1s 577us/step - loss: 0.0117 - accuracy: 0.9500 - val_loss: 0.0313 - val_accuracy: 0.9500\n",
      "Epoch 1271/2000\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0197 - accuracy: 0.9440 - val_loss: 0.0490 - val_accuracy: 0.9500\n",
      "Epoch 1272/2000\n",
      "1000/1000 [==============================] - 1s 610us/step - loss: 0.0194 - accuracy: 0.9430 - val_loss: 0.0241 - val_accuracy: 0.9250\n",
      "Epoch 1273/2000\n",
      "1000/1000 [==============================] - 1s 622us/step - loss: 0.0193 - accuracy: 0.9510 - val_loss: 0.0342 - val_accuracy: 0.9000\n",
      "Epoch 1274/2000\n",
      "1000/1000 [==============================] - 1s 620us/step - loss: 0.0211 - accuracy: 0.9380 - val_loss: 0.0267 - val_accuracy: 0.9000\n",
      "Epoch 1275/2000\n",
      "1000/1000 [==============================] - 1s 687us/step - loss: 0.0186 - accuracy: 0.9420 - val_loss: 0.0694 - val_accuracy: 0.9250\n",
      "Epoch 1276/2000\n",
      "1000/1000 [==============================] - 1s 687us/step - loss: 0.0191 - accuracy: 0.9500 - val_loss: 0.0196 - val_accuracy: 0.9250\n",
      "Epoch 1277/2000\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0221 - accuracy: 0.9500 - val_loss: 0.0127 - val_accuracy: 0.9500\n",
      "Epoch 1278/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0122 - accuracy: 0.9390 - val_loss: 0.0191 - val_accuracy: 0.9250\n",
      "Epoch 1279/2000\n",
      "1000/1000 [==============================] - 1s 552us/step - loss: 0.0231 - accuracy: 0.9220 - val_loss: 0.0199 - val_accuracy: 0.8750\n",
      "Epoch 1280/2000\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 0.0117 - accuracy: 0.9500 - val_loss: 0.0119 - val_accuracy: 0.9250\n",
      "Epoch 1281/2000\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.0219 - accuracy: 0.9430 - val_loss: 0.0363 - val_accuracy: 0.9250\n",
      "Epoch 1282/2000\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.0162 - accuracy: 0.9430 - val_loss: 0.0401 - val_accuracy: 0.9250\n",
      "Epoch 1283/2000\n",
      "1000/1000 [==============================] - 1s 615us/step - loss: 0.0249 - accuracy: 0.9490 - val_loss: 0.0266 - val_accuracy: 0.9000\n",
      "Epoch 1284/2000\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 0.0145 - accuracy: 0.9350 - val_loss: 0.0286 - val_accuracy: 0.9000\n",
      "Epoch 1285/2000\n",
      "1000/1000 [==============================] - 1s 572us/step - loss: 0.0169 - accuracy: 0.9400 - val_loss: 0.0510 - val_accuracy: 0.8750\n",
      "Epoch 1286/2000\n",
      "1000/1000 [==============================] - 1s 568us/step - loss: 0.0223 - accuracy: 0.9440 - val_loss: 0.0214 - val_accuracy: 0.9500\n",
      "Epoch 1287/2000\n",
      "1000/1000 [==============================] - 1s 523us/step - loss: 0.0236 - accuracy: 0.9350 - val_loss: 0.0298 - val_accuracy: 0.9000\n",
      "Epoch 1288/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0386 - accuracy: 0.9390 - val_loss: 0.0232 - val_accuracy: 0.9500\n",
      "Epoch 1289/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0241 - accuracy: 0.9380 - val_loss: 0.0730 - val_accuracy: 0.8750\n",
      "Epoch 1290/2000\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.0228 - accuracy: 0.9360 - val_loss: 0.0384 - val_accuracy: 0.9250\n",
      "Epoch 1291/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0165 - accuracy: 0.9490 - val_loss: 0.0172 - val_accuracy: 0.9250\n",
      "Epoch 1292/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0137 - accuracy: 0.9430 - val_loss: 0.0189 - val_accuracy: 0.9500\n",
      "Epoch 1293/2000\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 0.0184 - accuracy: 0.9400 - val_loss: 0.0322 - val_accuracy: 0.9500\n",
      "Epoch 1294/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0154 - accuracy: 0.9450 - val_loss: 0.0120 - val_accuracy: 0.9500\n",
      "Epoch 1295/2000\n",
      "1000/1000 [==============================] - 1s 569us/step - loss: 0.0169 - accuracy: 0.9470 - val_loss: 0.0198 - val_accuracy: 0.9500\n",
      "Epoch 1296/2000\n",
      "1000/1000 [==============================] - 1s 533us/step - loss: 0.0165 - accuracy: 0.9460 - val_loss: 0.0327 - val_accuracy: 0.9500\n",
      "Epoch 1297/2000\n",
      "1000/1000 [==============================] - 1s 579us/step - loss: 0.0123 - accuracy: 0.9540 - val_loss: 0.0308 - val_accuracy: 0.9250\n",
      "Epoch 1298/2000\n",
      "1000/1000 [==============================] - 1s 555us/step - loss: 0.0152 - accuracy: 0.9390 - val_loss: 0.0178 - val_accuracy: 0.9500\n",
      "Epoch 1299/2000\n",
      "1000/1000 [==============================] - 1s 573us/step - loss: 0.0155 - accuracy: 0.9430 - val_loss: 0.0232 - val_accuracy: 0.9000\n",
      "Epoch 1300/2000\n",
      "1000/1000 [==============================] - 1s 538us/step - loss: 0.0144 - accuracy: 0.9500 - val_loss: 0.0180 - val_accuracy: 0.9250\n",
      "Epoch 1301/2000\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0110 - accuracy: 0.9370 - val_loss: 0.0245 - val_accuracy: 0.9250\n",
      "Epoch 1302/2000\n",
      "1000/1000 [==============================] - 1s 577us/step - loss: 0.0168 - accuracy: 0.9370 - val_loss: 0.0219 - val_accuracy: 0.8750\n",
      "Epoch 1303/2000\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 0.0173 - accuracy: 0.9450 - val_loss: 0.0152 - val_accuracy: 0.9000\n",
      "Epoch 1304/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0099 - accuracy: 0.9300 - val_loss: 0.0340 - val_accuracy: 0.9250\n",
      "Epoch 1305/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0246 - accuracy: 0.9350 - val_loss: 0.0136 - val_accuracy: 0.9000\n",
      "Epoch 1306/2000\n",
      "1000/1000 [==============================] - 1s 616us/step - loss: 0.0143 - accuracy: 0.9500 - val_loss: 0.0881 - val_accuracy: 0.9250\n",
      "Epoch 1307/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 556us/step - loss: 0.0276 - accuracy: 0.9380 - val_loss: 0.0287 - val_accuracy: 0.9250\n",
      "Epoch 1308/2000\n",
      "1000/1000 [==============================] - 1s 556us/step - loss: 0.0141 - accuracy: 0.9430 - val_loss: 0.0142 - val_accuracy: 0.9750\n",
      "Epoch 1309/2000\n",
      "1000/1000 [==============================] - 1s 615us/step - loss: 0.0112 - accuracy: 0.9510 - val_loss: 0.0181 - val_accuracy: 0.9000\n",
      "Epoch 1310/2000\n",
      "1000/1000 [==============================] - 1s 579us/step - loss: 0.0215 - accuracy: 0.9290 - val_loss: 0.0228 - val_accuracy: 0.9250\n",
      "Epoch 1311/2000\n",
      "1000/1000 [==============================] - 1s 607us/step - loss: 0.0147 - accuracy: 0.9360 - val_loss: 0.0270 - val_accuracy: 0.9500\n",
      "Epoch 1312/2000\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 0.0205 - accuracy: 0.9380 - val_loss: 0.0377 - val_accuracy: 0.9250\n",
      "Epoch 1313/2000\n",
      "1000/1000 [==============================] - 1s 611us/step - loss: 0.0146 - accuracy: 0.9290 - val_loss: 0.0272 - val_accuracy: 0.9000\n",
      "Epoch 1314/2000\n",
      "1000/1000 [==============================] - 1s 769us/step - loss: 0.0312 - accuracy: 0.9340 - val_loss: 0.0284 - val_accuracy: 0.9250\n",
      "Epoch 1315/2000\n",
      "1000/1000 [==============================] - 1s 651us/step - loss: 0.0126 - accuracy: 0.9470 - val_loss: 0.0200 - val_accuracy: 0.9000\n",
      "Epoch 1316/2000\n",
      "1000/1000 [==============================] - 1s 555us/step - loss: 0.0143 - accuracy: 0.9410 - val_loss: 0.0181 - val_accuracy: 0.9500\n",
      "Epoch 1317/2000\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 0.0122 - accuracy: 0.9460 - val_loss: 0.0151 - val_accuracy: 0.9000\n",
      "Epoch 1318/2000\n",
      "1000/1000 [==============================] - 1s 562us/step - loss: 0.0193 - accuracy: 0.9350 - val_loss: 0.0281 - val_accuracy: 0.9250\n",
      "Epoch 1319/2000\n",
      "1000/1000 [==============================] - 1s 668us/step - loss: 0.0134 - accuracy: 0.9400 - val_loss: 0.0155 - val_accuracy: 0.9250\n",
      "Epoch 1320/2000\n",
      "1000/1000 [==============================] - 1s 710us/step - loss: 0.0103 - accuracy: 0.9510 - val_loss: 0.0375 - val_accuracy: 0.9750\n",
      "Epoch 1321/2000\n",
      "1000/1000 [==============================] - 1s 559us/step - loss: 0.0168 - accuracy: 0.9500 - val_loss: 0.0211 - val_accuracy: 0.9250\n",
      "Epoch 1322/2000\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.0120 - accuracy: 0.9450 - val_loss: 0.1329 - val_accuracy: 0.9000\n",
      "Epoch 1323/2000\n",
      "1000/1000 [==============================] - 1s 562us/step - loss: 0.0143 - accuracy: 0.9420 - val_loss: 0.0203 - val_accuracy: 0.9500\n",
      "Epoch 1324/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0165 - accuracy: 0.9310 - val_loss: 0.0178 - val_accuracy: 0.9250\n",
      "Epoch 1325/2000\n",
      "1000/1000 [==============================] - 1s 617us/step - loss: 0.0105 - accuracy: 0.9410 - val_loss: 0.0197 - val_accuracy: 0.9500\n",
      "Epoch 1326/2000\n",
      "1000/1000 [==============================] - 1s 630us/step - loss: 0.0105 - accuracy: 0.9330 - val_loss: 0.0263 - val_accuracy: 0.9250\n",
      "Epoch 1327/2000\n",
      "1000/1000 [==============================] - 1s 580us/step - loss: 0.0133 - accuracy: 0.9450 - val_loss: 0.0341 - val_accuracy: 0.9250\n",
      "Epoch 1328/2000\n",
      "1000/1000 [==============================] - 1s 556us/step - loss: 0.0167 - accuracy: 0.9460 - val_loss: 0.0189 - val_accuracy: 0.9500\n",
      "Epoch 1329/2000\n",
      "1000/1000 [==============================] - 1s 557us/step - loss: 0.0157 - accuracy: 0.9440 - val_loss: 0.0322 - val_accuracy: 0.9000\n",
      "Epoch 1330/2000\n",
      "1000/1000 [==============================] - 1s 543us/step - loss: 0.0204 - accuracy: 0.9370 - val_loss: 0.0525 - val_accuracy: 0.9000\n",
      "Epoch 1331/2000\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0184 - accuracy: 0.9520 - val_loss: 0.0349 - val_accuracy: 0.9000\n",
      "Epoch 1332/2000\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.0101 - accuracy: 0.9490 - val_loss: 0.0172 - val_accuracy: 0.9500\n",
      "Epoch 1333/2000\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0111 - accuracy: 0.9460 - val_loss: 0.0275 - val_accuracy: 0.9250\n",
      "Epoch 1334/2000\n",
      "1000/1000 [==============================] - 1s 580us/step - loss: 0.0105 - accuracy: 0.9440 - val_loss: 0.0151 - val_accuracy: 0.9000\n",
      "Epoch 1335/2000\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 0.0084 - accuracy: 0.9390 - val_loss: 0.0190 - val_accuracy: 0.9000\n",
      "Epoch 1336/2000\n",
      "1000/1000 [==============================] - 1s 555us/step - loss: 0.0098 - accuracy: 0.9520 - val_loss: 0.0305 - val_accuracy: 0.9250\n",
      "Epoch 1337/2000\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.0172 - accuracy: 0.9410 - val_loss: 0.0166 - val_accuracy: 0.8750\n",
      "Epoch 1338/2000\n",
      "1000/1000 [==============================] - 1s 542us/step - loss: 0.0133 - accuracy: 0.9420 - val_loss: 0.0167 - val_accuracy: 0.9000\n",
      "Epoch 1339/2000\n",
      "1000/1000 [==============================] - 1s 538us/step - loss: 0.0099 - accuracy: 0.9470 - val_loss: 0.0321 - val_accuracy: 0.9000\n",
      "Epoch 1340/2000\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 0.0192 - accuracy: 0.9460 - val_loss: 0.0251 - val_accuracy: 0.8500\n",
      "Epoch 1341/2000\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.0249 - accuracy: 0.9400 - val_loss: 0.0138 - val_accuracy: 0.9750\n",
      "Epoch 1342/2000\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.0220 - accuracy: 0.9470 - val_loss: 0.0168 - val_accuracy: 0.9000\n",
      "Epoch 1343/2000\n",
      "1000/1000 [==============================] - 1s 542us/step - loss: 0.0135 - accuracy: 0.9430 - val_loss: 0.0185 - val_accuracy: 0.8750\n",
      "Epoch 1344/2000\n",
      "1000/1000 [==============================] - 1s 533us/step - loss: 0.0136 - accuracy: 0.9350 - val_loss: 0.0135 - val_accuracy: 0.9000\n",
      "Epoch 1345/2000\n",
      "1000/1000 [==============================] - 1s 549us/step - loss: 0.0108 - accuracy: 0.9300 - val_loss: 0.0132 - val_accuracy: 0.8750\n",
      "Epoch 1346/2000\n",
      "1000/1000 [==============================] - 1s 601us/step - loss: 0.0208 - accuracy: 0.9350 - val_loss: 0.0145 - val_accuracy: 0.8750\n",
      "Epoch 1347/2000\n",
      "1000/1000 [==============================] - 1s 573us/step - loss: 0.0117 - accuracy: 0.9440 - val_loss: 0.0343 - val_accuracy: 0.9250\n",
      "Epoch 1348/2000\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0135 - accuracy: 0.9380 - val_loss: 0.0163 - val_accuracy: 0.9250\n",
      "Epoch 1349/2000\n",
      "1000/1000 [==============================] - 1s 613us/step - loss: 0.0095 - accuracy: 0.9430 - val_loss: 0.0222 - val_accuracy: 0.9250\n",
      "Epoch 1350/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0099 - accuracy: 0.9430 - val_loss: 0.0287 - val_accuracy: 0.9000\n",
      "Epoch 1351/2000\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 0.0111 - accuracy: 0.9430 - val_loss: 0.0142 - val_accuracy: 0.9000\n",
      "Epoch 1352/2000\n",
      "1000/1000 [==============================] - 1s 570us/step - loss: 0.0151 - accuracy: 0.9300 - val_loss: 0.0225 - val_accuracy: 0.9250\n",
      "Epoch 1353/2000\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0169 - accuracy: 0.9450 - val_loss: 0.0189 - val_accuracy: 0.9250\n",
      "Epoch 1354/2000\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0114 - accuracy: 0.9200 - val_loss: 0.0193 - val_accuracy: 0.9250\n",
      "Epoch 1355/2000\n",
      "1000/1000 [==============================] - 1s 564us/step - loss: 0.0098 - accuracy: 0.9450 - val_loss: 0.0230 - val_accuracy: 0.9000\n",
      "Epoch 1356/2000\n",
      "1000/1000 [==============================] - 1s 556us/step - loss: 0.0196 - accuracy: 0.9450 - val_loss: 0.0169 - val_accuracy: 0.9250\n",
      "Epoch 1357/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0136 - accuracy: 0.9380 - val_loss: 0.0227 - val_accuracy: 0.9250\n",
      "Epoch 1358/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0108 - accuracy: 0.9510 - val_loss: 0.0367 - val_accuracy: 0.9250\n",
      "Epoch 1359/2000\n",
      "1000/1000 [==============================] - 1s 542us/step - loss: 0.0104 - accuracy: 0.9430 - val_loss: 0.0198 - val_accuracy: 0.9250\n",
      "Epoch 1360/2000\n",
      "1000/1000 [==============================] - 1s 580us/step - loss: 0.0170 - accuracy: 0.9460 - val_loss: 0.0196 - val_accuracy: 0.8750\n",
      "Epoch 1361/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 570us/step - loss: 0.0112 - accuracy: 0.9400 - val_loss: 0.0218 - val_accuracy: 0.9250\n",
      "Epoch 1362/2000\n",
      "1000/1000 [==============================] - 1s 549us/step - loss: 0.0184 - accuracy: 0.9380 - val_loss: 0.0199 - val_accuracy: 0.9250\n",
      "Epoch 1363/2000\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0173 - accuracy: 0.9400 - val_loss: 0.0256 - val_accuracy: 0.9500\n",
      "Epoch 1364/2000\n",
      "1000/1000 [==============================] - 1s 556us/step - loss: 0.0146 - accuracy: 0.9460 - val_loss: 0.0152 - val_accuracy: 0.9000\n",
      "Epoch 1365/2000\n",
      "1000/1000 [==============================] - 1s 561us/step - loss: 0.0117 - accuracy: 0.9430 - val_loss: 0.0202 - val_accuracy: 0.9250\n",
      "Epoch 1366/2000\n",
      "1000/1000 [==============================] - 1s 560us/step - loss: 0.0114 - accuracy: 0.9370 - val_loss: 0.0167 - val_accuracy: 0.9000\n",
      "Epoch 1367/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0171 - accuracy: 0.9410 - val_loss: 0.1019 - val_accuracy: 0.9250\n",
      "Epoch 1368/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0206 - accuracy: 0.9410 - val_loss: 0.0269 - val_accuracy: 0.9000\n",
      "Epoch 1369/2000\n",
      "1000/1000 [==============================] - 1s 549us/step - loss: 0.0241 - accuracy: 0.9390 - val_loss: 0.0453 - val_accuracy: 0.9250\n",
      "Epoch 1370/2000\n",
      "1000/1000 [==============================] - 1s 542us/step - loss: 0.0162 - accuracy: 0.9430 - val_loss: 0.0133 - val_accuracy: 0.9250\n",
      "Epoch 1371/2000\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 0.0154 - accuracy: 0.9500 - val_loss: 0.0224 - val_accuracy: 0.9250\n",
      "Epoch 1372/2000\n",
      "1000/1000 [==============================] - 1s 538us/step - loss: 0.0157 - accuracy: 0.9370 - val_loss: 0.0325 - val_accuracy: 0.9000\n",
      "Epoch 1373/2000\n",
      "1000/1000 [==============================] - 1s 544us/step - loss: 0.0218 - accuracy: 0.9400 - val_loss: 0.0568 - val_accuracy: 0.9000\n",
      "Epoch 1374/2000\n",
      "1000/1000 [==============================] - 1s 530us/step - loss: 0.0240 - accuracy: 0.9410 - val_loss: 0.0611 - val_accuracy: 0.9250\n",
      "Epoch 1375/2000\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.0400 - accuracy: 0.9420 - val_loss: 0.0210 - val_accuracy: 0.9250\n",
      "Epoch 1376/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0102 - accuracy: 0.9350 - val_loss: 0.0220 - val_accuracy: 0.9250\n",
      "Epoch 1377/2000\n",
      "1000/1000 [==============================] - 1s 542us/step - loss: 0.0152 - accuracy: 0.9430 - val_loss: 0.0149 - val_accuracy: 0.9250\n",
      "Epoch 1378/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0136 - accuracy: 0.9510 - val_loss: 0.0282 - val_accuracy: 0.9250\n",
      "Epoch 1379/2000\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 0.0098 - accuracy: 0.9380 - val_loss: 0.0191 - val_accuracy: 0.9250\n",
      "Epoch 1380/2000\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 0.0118 - accuracy: 0.9430 - val_loss: 0.0250 - val_accuracy: 0.8750\n",
      "Epoch 1381/2000\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0125 - accuracy: 0.9430 - val_loss: 0.0460 - val_accuracy: 0.9000\n",
      "Epoch 1382/2000\n",
      "1000/1000 [==============================] - 1s 578us/step - loss: 0.0176 - accuracy: 0.9520 - val_loss: 0.0302 - val_accuracy: 0.9000\n",
      "Epoch 1383/2000\n",
      "1000/1000 [==============================] - 1s 571us/step - loss: 0.0450 - accuracy: 0.9340 - val_loss: 0.0208 - val_accuracy: 0.9250\n",
      "Epoch 1384/2000\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0245 - accuracy: 0.9380 - val_loss: 0.0225 - val_accuracy: 0.9000\n",
      "Epoch 1385/2000\n",
      "1000/1000 [==============================] - 1s 599us/step - loss: 0.0162 - accuracy: 0.9470 - val_loss: 0.0221 - val_accuracy: 0.9500\n",
      "Epoch 1386/2000\n",
      "1000/1000 [==============================] - 1s 555us/step - loss: 0.0147 - accuracy: 0.9410 - val_loss: 0.0149 - val_accuracy: 0.9250\n",
      "Epoch 1387/2000\n",
      "1000/1000 [==============================] - 1s 574us/step - loss: 0.0148 - accuracy: 0.9420 - val_loss: 0.0201 - val_accuracy: 0.9250\n",
      "Epoch 1388/2000\n",
      "1000/1000 [==============================] - 1s 666us/step - loss: 0.0086 - accuracy: 0.9550 - val_loss: 0.0174 - val_accuracy: 0.9500\n",
      "Epoch 1389/2000\n",
      "1000/1000 [==============================] - 1s 569us/step - loss: 0.0141 - accuracy: 0.9400 - val_loss: 0.0207 - val_accuracy: 0.9000\n",
      "Epoch 1390/2000\n",
      "1000/1000 [==============================] - 1s 574us/step - loss: 0.0135 - accuracy: 0.9510 - val_loss: 0.0122 - val_accuracy: 0.9250\n",
      "Epoch 1391/2000\n",
      "1000/1000 [==============================] - 1s 651us/step - loss: 0.0095 - accuracy: 0.9450 - val_loss: 0.0292 - val_accuracy: 0.9000\n",
      "Epoch 1392/2000\n",
      "1000/1000 [==============================] - 1s 652us/step - loss: 0.0185 - accuracy: 0.9450 - val_loss: 0.0178 - val_accuracy: 0.9000\n",
      "Epoch 1393/2000\n",
      "1000/1000 [==============================] - 1s 645us/step - loss: 0.0151 - accuracy: 0.9460 - val_loss: 0.0149 - val_accuracy: 0.9250\n",
      "Epoch 1394/2000\n",
      "1000/1000 [==============================] - 1s 634us/step - loss: 0.0088 - accuracy: 0.9540 - val_loss: 0.0286 - val_accuracy: 0.9000\n",
      "Epoch 1395/2000\n",
      "1000/1000 [==============================] - 1s 679us/step - loss: 0.0264 - accuracy: 0.9410 - val_loss: 0.0153 - val_accuracy: 0.9250\n",
      "Epoch 1396/2000\n",
      "1000/1000 [==============================] - 1s 649us/step - loss: 0.0203 - accuracy: 0.9550 - val_loss: 0.0304 - val_accuracy: 0.9250\n",
      "Epoch 1397/2000\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0197 - accuracy: 0.9410 - val_loss: 0.0118 - val_accuracy: 0.9250\n",
      "Epoch 1398/2000\n",
      "1000/1000 [==============================] - 1s 562us/step - loss: 0.0108 - accuracy: 0.9480 - val_loss: 0.0218 - val_accuracy: 0.9250\n",
      "Epoch 1399/2000\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0135 - accuracy: 0.9410 - val_loss: 0.0506 - val_accuracy: 0.9250\n",
      "Epoch 1400/2000\n",
      "1000/1000 [==============================] - 1s 652us/step - loss: 0.0148 - accuracy: 0.9380 - val_loss: 0.0275 - val_accuracy: 0.9250\n",
      "Epoch 1401/2000\n",
      "1000/1000 [==============================] - 1s 648us/step - loss: 0.0130 - accuracy: 0.9450 - val_loss: 0.0214 - val_accuracy: 0.9250\n",
      "Epoch 1402/2000\n",
      "1000/1000 [==============================] - 1s 607us/step - loss: 0.0090 - accuracy: 0.9450 - val_loss: 0.0424 - val_accuracy: 0.8750\n",
      "Epoch 1403/2000\n",
      "1000/1000 [==============================] - 1s 570us/step - loss: 0.0095 - accuracy: 0.9390 - val_loss: 0.0250 - val_accuracy: 0.9250\n",
      "Epoch 1404/2000\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 0.0156 - accuracy: 0.9460 - val_loss: 0.0358 - val_accuracy: 0.9250\n",
      "Epoch 1405/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0149 - accuracy: 0.9400 - val_loss: 0.0263 - val_accuracy: 0.9250\n",
      "Epoch 1406/2000\n",
      "1000/1000 [==============================] - 1s 617us/step - loss: 0.0207 - accuracy: 0.9400 - val_loss: 0.0373 - val_accuracy: 0.9500\n",
      "Epoch 1407/2000\n",
      "1000/1000 [==============================] - 1s 672us/step - loss: 0.0182 - accuracy: 0.9340 - val_loss: 0.0122 - val_accuracy: 0.9250\n",
      "Epoch 1408/2000\n",
      "1000/1000 [==============================] - 1s 617us/step - loss: 0.0211 - accuracy: 0.9400 - val_loss: 0.0277 - val_accuracy: 0.9000\n",
      "Epoch 1409/2000\n",
      "1000/1000 [==============================] - 1s 639us/step - loss: 0.0262 - accuracy: 0.9390 - val_loss: 0.0262 - val_accuracy: 0.9250\n",
      "Epoch 1410/2000\n",
      "1000/1000 [==============================] - 1s 606us/step - loss: 0.0140 - accuracy: 0.9500 - val_loss: 0.0209 - val_accuracy: 0.9250\n",
      "Epoch 1411/2000\n",
      "1000/1000 [==============================] - 1s 628us/step - loss: 0.0208 - accuracy: 0.9590 - val_loss: 0.0233 - val_accuracy: 0.9250\n",
      "Epoch 1412/2000\n",
      "1000/1000 [==============================] - 1s 582us/step - loss: 0.0286 - accuracy: 0.9370 - val_loss: 0.0203 - val_accuracy: 0.9250\n",
      "Epoch 1413/2000\n",
      "1000/1000 [==============================] - 1s 627us/step - loss: 0.0132 - accuracy: 0.9430 - val_loss: 0.0202 - val_accuracy: 0.9000\n",
      "Epoch 1414/2000\n",
      "1000/1000 [==============================] - 1s 624us/step - loss: 0.0129 - accuracy: 0.9500 - val_loss: 0.0161 - val_accuracy: 0.9250\n",
      "Epoch 1415/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 582us/step - loss: 0.0165 - accuracy: 0.9470 - val_loss: 0.0181 - val_accuracy: 0.9250\n",
      "Epoch 1416/2000\n",
      "1000/1000 [==============================] - 1s 571us/step - loss: 0.0201 - accuracy: 0.9460 - val_loss: 0.0133 - val_accuracy: 0.9250\n",
      "Epoch 1417/2000\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0121 - accuracy: 0.9380 - val_loss: 0.0228 - val_accuracy: 0.9250\n",
      "Epoch 1418/2000\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.0099 - accuracy: 0.9440 - val_loss: 0.0238 - val_accuracy: 0.9000\n",
      "Epoch 1419/2000\n",
      "1000/1000 [==============================] - 1s 585us/step - loss: 0.0129 - accuracy: 0.9380 - val_loss: 0.0207 - val_accuracy: 0.9000\n",
      "Epoch 1420/2000\n",
      "1000/1000 [==============================] - 1s 579us/step - loss: 0.0128 - accuracy: 0.9420 - val_loss: 0.0196 - val_accuracy: 0.9000\n",
      "Epoch 1421/2000\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 0.0210 - accuracy: 0.9360 - val_loss: 0.0210 - val_accuracy: 0.9000\n",
      "Epoch 1422/2000\n",
      "1000/1000 [==============================] - 1s 549us/step - loss: 0.0206 - accuracy: 0.9320 - val_loss: 0.0215 - val_accuracy: 0.9250\n",
      "Epoch 1423/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0160 - accuracy: 0.9380 - val_loss: 0.0369 - val_accuracy: 0.9000\n",
      "Epoch 1424/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0154 - accuracy: 0.9470 - val_loss: 0.0376 - val_accuracy: 0.9000\n",
      "Epoch 1425/2000\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0088 - accuracy: 0.9460 - val_loss: 0.0175 - val_accuracy: 0.9500\n",
      "Epoch 1426/2000\n",
      "1000/1000 [==============================] - 1s 529us/step - loss: 0.0115 - accuracy: 0.9340 - val_loss: 0.0413 - val_accuracy: 0.9250\n",
      "Epoch 1427/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0103 - accuracy: 0.9400 - val_loss: 0.0114 - val_accuracy: 0.9250\n",
      "Epoch 1428/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0101 - accuracy: 0.9430 - val_loss: 0.0192 - val_accuracy: 0.9000\n",
      "Epoch 1429/2000\n",
      "1000/1000 [==============================] - 1s 526us/step - loss: 0.0133 - accuracy: 0.9320 - val_loss: 0.0455 - val_accuracy: 0.8750\n",
      "Epoch 1430/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0108 - accuracy: 0.9440 - val_loss: 0.0311 - val_accuracy: 0.9250\n",
      "Epoch 1431/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0154 - accuracy: 0.9420 - val_loss: 0.0430 - val_accuracy: 0.9250\n",
      "Epoch 1432/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.0114 - accuracy: 0.9400 - val_loss: 0.0146 - val_accuracy: 0.8750\n",
      "Epoch 1433/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0086 - accuracy: 0.9410 - val_loss: 0.0247 - val_accuracy: 0.9250\n",
      "Epoch 1434/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0150 - accuracy: 0.9360 - val_loss: 0.0364 - val_accuracy: 0.9500\n",
      "Epoch 1435/2000\n",
      "1000/1000 [==============================] - 1s 510us/step - loss: 0.0160 - accuracy: 0.9450 - val_loss: 0.0191 - val_accuracy: 0.8750\n",
      "Epoch 1436/2000\n",
      "1000/1000 [==============================] - 1s 506us/step - loss: 0.0095 - accuracy: 0.9430 - val_loss: 0.0179 - val_accuracy: 0.9250\n",
      "Epoch 1437/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0136 - accuracy: 0.9400 - val_loss: 0.0306 - val_accuracy: 0.9250\n",
      "Epoch 1438/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0109 - accuracy: 0.9450 - val_loss: 0.0324 - val_accuracy: 0.9000\n",
      "Epoch 1439/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0113 - accuracy: 0.9490 - val_loss: 0.0231 - val_accuracy: 0.9250\n",
      "Epoch 1440/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0093 - accuracy: 0.9580 - val_loss: 0.0151 - val_accuracy: 0.9000\n",
      "Epoch 1441/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0121 - accuracy: 0.9530 - val_loss: 0.0116 - val_accuracy: 0.9250\n",
      "Epoch 1442/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0079 - accuracy: 0.9420 - val_loss: 0.0258 - val_accuracy: 0.9250\n",
      "Epoch 1443/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0104 - accuracy: 0.9410 - val_loss: 0.0251 - val_accuracy: 0.9000\n",
      "Epoch 1444/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.0153 - accuracy: 0.9370 - val_loss: 0.0211 - val_accuracy: 0.9000\n",
      "Epoch 1445/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0150 - accuracy: 0.9530 - val_loss: 0.0155 - val_accuracy: 0.9250\n",
      "Epoch 1446/2000\n",
      "1000/1000 [==============================] - 1s 526us/step - loss: 0.0095 - accuracy: 0.9450 - val_loss: 0.0237 - val_accuracy: 0.9000\n",
      "Epoch 1447/2000\n",
      "1000/1000 [==============================] - 1s 525us/step - loss: 0.0281 - accuracy: 0.9400 - val_loss: 0.0262 - val_accuracy: 0.9250\n",
      "Epoch 1448/2000\n",
      "1000/1000 [==============================] - 1s 507us/step - loss: 0.0110 - accuracy: 0.9400 - val_loss: 0.0321 - val_accuracy: 0.9250\n",
      "Epoch 1449/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0091 - accuracy: 0.9470 - val_loss: 0.0166 - val_accuracy: 0.9500\n",
      "Epoch 1450/2000\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 0.0109 - accuracy: 0.9500 - val_loss: 0.0393 - val_accuracy: 0.8750\n",
      "Epoch 1451/2000\n",
      "1000/1000 [==============================] - 1s 510us/step - loss: 0.0159 - accuracy: 0.9510 - val_loss: 0.0420 - val_accuracy: 0.9250\n",
      "Epoch 1452/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0412 - accuracy: 0.9400 - val_loss: 0.0158 - val_accuracy: 0.9250\n",
      "Epoch 1453/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0137 - accuracy: 0.9420 - val_loss: 0.0221 - val_accuracy: 0.9500\n",
      "Epoch 1454/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0165 - accuracy: 0.9410 - val_loss: 0.0128 - val_accuracy: 0.9250\n",
      "Epoch 1455/2000\n",
      "1000/1000 [==============================] - 1s 559us/step - loss: 0.0144 - accuracy: 0.9470 - val_loss: 0.0338 - val_accuracy: 0.9500\n",
      "Epoch 1456/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0113 - accuracy: 0.9370 - val_loss: 0.0244 - val_accuracy: 0.9000\n",
      "Epoch 1457/2000\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.0158 - accuracy: 0.9500 - val_loss: 0.0302 - val_accuracy: 0.9250\n",
      "Epoch 1458/2000\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 0.0127 - accuracy: 0.9550 - val_loss: 0.0220 - val_accuracy: 0.9000\n",
      "Epoch 1459/2000\n",
      "1000/1000 [==============================] - 1s 529us/step - loss: 0.0109 - accuracy: 0.9410 - val_loss: 0.0175 - val_accuracy: 0.9250\n",
      "Epoch 1460/2000\n",
      "1000/1000 [==============================] - 1s 533us/step - loss: 0.0115 - accuracy: 0.9440 - val_loss: 0.0276 - val_accuracy: 0.9500\n",
      "Epoch 1461/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0127 - accuracy: 0.9540 - val_loss: 0.0209 - val_accuracy: 0.9500\n",
      "Epoch 1462/2000\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 0.0221 - accuracy: 0.9350 - val_loss: 0.0239 - val_accuracy: 0.9250\n",
      "Epoch 1463/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0145 - accuracy: 0.9480 - val_loss: 0.0152 - val_accuracy: 0.9250\n",
      "Epoch 1464/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.0139 - accuracy: 0.9500 - val_loss: 0.0643 - val_accuracy: 0.9250\n",
      "Epoch 1465/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0220 - accuracy: 0.9360 - val_loss: 0.0394 - val_accuracy: 0.9000\n",
      "Epoch 1466/2000\n",
      "1000/1000 [==============================] - 1s 544us/step - loss: 0.0117 - accuracy: 0.9560 - val_loss: 0.0370 - val_accuracy: 0.9500\n",
      "Epoch 1467/2000\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 0.0207 - accuracy: 0.9480 - val_loss: 0.0141 - val_accuracy: 0.9000\n",
      "Epoch 1468/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0159 - accuracy: 0.9490 - val_loss: 0.0201 - val_accuracy: 0.9000\n",
      "Epoch 1469/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0169 - accuracy: 0.9340 - val_loss: 0.0203 - val_accuracy: 0.9000\n",
      "Epoch 1470/2000\n",
      "1000/1000 [==============================] - 1s 567us/step - loss: 0.0155 - accuracy: 0.9330 - val_loss: 0.0337 - val_accuracy: 0.9500\n",
      "Epoch 1471/2000\n",
      "1000/1000 [==============================] - 1s 681us/step - loss: 0.0092 - accuracy: 0.9550 - val_loss: 0.0248 - val_accuracy: 0.9500\n",
      "Epoch 1472/2000\n",
      "1000/1000 [==============================] - 1s 582us/step - loss: 0.0117 - accuracy: 0.9490 - val_loss: 0.0191 - val_accuracy: 0.9000\n",
      "Epoch 1473/2000\n",
      "1000/1000 [==============================] - 1s 612us/step - loss: 0.0159 - accuracy: 0.9560 - val_loss: 0.0199 - val_accuracy: 0.9250\n",
      "Epoch 1474/2000\n",
      "1000/1000 [==============================] - 1s 635us/step - loss: 0.0186 - accuracy: 0.9380 - val_loss: 0.0252 - val_accuracy: 0.8750\n",
      "Epoch 1475/2000\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.0170 - accuracy: 0.9440 - val_loss: 0.0164 - val_accuracy: 0.9250\n",
      "Epoch 1476/2000\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.0132 - accuracy: 0.9460 - val_loss: 0.0306 - val_accuracy: 0.9000\n",
      "Epoch 1477/2000\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0128 - accuracy: 0.9440 - val_loss: 0.0288 - val_accuracy: 0.9500\n",
      "Epoch 1478/2000\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 0.0225 - accuracy: 0.9480 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 1479/2000\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0239 - accuracy: 0.9510 - val_loss: 0.0169 - val_accuracy: 0.9250\n",
      "Epoch 1480/2000\n",
      "1000/1000 [==============================] - 1s 600us/step - loss: 0.0194 - accuracy: 0.9480 - val_loss: 0.0285 - val_accuracy: 0.9250\n",
      "Epoch 1481/2000\n",
      "1000/1000 [==============================] - 1s 609us/step - loss: 0.0132 - accuracy: 0.9510 - val_loss: 0.0262 - val_accuracy: 0.9500\n",
      "Epoch 1482/2000\n",
      "1000/1000 [==============================] - 1s 606us/step - loss: 0.0124 - accuracy: 0.9510 - val_loss: 0.0269 - val_accuracy: 0.9500\n",
      "Epoch 1483/2000\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 0.0201 - accuracy: 0.9420 - val_loss: 0.0163 - val_accuracy: 0.9000\n",
      "Epoch 1484/2000\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.0143 - accuracy: 0.9480 - val_loss: 0.0206 - val_accuracy: 0.9000\n",
      "Epoch 1485/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0119 - accuracy: 0.9420 - val_loss: 0.0323 - val_accuracy: 0.9500\n",
      "Epoch 1486/2000\n",
      "1000/1000 [==============================] - 1s 564us/step - loss: 0.0091 - accuracy: 0.9490 - val_loss: 0.0183 - val_accuracy: 0.9000\n",
      "Epoch 1487/2000\n",
      "1000/1000 [==============================] - 1s 613us/step - loss: 0.0124 - accuracy: 0.9410 - val_loss: 0.0226 - val_accuracy: 0.8750\n",
      "Epoch 1488/2000\n",
      "1000/1000 [==============================] - 1s 636us/step - loss: 0.0147 - accuracy: 0.9540 - val_loss: 0.0201 - val_accuracy: 0.9000\n",
      "Epoch 1489/2000\n",
      "1000/1000 [==============================] - 1s 582us/step - loss: 0.0105 - accuracy: 0.9450 - val_loss: 0.0152 - val_accuracy: 0.9250\n",
      "Epoch 1490/2000\n",
      "1000/1000 [==============================] - 1s 562us/step - loss: 0.0134 - accuracy: 0.9440 - val_loss: 0.0198 - val_accuracy: 0.8750\n",
      "Epoch 1491/2000\n",
      "1000/1000 [==============================] - 1s 564us/step - loss: 0.0158 - accuracy: 0.9410 - val_loss: 0.0354 - val_accuracy: 0.9000\n",
      "Epoch 1492/2000\n",
      "1000/1000 [==============================] - 1s 564us/step - loss: 0.0098 - accuracy: 0.9410 - val_loss: 0.0152 - val_accuracy: 0.9000\n",
      "Epoch 1493/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0160 - accuracy: 0.9400 - val_loss: 0.0175 - val_accuracy: 0.9000\n",
      "Epoch 1494/2000\n",
      "1000/1000 [==============================] - 1s 562us/step - loss: 0.0116 - accuracy: 0.9370 - val_loss: 0.0158 - val_accuracy: 0.9500\n",
      "Epoch 1495/2000\n",
      "1000/1000 [==============================] - 1s 623us/step - loss: 0.0117 - accuracy: 0.9320 - val_loss: 0.0176 - val_accuracy: 0.9250\n",
      "Epoch 1496/2000\n",
      "1000/1000 [==============================] - 1s 573us/step - loss: 0.0125 - accuracy: 0.9400 - val_loss: 0.0194 - val_accuracy: 0.9250\n",
      "Epoch 1497/2000\n",
      "1000/1000 [==============================] - 1s 574us/step - loss: 0.0172 - accuracy: 0.9380 - val_loss: 0.0470 - val_accuracy: 0.9000\n",
      "Epoch 1498/2000\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0097 - accuracy: 0.9440 - val_loss: 0.0164 - val_accuracy: 0.9250\n",
      "Epoch 1499/2000\n",
      "1000/1000 [==============================] - 1s 618us/step - loss: 0.0087 - accuracy: 0.9510 - val_loss: 0.0773 - val_accuracy: 0.9000\n",
      "Epoch 1500/2000\n",
      "1000/1000 [==============================] - 1s 563us/step - loss: 0.0155 - accuracy: 0.9430 - val_loss: 0.0243 - val_accuracy: 0.9000\n",
      "Epoch 1501/2000\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0178 - accuracy: 0.9440 - val_loss: 0.0637 - val_accuracy: 0.9000\n",
      "Epoch 1502/2000\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 0.0147 - accuracy: 0.9530 - val_loss: 0.0290 - val_accuracy: 0.8750\n",
      "Epoch 1503/2000\n",
      "1000/1000 [==============================] - 1s 611us/step - loss: 0.0174 - accuracy: 0.9410 - val_loss: 0.0499 - val_accuracy: 0.9000\n",
      "Epoch 1504/2000\n",
      "1000/1000 [==============================] - 1s 581us/step - loss: 0.0181 - accuracy: 0.9470 - val_loss: 0.0162 - val_accuracy: 0.8750\n",
      "Epoch 1505/2000\n",
      "1000/1000 [==============================] - 1s 604us/step - loss: 0.0142 - accuracy: 0.9400 - val_loss: 0.0235 - val_accuracy: 0.9000\n",
      "Epoch 1506/2000\n",
      "1000/1000 [==============================] - 1s 599us/step - loss: 0.0125 - accuracy: 0.9490 - val_loss: 0.0242 - val_accuracy: 0.9000\n",
      "Epoch 1507/2000\n",
      "1000/1000 [==============================] - 1s 620us/step - loss: 0.0091 - accuracy: 0.9480 - val_loss: 0.0263 - val_accuracy: 0.9250\n",
      "Epoch 1508/2000\n",
      "1000/1000 [==============================] - 1s 565us/step - loss: 0.0111 - accuracy: 0.9450 - val_loss: 0.0452 - val_accuracy: 0.9500\n",
      "Epoch 1509/2000\n",
      "1000/1000 [==============================] - 1s 622us/step - loss: 0.0273 - accuracy: 0.9460 - val_loss: 0.0949 - val_accuracy: 0.9500\n",
      "Epoch 1510/2000\n",
      "1000/1000 [==============================] - 1s 600us/step - loss: 0.0129 - accuracy: 0.9520 - val_loss: 0.0295 - val_accuracy: 0.9250\n",
      "Epoch 1511/2000\n",
      "1000/1000 [==============================] - 1s 671us/step - loss: 0.0102 - accuracy: 0.9580 - val_loss: 0.0160 - val_accuracy: 0.9000\n",
      "Epoch 1512/2000\n",
      "1000/1000 [==============================] - 1s 667us/step - loss: 0.0120 - accuracy: 0.9520 - val_loss: 0.0332 - val_accuracy: 0.9000\n",
      "Epoch 1513/2000\n",
      "1000/1000 [==============================] - 1s 648us/step - loss: 0.0156 - accuracy: 0.9580 - val_loss: 0.0258 - val_accuracy: 0.9000\n",
      "Epoch 1514/2000\n",
      "1000/1000 [==============================] - 1s 820us/step - loss: 0.0194 - accuracy: 0.9430 - val_loss: 0.0422 - val_accuracy: 0.9250\n",
      "Epoch 1515/2000\n",
      "1000/1000 [==============================] - 1s 712us/step - loss: 0.0138 - accuracy: 0.9450 - val_loss: 0.0167 - val_accuracy: 0.9250\n",
      "Epoch 1516/2000\n",
      "1000/1000 [==============================] - 1s 624us/step - loss: 0.0095 - accuracy: 0.9410 - val_loss: 0.0203 - val_accuracy: 0.9250\n",
      "Epoch 1517/2000\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0113 - accuracy: 0.9420 - val_loss: 0.0145 - val_accuracy: 0.9500\n",
      "Epoch 1518/2000\n",
      "1000/1000 [==============================] - 1s 645us/step - loss: 0.0209 - accuracy: 0.9510 - val_loss: 0.0195 - val_accuracy: 0.9000\n",
      "Epoch 1519/2000\n",
      "1000/1000 [==============================] - 1s 760us/step - loss: 0.0096 - accuracy: 0.9480 - val_loss: 0.0181 - val_accuracy: 0.9500\n",
      "Epoch 1520/2000\n",
      "1000/1000 [==============================] - 1s 636us/step - loss: 0.0115 - accuracy: 0.9540 - val_loss: 0.0143 - val_accuracy: 0.9250\n",
      "Epoch 1521/2000\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 0.0166 - accuracy: 0.9430 - val_loss: 0.0247 - val_accuracy: 0.9250\n",
      "Epoch 1522/2000\n",
      "1000/1000 [==============================] - 1s 601us/step - loss: 0.0089 - accuracy: 0.9530 - val_loss: 0.0133 - val_accuracy: 0.9250\n",
      "Epoch 1523/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 579us/step - loss: 0.0110 - accuracy: 0.9570 - val_loss: 0.0437 - val_accuracy: 0.9000\n",
      "Epoch 1524/2000\n",
      "1000/1000 [==============================] - 1s 617us/step - loss: 0.0258 - accuracy: 0.9520 - val_loss: 0.0214 - val_accuracy: 0.9250\n",
      "Epoch 1525/2000\n",
      "1000/1000 [==============================] - 1s 707us/step - loss: 0.0085 - accuracy: 0.9470 - val_loss: 0.0154 - val_accuracy: 0.9250\n",
      "Epoch 1526/2000\n",
      "1000/1000 [==============================] - 1s 713us/step - loss: 0.0408 - accuracy: 0.9360 - val_loss: 0.0220 - val_accuracy: 0.9500\n",
      "Epoch 1527/2000\n",
      "1000/1000 [==============================] - 1s 674us/step - loss: 0.0113 - accuracy: 0.9480 - val_loss: 0.0234 - val_accuracy: 0.9000\n",
      "Epoch 1528/2000\n",
      "1000/1000 [==============================] - 1s 644us/step - loss: 0.0167 - accuracy: 0.9350 - val_loss: 0.0244 - val_accuracy: 0.9250\n",
      "Epoch 1529/2000\n",
      "1000/1000 [==============================] - 1s 630us/step - loss: 0.0179 - accuracy: 0.9390 - val_loss: 0.0172 - val_accuracy: 0.9500\n",
      "Epoch 1530/2000\n",
      "1000/1000 [==============================] - 1s 648us/step - loss: 0.0121 - accuracy: 0.9500 - val_loss: 0.0139 - val_accuracy: 0.8750\n",
      "Epoch 1531/2000\n",
      "1000/1000 [==============================] - 1s 628us/step - loss: 0.0150 - accuracy: 0.9390 - val_loss: 0.0158 - val_accuracy: 0.9250\n",
      "Epoch 1532/2000\n",
      "1000/1000 [==============================] - 1s 601us/step - loss: 0.0231 - accuracy: 0.9420 - val_loss: 0.0286 - val_accuracy: 0.9000\n",
      "Epoch 1533/2000\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0076 - accuracy: 0.9430 - val_loss: 0.0381 - val_accuracy: 0.9500\n",
      "Epoch 1534/2000\n",
      "1000/1000 [==============================] - 1s 607us/step - loss: 0.0103 - accuracy: 0.9370 - val_loss: 0.0187 - val_accuracy: 0.9250\n",
      "Epoch 1535/2000\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0136 - accuracy: 0.9410 - val_loss: 0.0173 - val_accuracy: 0.9000\n",
      "Epoch 1536/2000\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0102 - accuracy: 0.9390 - val_loss: 0.0174 - val_accuracy: 0.9000\n",
      "Epoch 1537/2000\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0099 - accuracy: 0.9430 - val_loss: 0.0202 - val_accuracy: 0.9250\n",
      "Epoch 1538/2000\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0142 - accuracy: 0.9480 - val_loss: 0.0175 - val_accuracy: 0.9000\n",
      "Epoch 1539/2000\n",
      "1000/1000 [==============================] - 1s 601us/step - loss: 0.0131 - accuracy: 0.9460 - val_loss: 0.0392 - val_accuracy: 0.9000\n",
      "Epoch 1540/2000\n",
      "1000/1000 [==============================] - 1s 617us/step - loss: 0.0127 - accuracy: 0.9420 - val_loss: 0.0383 - val_accuracy: 0.9250\n",
      "Epoch 1541/2000\n",
      "1000/1000 [==============================] - 1s 671us/step - loss: 0.0113 - accuracy: 0.9430 - val_loss: 0.0221 - val_accuracy: 0.9000\n",
      "Epoch 1542/2000\n",
      "1000/1000 [==============================] - 1s 627us/step - loss: 0.0114 - accuracy: 0.9540 - val_loss: 0.0197 - val_accuracy: 0.9250\n",
      "Epoch 1543/2000\n",
      "1000/1000 [==============================] - 1s 617us/step - loss: 0.0198 - accuracy: 0.9400 - val_loss: 0.0140 - val_accuracy: 0.9000\n",
      "Epoch 1544/2000\n",
      "1000/1000 [==============================] - 1s 623us/step - loss: 0.0147 - accuracy: 0.9290 - val_loss: 0.0160 - val_accuracy: 0.9000\n",
      "Epoch 1545/2000\n",
      "1000/1000 [==============================] - 1s 612us/step - loss: 0.0074 - accuracy: 0.9540 - val_loss: 0.0185 - val_accuracy: 0.9250\n",
      "Epoch 1546/2000\n",
      "1000/1000 [==============================] - 1s 621us/step - loss: 0.0120 - accuracy: 0.9460 - val_loss: 0.0269 - val_accuracy: 0.9500\n",
      "Epoch 1547/2000\n",
      "1000/1000 [==============================] - 1s 689us/step - loss: 0.0157 - accuracy: 0.9390 - val_loss: 0.0228 - val_accuracy: 0.9750\n",
      "Epoch 1548/2000\n",
      "1000/1000 [==============================] - 1s 701us/step - loss: 0.0101 - accuracy: 0.9370 - val_loss: 0.0152 - val_accuracy: 0.9250\n",
      "Epoch 1549/2000\n",
      "1000/1000 [==============================] - 1s 658us/step - loss: 0.0092 - accuracy: 0.9470 - val_loss: 0.0216 - val_accuracy: 0.8500\n",
      "Epoch 1550/2000\n",
      "1000/1000 [==============================] - 1s 698us/step - loss: 0.0095 - accuracy: 0.9470 - val_loss: 0.0176 - val_accuracy: 0.9500\n",
      "Epoch 1551/2000\n",
      "1000/1000 [==============================] - 1s 725us/step - loss: 0.0202 - accuracy: 0.9360 - val_loss: 0.0236 - val_accuracy: 0.9250\n",
      "Epoch 1552/2000\n",
      "1000/1000 [==============================] - 1s 588us/step - loss: 0.0122 - accuracy: 0.9390 - val_loss: 0.0304 - val_accuracy: 0.9000\n",
      "Epoch 1553/2000\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0116 - accuracy: 0.9590 - val_loss: 0.0132 - val_accuracy: 0.9000\n",
      "Epoch 1554/2000\n",
      "1000/1000 [==============================] - 1s 620us/step - loss: 0.0132 - accuracy: 0.9470 - val_loss: 0.0316 - val_accuracy: 0.9250\n",
      "Epoch 1555/2000\n",
      "1000/1000 [==============================] - 1s 620us/step - loss: 0.0091 - accuracy: 0.9440 - val_loss: 0.0371 - val_accuracy: 0.8750\n",
      "Epoch 1556/2000\n",
      "1000/1000 [==============================] - 1s 624us/step - loss: 0.0120 - accuracy: 0.9430 - val_loss: 0.0302 - val_accuracy: 0.9500\n",
      "Epoch 1557/2000\n",
      "1000/1000 [==============================] - 1s 651us/step - loss: 0.0110 - accuracy: 0.9320 - val_loss: 0.0144 - val_accuracy: 0.9000\n",
      "Epoch 1558/2000\n",
      "1000/1000 [==============================] - 1s 610us/step - loss: 0.0133 - accuracy: 0.9350 - val_loss: 0.0179 - val_accuracy: 0.9500\n",
      "Epoch 1559/2000\n",
      "1000/1000 [==============================] - 1s 599us/step - loss: 0.0325 - accuracy: 0.9490 - val_loss: 0.0281 - val_accuracy: 0.9250\n",
      "Epoch 1560/2000\n",
      "1000/1000 [==============================] - 1s 726us/step - loss: 0.0144 - accuracy: 0.9350 - val_loss: 0.0276 - val_accuracy: 0.9000\n",
      "Epoch 1561/2000\n",
      "1000/1000 [==============================] - 1s 699us/step - loss: 0.0129 - accuracy: 0.9370 - val_loss: 0.0145 - val_accuracy: 0.9250\n",
      "Epoch 1562/2000\n",
      "1000/1000 [==============================] - 1s 781us/step - loss: 0.0165 - accuracy: 0.9390 - val_loss: 0.0412 - val_accuracy: 0.9500\n",
      "Epoch 1563/2000\n",
      "1000/1000 [==============================] - 1s 747us/step - loss: 0.0105 - accuracy: 0.9450 - val_loss: 0.0256 - val_accuracy: 0.9250\n",
      "Epoch 1564/2000\n",
      "1000/1000 [==============================] - 1s 678us/step - loss: 0.0170 - accuracy: 0.9430 - val_loss: 0.0294 - val_accuracy: 0.9250\n",
      "Epoch 1565/2000\n",
      "1000/1000 [==============================] - 1s 601us/step - loss: 0.0133 - accuracy: 0.9390 - val_loss: 0.0306 - val_accuracy: 0.8750\n",
      "Epoch 1566/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0120 - accuracy: 0.9340 - val_loss: 0.0200 - val_accuracy: 0.9000\n",
      "Epoch 1567/2000\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 0.0137 - accuracy: 0.9390 - val_loss: 0.0216 - val_accuracy: 0.9000\n",
      "Epoch 1568/2000\n",
      "1000/1000 [==============================] - 1s 605us/step - loss: 0.0090 - accuracy: 0.9470 - val_loss: 0.0315 - val_accuracy: 0.9250\n",
      "Epoch 1569/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.0162 - accuracy: 0.9390 - val_loss: 0.0257 - val_accuracy: 0.9250\n",
      "Epoch 1570/2000\n",
      "1000/1000 [==============================] - 1s 544us/step - loss: 0.0120 - accuracy: 0.9450 - val_loss: 0.0182 - val_accuracy: 0.9250\n",
      "Epoch 1571/2000\n",
      "1000/1000 [==============================] - 1s 542us/step - loss: 0.0198 - accuracy: 0.9440 - val_loss: 0.0621 - val_accuracy: 0.9250\n",
      "Epoch 1572/2000\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 0.0156 - accuracy: 0.9480 - val_loss: 0.0190 - val_accuracy: 0.9250\n",
      "Epoch 1573/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0085 - accuracy: 0.9520 - val_loss: 0.0386 - val_accuracy: 0.9500\n",
      "Epoch 1574/2000\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 0.0117 - accuracy: 0.9460 - val_loss: 0.0490 - val_accuracy: 0.9000\n",
      "Epoch 1575/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0195 - accuracy: 0.9460 - val_loss: 0.0593 - val_accuracy: 0.8750\n",
      "Epoch 1576/2000\n",
      "1000/1000 [==============================] - 1s 510us/step - loss: 0.0126 - accuracy: 0.9510 - val_loss: 0.0240 - val_accuracy: 0.9000\n",
      "Epoch 1577/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 523us/step - loss: 0.0063 - accuracy: 0.9460 - val_loss: 0.0252 - val_accuracy: 0.9250\n",
      "Epoch 1578/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0169 - accuracy: 0.9470 - val_loss: 0.0411 - val_accuracy: 0.9250\n",
      "Epoch 1579/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0168 - accuracy: 0.9520 - val_loss: 0.0170 - val_accuracy: 0.9000\n",
      "Epoch 1580/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0113 - accuracy: 0.9560 - val_loss: 0.0383 - val_accuracy: 0.9000\n",
      "Epoch 1581/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0133 - accuracy: 0.9390 - val_loss: 0.0321 - val_accuracy: 0.9250\n",
      "Epoch 1582/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.0118 - accuracy: 0.9460 - val_loss: 0.0207 - val_accuracy: 0.9000\n",
      "Epoch 1583/2000\n",
      "1000/1000 [==============================] - 1s 523us/step - loss: 0.0124 - accuracy: 0.9540 - val_loss: 0.0182 - val_accuracy: 0.9000\n",
      "Epoch 1584/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0133 - accuracy: 0.9480 - val_loss: 0.0238 - val_accuracy: 0.9500\n",
      "Epoch 1585/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0173 - accuracy: 0.9460 - val_loss: 0.0157 - val_accuracy: 0.9250\n",
      "Epoch 1586/2000\n",
      "1000/1000 [==============================] - 1s 534us/step - loss: 0.0111 - accuracy: 0.9420 - val_loss: 0.0410 - val_accuracy: 0.9250\n",
      "Epoch 1587/2000\n",
      "1000/1000 [==============================] - 1s 530us/step - loss: 0.0086 - accuracy: 0.9550 - val_loss: 0.0185 - val_accuracy: 0.9250\n",
      "Epoch 1588/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0099 - accuracy: 0.9480 - val_loss: 0.0383 - val_accuracy: 0.9500\n",
      "Epoch 1589/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0234 - accuracy: 0.9470 - val_loss: 0.0266 - val_accuracy: 0.9000\n",
      "Epoch 1590/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0151 - accuracy: 0.9520 - val_loss: 0.0473 - val_accuracy: 0.9500\n",
      "Epoch 1591/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0250 - accuracy: 0.9460 - val_loss: 0.0164 - val_accuracy: 0.9000\n",
      "Epoch 1592/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0148 - accuracy: 0.9450 - val_loss: 0.0150 - val_accuracy: 0.9000\n",
      "Epoch 1593/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0190 - accuracy: 0.9430 - val_loss: 0.0232 - val_accuracy: 0.8750\n",
      "Epoch 1594/2000\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 0.0075 - accuracy: 0.9380 - val_loss: 0.0202 - val_accuracy: 0.9500\n",
      "Epoch 1595/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0089 - accuracy: 0.9400 - val_loss: 0.0144 - val_accuracy: 0.9000\n",
      "Epoch 1596/2000\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 0.0107 - accuracy: 0.9520 - val_loss: 0.0189 - val_accuracy: 0.9000\n",
      "Epoch 1597/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0119 - accuracy: 0.9390 - val_loss: 0.0267 - val_accuracy: 0.8750\n",
      "Epoch 1598/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0112 - accuracy: 0.9550 - val_loss: 0.0141 - val_accuracy: 0.9250\n",
      "Epoch 1599/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0140 - accuracy: 0.9450 - val_loss: 0.0166 - val_accuracy: 0.9250\n",
      "Epoch 1600/2000\n",
      "1000/1000 [==============================] - 1s 530us/step - loss: 0.0181 - accuracy: 0.9370 - val_loss: 0.0148 - val_accuracy: 0.9250\n",
      "Epoch 1601/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0095 - accuracy: 0.9450 - val_loss: 0.0186 - val_accuracy: 0.9250\n",
      "Epoch 1602/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0186 - accuracy: 0.9440 - val_loss: 0.0158 - val_accuracy: 0.9000\n",
      "Epoch 1603/2000\n",
      "1000/1000 [==============================] - 1s 531us/step - loss: 0.0131 - accuracy: 0.9420 - val_loss: 0.0399 - val_accuracy: 0.9500\n",
      "Epoch 1604/2000\n",
      "1000/1000 [==============================] - 1s 525us/step - loss: 0.0109 - accuracy: 0.9520 - val_loss: 0.0170 - val_accuracy: 0.9500\n",
      "Epoch 1605/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0119 - accuracy: 0.9470 - val_loss: 0.0600 - val_accuracy: 0.9500\n",
      "Epoch 1606/2000\n",
      "1000/1000 [==============================] - 1s 534us/step - loss: 0.0112 - accuracy: 0.9510 - val_loss: 0.0219 - val_accuracy: 0.9750\n",
      "Epoch 1607/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0140 - accuracy: 0.9500 - val_loss: 0.0158 - val_accuracy: 0.9250\n",
      "Epoch 1608/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0208 - accuracy: 0.9390 - val_loss: 0.0413 - val_accuracy: 0.8750\n",
      "Epoch 1609/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0141 - accuracy: 0.9500 - val_loss: 0.0202 - val_accuracy: 0.9250\n",
      "Epoch 1610/2000\n",
      "1000/1000 [==============================] - 1s 563us/step - loss: 0.0161 - accuracy: 0.9420 - val_loss: 0.0195 - val_accuracy: 0.8750\n",
      "Epoch 1611/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0075 - accuracy: 0.9540 - val_loss: 0.0181 - val_accuracy: 0.9000\n",
      "Epoch 1612/2000\n",
      "1000/1000 [==============================] - 1s 533us/step - loss: 0.0159 - accuracy: 0.9530 - val_loss: 0.0204 - val_accuracy: 0.9250\n",
      "Epoch 1613/2000\n",
      "1000/1000 [==============================] - 1s 557us/step - loss: 0.0152 - accuracy: 0.9470 - val_loss: 0.0165 - val_accuracy: 0.9750\n",
      "Epoch 1614/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0133 - accuracy: 0.9460 - val_loss: 0.0674 - val_accuracy: 0.9000\n",
      "Epoch 1615/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0183 - accuracy: 0.9520 - val_loss: 0.0326 - val_accuracy: 0.9250\n",
      "Epoch 1616/2000\n",
      "1000/1000 [==============================] - 1s 533us/step - loss: 0.0099 - accuracy: 0.9510 - val_loss: 0.0526 - val_accuracy: 0.9250\n",
      "Epoch 1617/2000\n",
      "1000/1000 [==============================] - 1s 559us/step - loss: 0.0144 - accuracy: 0.9450 - val_loss: 0.0330 - val_accuracy: 0.9250\n",
      "Epoch 1618/2000\n",
      "1000/1000 [==============================] - 1s 543us/step - loss: 0.0090 - accuracy: 0.9460 - val_loss: 0.0421 - val_accuracy: 0.9000\n",
      "Epoch 1619/2000\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0094 - accuracy: 0.9420 - val_loss: 0.0225 - val_accuracy: 0.9500\n",
      "Epoch 1620/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0117 - accuracy: 0.9480 - val_loss: 0.0270 - val_accuracy: 0.9000\n",
      "Epoch 1621/2000\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 0.0073 - accuracy: 0.9550 - val_loss: 0.0232 - val_accuracy: 0.9250\n",
      "Epoch 1622/2000\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 0.0318 - accuracy: 0.9360 - val_loss: 0.0148 - val_accuracy: 0.9000\n",
      "Epoch 1623/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0107 - accuracy: 0.9480 - val_loss: 0.0324 - val_accuracy: 0.9500\n",
      "Epoch 1624/2000\n",
      "1000/1000 [==============================] - 1s 556us/step - loss: 0.0117 - accuracy: 0.9390 - val_loss: 0.0194 - val_accuracy: 0.9500\n",
      "Epoch 1625/2000\n",
      "1000/1000 [==============================] - 1s 549us/step - loss: 0.0201 - accuracy: 0.9420 - val_loss: 0.0611 - val_accuracy: 0.9250\n",
      "Epoch 1626/2000\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 0.0096 - accuracy: 0.9470 - val_loss: 0.0999 - val_accuracy: 0.9250\n",
      "Epoch 1627/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0222 - accuracy: 0.9440 - val_loss: 0.0111 - val_accuracy: 0.9750\n",
      "Epoch 1628/2000\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 0.0207 - accuracy: 0.9390 - val_loss: 0.0155 - val_accuracy: 0.9250\n",
      "Epoch 1629/2000\n",
      "1000/1000 [==============================] - 1s 577us/step - loss: 0.0267 - accuracy: 0.9430 - val_loss: 0.0185 - val_accuracy: 0.9250\n",
      "Epoch 1630/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0126 - accuracy: 0.9500 - val_loss: 0.0412 - val_accuracy: 0.9250\n",
      "Epoch 1631/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0140 - accuracy: 0.9520 - val_loss: 0.0212 - val_accuracy: 0.9000\n",
      "Epoch 1632/2000\n",
      "1000/1000 [==============================] - 1s 752us/step - loss: 0.0154 - accuracy: 0.9510 - val_loss: 0.0315 - val_accuracy: 0.9250\n",
      "Epoch 1633/2000\n",
      "1000/1000 [==============================] - 1s 627us/step - loss: 0.0228 - accuracy: 0.9410 - val_loss: 0.0354 - val_accuracy: 0.9250\n",
      "Epoch 1634/2000\n",
      "1000/1000 [==============================] - 1s 671us/step - loss: 0.0293 - accuracy: 0.9490 - val_loss: 0.0350 - val_accuracy: 0.9250\n",
      "Epoch 1635/2000\n",
      "1000/1000 [==============================] - 1s 598us/step - loss: 0.0119 - accuracy: 0.9540 - val_loss: 0.0157 - val_accuracy: 0.9500\n",
      "Epoch 1636/2000\n",
      "1000/1000 [==============================] - 1s 672us/step - loss: 0.0102 - accuracy: 0.9480 - val_loss: 0.0137 - val_accuracy: 0.9250\n",
      "Epoch 1637/2000\n",
      "1000/1000 [==============================] - 1s 604us/step - loss: 0.0114 - accuracy: 0.9470 - val_loss: 0.0215 - val_accuracy: 0.9000\n",
      "Epoch 1638/2000\n",
      "1000/1000 [==============================] - 1s 583us/step - loss: 0.0158 - accuracy: 0.9570 - val_loss: 0.0616 - val_accuracy: 0.9500\n",
      "Epoch 1639/2000\n",
      "1000/1000 [==============================] - 1s 629us/step - loss: 0.0140 - accuracy: 0.9510 - val_loss: 0.0254 - val_accuracy: 0.9250\n",
      "Epoch 1640/2000\n",
      "1000/1000 [==============================] - 1s 601us/step - loss: 0.0128 - accuracy: 0.9490 - val_loss: 0.0231 - val_accuracy: 0.9000\n",
      "Epoch 1641/2000\n",
      "1000/1000 [==============================] - 1s 606us/step - loss: 0.0188 - accuracy: 0.9470 - val_loss: 0.0413 - val_accuracy: 0.9750\n",
      "Epoch 1642/2000\n",
      "1000/1000 [==============================] - 1s 620us/step - loss: 0.0106 - accuracy: 0.9440 - val_loss: 0.0160 - val_accuracy: 0.9250\n",
      "Epoch 1643/2000\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 0.0090 - accuracy: 0.9530 - val_loss: 0.0443 - val_accuracy: 0.9500\n",
      "Epoch 1644/2000\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0138 - accuracy: 0.9650 - val_loss: 0.0425 - val_accuracy: 0.9750\n",
      "Epoch 1645/2000\n",
      "1000/1000 [==============================] - 1s 647us/step - loss: 0.0107 - accuracy: 0.9590 - val_loss: 0.0140 - val_accuracy: 0.9250\n",
      "Epoch 1646/2000\n",
      "1000/1000 [==============================] - 1s 621us/step - loss: 0.0176 - accuracy: 0.9520 - val_loss: 0.0150 - val_accuracy: 0.9500\n",
      "Epoch 1647/2000\n",
      "1000/1000 [==============================] - 1s 614us/step - loss: 0.0188 - accuracy: 0.9450 - val_loss: 0.0162 - val_accuracy: 0.9500\n",
      "Epoch 1648/2000\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 0.0176 - accuracy: 0.9560 - val_loss: 0.0164 - val_accuracy: 0.9250\n",
      "Epoch 1649/2000\n",
      "1000/1000 [==============================] - 1s 593us/step - loss: 0.0114 - accuracy: 0.9580 - val_loss: 0.0260 - val_accuracy: 0.9750\n",
      "Epoch 1650/2000\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 0.0124 - accuracy: 0.9490 - val_loss: 0.0121 - val_accuracy: 0.9000\n",
      "Epoch 1651/2000\n",
      "1000/1000 [==============================] - 1s 586us/step - loss: 0.0151 - accuracy: 0.9500 - val_loss: 0.0202 - val_accuracy: 0.9500\n",
      "Epoch 1652/2000\n",
      "1000/1000 [==============================] - 1s 602us/step - loss: 0.0116 - accuracy: 0.9480 - val_loss: 0.0236 - val_accuracy: 0.9000\n",
      "Epoch 1653/2000\n",
      "1000/1000 [==============================] - 1s 606us/step - loss: 0.0135 - accuracy: 0.9580 - val_loss: 0.0381 - val_accuracy: 0.9500\n",
      "Epoch 1654/2000\n",
      "1000/1000 [==============================] - 1s 589us/step - loss: 0.0129 - accuracy: 0.9580 - val_loss: 0.0246 - val_accuracy: 0.9500\n",
      "Epoch 1655/2000\n",
      "1000/1000 [==============================] - 1s 595us/step - loss: 0.0147 - accuracy: 0.9580 - val_loss: 0.0189 - val_accuracy: 0.9250\n",
      "Epoch 1656/2000\n",
      "1000/1000 [==============================] - 1s 636us/step - loss: 0.0087 - accuracy: 0.9450 - val_loss: 0.0160 - val_accuracy: 0.9000\n",
      "Epoch 1657/2000\n",
      "1000/1000 [==============================] - 1s 661us/step - loss: 0.0273 - accuracy: 0.9400 - val_loss: 0.0270 - val_accuracy: 0.9250\n",
      "Epoch 1658/2000\n",
      "1000/1000 [==============================] - 1s 592us/step - loss: 0.0148 - accuracy: 0.9420 - val_loss: 0.0148 - val_accuracy: 0.9750\n",
      "Epoch 1659/2000\n",
      "1000/1000 [==============================] - 1s 658us/step - loss: 0.0098 - accuracy: 0.9540 - val_loss: 0.0214 - val_accuracy: 0.9250\n",
      "Epoch 1660/2000\n",
      "1000/1000 [==============================] - 1s 601us/step - loss: 0.0097 - accuracy: 0.9500 - val_loss: 0.0216 - val_accuracy: 0.9750\n",
      "Epoch 1661/2000\n",
      "1000/1000 [==============================] - 1s 623us/step - loss: 0.0155 - accuracy: 0.9570 - val_loss: 0.0295 - val_accuracy: 0.9250\n",
      "Epoch 1662/2000\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0101 - accuracy: 0.9480 - val_loss: 0.0165 - val_accuracy: 0.8750\n",
      "Epoch 1663/2000\n",
      "1000/1000 [==============================] - 1s 659us/step - loss: 0.0127 - accuracy: 0.9480 - val_loss: 0.0162 - val_accuracy: 0.9250\n",
      "Epoch 1664/2000\n",
      "1000/1000 [==============================] - 1s 620us/step - loss: 0.0158 - accuracy: 0.9520 - val_loss: 0.0255 - val_accuracy: 0.9250\n",
      "Epoch 1665/2000\n",
      "1000/1000 [==============================] - 1s 613us/step - loss: 0.0110 - accuracy: 0.9480 - val_loss: 0.0304 - val_accuracy: 0.9500\n",
      "Epoch 1666/2000\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 0.0248 - accuracy: 0.9540 - val_loss: 0.0403 - val_accuracy: 0.9750\n",
      "Epoch 1667/2000\n",
      "1000/1000 [==============================] - 1s 650us/step - loss: 0.0159 - accuracy: 0.9570 - val_loss: 0.0616 - val_accuracy: 0.9000\n",
      "Epoch 1668/2000\n",
      "1000/1000 [==============================] - 1s 657us/step - loss: 0.0176 - accuracy: 0.9540 - val_loss: 0.0168 - val_accuracy: 0.9500\n",
      "Epoch 1669/2000\n",
      "1000/1000 [==============================] - 1s 642us/step - loss: 0.0187 - accuracy: 0.9420 - val_loss: 0.0201 - val_accuracy: 0.9250\n",
      "Epoch 1670/2000\n",
      "1000/1000 [==============================] - 1s 690us/step - loss: 0.0265 - accuracy: 0.9570 - val_loss: 0.0236 - val_accuracy: 0.9000\n",
      "Epoch 1671/2000\n",
      "1000/1000 [==============================] - 1s 654us/step - loss: 0.0205 - accuracy: 0.9500 - val_loss: 0.0563 - val_accuracy: 0.9250\n",
      "Epoch 1672/2000\n",
      "1000/1000 [==============================] - 1s 631us/step - loss: 0.0170 - accuracy: 0.9500 - val_loss: 0.0376 - val_accuracy: 0.9250\n",
      "Epoch 1673/2000\n",
      "1000/1000 [==============================] - 1s 642us/step - loss: 0.0115 - accuracy: 0.9440 - val_loss: 0.0381 - val_accuracy: 0.9000\n",
      "Epoch 1674/2000\n",
      "1000/1000 [==============================] - 1s 691us/step - loss: 0.0123 - accuracy: 0.9520 - val_loss: 0.0209 - val_accuracy: 0.9250\n",
      "Epoch 1675/2000\n",
      "1000/1000 [==============================] - 1s 652us/step - loss: 0.0177 - accuracy: 0.9420 - val_loss: 0.0144 - val_accuracy: 0.9250\n",
      "Epoch 1676/2000\n",
      "1000/1000 [==============================] - 1s 706us/step - loss: 0.0075 - accuracy: 0.9520 - val_loss: 0.0205 - val_accuracy: 0.9500\n",
      "Epoch 1677/2000\n",
      "1000/1000 [==============================] - 1s 804us/step - loss: 0.0099 - accuracy: 0.9390 - val_loss: 0.0139 - val_accuracy: 0.9500\n",
      "Epoch 1678/2000\n",
      "1000/1000 [==============================] - 1s 698us/step - loss: 0.0141 - accuracy: 0.9470 - val_loss: 0.0236 - val_accuracy: 0.9250\n",
      "Epoch 1679/2000\n",
      "1000/1000 [==============================] - 1s 642us/step - loss: 0.0095 - accuracy: 0.9450 - val_loss: 0.0154 - val_accuracy: 0.9250\n",
      "Epoch 1680/2000\n",
      "1000/1000 [==============================] - 1s 762us/step - loss: 0.0124 - accuracy: 0.9550 - val_loss: 0.1029 - val_accuracy: 0.9250\n",
      "Epoch 1681/2000\n",
      "1000/1000 [==============================] - 1s 673us/step - loss: 0.0203 - accuracy: 0.9490 - val_loss: 0.0138 - val_accuracy: 0.8750\n",
      "Epoch 1682/2000\n",
      "1000/1000 [==============================] - 1s 683us/step - loss: 0.0125 - accuracy: 0.9510 - val_loss: 0.0100 - val_accuracy: 0.9250\n",
      "Epoch 1683/2000\n",
      "1000/1000 [==============================] - 1s 657us/step - loss: 0.0126 - accuracy: 0.9490 - val_loss: 0.0457 - val_accuracy: 0.9500\n",
      "Epoch 1684/2000\n",
      "1000/1000 [==============================] - 1s 628us/step - loss: 0.0157 - accuracy: 0.9490 - val_loss: 0.0412 - val_accuracy: 0.9500\n",
      "Epoch 1685/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 618us/step - loss: 0.0115 - accuracy: 0.9440 - val_loss: 0.0189 - val_accuracy: 0.9750\n",
      "Epoch 1686/2000\n",
      "1000/1000 [==============================] - 1s 623us/step - loss: 0.0159 - accuracy: 0.9500 - val_loss: 0.0332 - val_accuracy: 0.9250\n",
      "Epoch 1687/2000\n",
      "1000/1000 [==============================] - 1s 621us/step - loss: 0.0257 - accuracy: 0.9520 - val_loss: 0.0436 - val_accuracy: 0.9250\n",
      "Epoch 1688/2000\n",
      "1000/1000 [==============================] - 1s 677us/step - loss: 0.0209 - accuracy: 0.9510 - val_loss: 0.0323 - val_accuracy: 0.9000\n",
      "Epoch 1689/2000\n",
      "1000/1000 [==============================] - 1s 631us/step - loss: 0.0112 - accuracy: 0.9640 - val_loss: 0.0154 - val_accuracy: 0.9000\n",
      "Epoch 1690/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0078 - accuracy: 0.9470 - val_loss: 0.0137 - val_accuracy: 0.9000\n",
      "Epoch 1691/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0081 - accuracy: 0.9460 - val_loss: 0.0154 - val_accuracy: 0.9250\n",
      "Epoch 1692/2000\n",
      "1000/1000 [==============================] - 1s 578us/step - loss: 0.0102 - accuracy: 0.9490 - val_loss: 0.0179 - val_accuracy: 0.9000\n",
      "Epoch 1693/2000\n",
      "1000/1000 [==============================] - 1s 613us/step - loss: 0.0125 - accuracy: 0.9500 - val_loss: 0.0304 - val_accuracy: 0.9250\n",
      "Epoch 1694/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0119 - accuracy: 0.9500 - val_loss: 0.0181 - val_accuracy: 0.9250\n",
      "Epoch 1695/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0248 - accuracy: 0.9310 - val_loss: 0.0169 - val_accuracy: 0.9000\n",
      "Epoch 1696/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0334 - accuracy: 0.9430 - val_loss: 0.0252 - val_accuracy: 0.9000\n",
      "Epoch 1697/2000\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 0.0100 - accuracy: 0.9500 - val_loss: 0.0201 - val_accuracy: 0.9250\n",
      "Epoch 1698/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0118 - accuracy: 0.9490 - val_loss: 0.0245 - val_accuracy: 0.9000\n",
      "Epoch 1699/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0173 - accuracy: 0.9340 - val_loss: 0.0148 - val_accuracy: 0.9000\n",
      "Epoch 1700/2000\n",
      "1000/1000 [==============================] - 1s 504us/step - loss: 0.0118 - accuracy: 0.9460 - val_loss: 0.0163 - val_accuracy: 0.9000\n",
      "Epoch 1701/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0113 - accuracy: 0.9420 - val_loss: 0.0399 - val_accuracy: 0.9250\n",
      "Epoch 1702/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0160 - accuracy: 0.9360 - val_loss: 0.0169 - val_accuracy: 0.9000\n",
      "Epoch 1703/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0130 - accuracy: 0.9510 - val_loss: 0.0166 - val_accuracy: 0.9250\n",
      "Epoch 1704/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0090 - accuracy: 0.9500 - val_loss: 0.0167 - val_accuracy: 0.9000\n",
      "Epoch 1705/2000\n",
      "1000/1000 [==============================] - 1s 569us/step - loss: 0.0098 - accuracy: 0.9410 - val_loss: 0.0273 - val_accuracy: 0.9250\n",
      "Epoch 1706/2000\n",
      "1000/1000 [==============================] - 1s 568us/step - loss: 0.0154 - accuracy: 0.9470 - val_loss: 0.0155 - val_accuracy: 0.8750\n",
      "Epoch 1707/2000\n",
      "1000/1000 [==============================] - 1s 531us/step - loss: 0.0149 - accuracy: 0.9440 - val_loss: 0.0212 - val_accuracy: 0.9250\n",
      "Epoch 1708/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0103 - accuracy: 0.9540 - val_loss: 0.0277 - val_accuracy: 0.9250\n",
      "Epoch 1709/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0100 - accuracy: 0.9430 - val_loss: 0.0165 - val_accuracy: 0.9250\n",
      "Epoch 1710/2000\n",
      "1000/1000 [==============================] - 1s 568us/step - loss: 0.0187 - accuracy: 0.9480 - val_loss: 0.0357 - val_accuracy: 0.8750\n",
      "Epoch 1711/2000\n",
      "1000/1000 [==============================] - 1s 531us/step - loss: 0.0141 - accuracy: 0.9380 - val_loss: 0.0240 - val_accuracy: 0.9250\n",
      "Epoch 1712/2000\n",
      "1000/1000 [==============================] - 1s 526us/step - loss: 0.0096 - accuracy: 0.9530 - val_loss: 0.0286 - val_accuracy: 0.9250\n",
      "Epoch 1713/2000\n",
      "1000/1000 [==============================] - 1s 552us/step - loss: 0.0126 - accuracy: 0.9430 - val_loss: 0.0218 - val_accuracy: 0.9250\n",
      "Epoch 1714/2000\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 0.0124 - accuracy: 0.9500 - val_loss: 0.0239 - val_accuracy: 0.9500\n",
      "Epoch 1715/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0095 - accuracy: 0.9440 - val_loss: 0.0257 - val_accuracy: 0.9000\n",
      "Epoch 1716/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0202 - accuracy: 0.9360 - val_loss: 0.0226 - val_accuracy: 0.9000\n",
      "Epoch 1717/2000\n",
      "1000/1000 [==============================] - 1s 531us/step - loss: 0.0154 - accuracy: 0.9490 - val_loss: 0.0208 - val_accuracy: 0.9250\n",
      "Epoch 1718/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0124 - accuracy: 0.9450 - val_loss: 0.0236 - val_accuracy: 0.9250\n",
      "Epoch 1719/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0086 - accuracy: 0.9460 - val_loss: 0.0149 - val_accuracy: 0.8750\n",
      "Epoch 1720/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0121 - accuracy: 0.9410 - val_loss: 0.0319 - val_accuracy: 0.9250\n",
      "Epoch 1721/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0092 - accuracy: 0.9420 - val_loss: 0.0158 - val_accuracy: 0.9000\n",
      "Epoch 1722/2000\n",
      "1000/1000 [==============================] - 1s 538us/step - loss: 0.0076 - accuracy: 0.9550 - val_loss: 0.0249 - val_accuracy: 0.9250\n",
      "Epoch 1723/2000\n",
      "1000/1000 [==============================] - 1s 525us/step - loss: 0.0140 - accuracy: 0.9450 - val_loss: 0.0368 - val_accuracy: 0.8750\n",
      "Epoch 1724/2000\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.0126 - accuracy: 0.9400 - val_loss: 0.0330 - val_accuracy: 0.8750\n",
      "Epoch 1725/2000\n",
      "1000/1000 [==============================] - 1s 531us/step - loss: 0.0109 - accuracy: 0.9460 - val_loss: 0.0277 - val_accuracy: 0.9250\n",
      "Epoch 1726/2000\n",
      "1000/1000 [==============================] - 1s 507us/step - loss: 0.0076 - accuracy: 0.9490 - val_loss: 0.0204 - val_accuracy: 0.8750\n",
      "Epoch 1727/2000\n",
      "1000/1000 [==============================] - 1s 531us/step - loss: 0.0136 - accuracy: 0.9530 - val_loss: 0.0228 - val_accuracy: 0.9250\n",
      "Epoch 1728/2000\n",
      "1000/1000 [==============================] - 1s 529us/step - loss: 0.0266 - accuracy: 0.9430 - val_loss: 0.0256 - val_accuracy: 0.9000\n",
      "Epoch 1729/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.0075 - accuracy: 0.9570 - val_loss: 0.0254 - val_accuracy: 0.9500\n",
      "Epoch 1730/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.0119 - accuracy: 0.9500 - val_loss: 0.0148 - val_accuracy: 0.9000\n",
      "Epoch 1731/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0110 - accuracy: 0.9460 - val_loss: 0.0196 - val_accuracy: 0.9750\n",
      "Epoch 1732/2000\n",
      "1000/1000 [==============================] - 1s 560us/step - loss: 0.0148 - accuracy: 0.9460 - val_loss: 0.0433 - val_accuracy: 0.9000\n",
      "Epoch 1733/2000\n",
      "1000/1000 [==============================] - 1s 534us/step - loss: 0.0206 - accuracy: 0.9480 - val_loss: 0.0169 - val_accuracy: 0.9250\n",
      "Epoch 1734/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0137 - accuracy: 0.9600 - val_loss: 0.0307 - val_accuracy: 0.9250\n",
      "Epoch 1735/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0078 - accuracy: 0.9530 - val_loss: 0.0187 - val_accuracy: 0.8750\n",
      "Epoch 1736/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0098 - accuracy: 0.9430 - val_loss: 0.0208 - val_accuracy: 0.9000\n",
      "Epoch 1737/2000\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 0.0095 - accuracy: 0.9420 - val_loss: 0.0189 - val_accuracy: 0.9000\n",
      "Epoch 1738/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0079 - accuracy: 0.9410 - val_loss: 0.0147 - val_accuracy: 0.9000\n",
      "Epoch 1739/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0088 - accuracy: 0.9540 - val_loss: 0.0533 - val_accuracy: 0.8750\n",
      "Epoch 1740/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0174 - accuracy: 0.9400 - val_loss: 0.0180 - val_accuracy: 0.9500\n",
      "Epoch 1741/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.0177 - accuracy: 0.9480 - val_loss: 0.0341 - val_accuracy: 0.9250\n",
      "Epoch 1742/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0086 - accuracy: 0.9530 - val_loss: 0.0129 - val_accuracy: 0.9250\n",
      "Epoch 1743/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0149 - accuracy: 0.9430 - val_loss: 0.0232 - val_accuracy: 0.9000\n",
      "Epoch 1744/2000\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 0.0103 - accuracy: 0.9510 - val_loss: 0.0291 - val_accuracy: 0.9000\n",
      "Epoch 1745/2000\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 0.0076 - accuracy: 0.9450 - val_loss: 0.0279 - val_accuracy: 0.9250\n",
      "Epoch 1746/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0188 - accuracy: 0.9500 - val_loss: 0.0319 - val_accuracy: 0.9000\n",
      "Epoch 1747/2000\n",
      "1000/1000 [==============================] - 1s 581us/step - loss: 0.0166 - accuracy: 0.9530 - val_loss: 0.0237 - val_accuracy: 0.9750\n",
      "Epoch 1748/2000\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 0.0087 - accuracy: 0.9430 - val_loss: 0.0256 - val_accuracy: 0.9000\n",
      "Epoch 1749/2000\n",
      "1000/1000 [==============================] - 1s 633us/step - loss: 0.0153 - accuracy: 0.9470 - val_loss: 0.0660 - val_accuracy: 0.9250\n",
      "Epoch 1750/2000\n",
      "1000/1000 [==============================] - 1s 645us/step - loss: 0.0138 - accuracy: 0.9430 - val_loss: 0.0313 - val_accuracy: 0.9500\n",
      "Epoch 1751/2000\n",
      "1000/1000 [==============================] - 1s 633us/step - loss: 0.0116 - accuracy: 0.9520 - val_loss: 0.0162 - val_accuracy: 0.9500\n",
      "Epoch 1752/2000\n",
      "1000/1000 [==============================] - 1s 624us/step - loss: 0.0102 - accuracy: 0.9570 - val_loss: 0.0263 - val_accuracy: 0.9250\n",
      "Epoch 1753/2000\n",
      "1000/1000 [==============================] - 1s 623us/step - loss: 0.0111 - accuracy: 0.9440 - val_loss: 0.0229 - val_accuracy: 0.9250\n",
      "Epoch 1754/2000\n",
      "1000/1000 [==============================] - 1s 643us/step - loss: 0.0102 - accuracy: 0.9520 - val_loss: 0.0218 - val_accuracy: 0.9000\n",
      "Epoch 1755/2000\n",
      "1000/1000 [==============================] - 1s 628us/step - loss: 0.0075 - accuracy: 0.9540 - val_loss: 0.0239 - val_accuracy: 0.9000\n",
      "Epoch 1756/2000\n",
      "1000/1000 [==============================] - 1s 657us/step - loss: 0.0087 - accuracy: 0.9490 - val_loss: 0.0221 - val_accuracy: 0.9250\n",
      "Epoch 1757/2000\n",
      "1000/1000 [==============================] - 1s 675us/step - loss: 0.0197 - accuracy: 0.9450 - val_loss: 0.0213 - val_accuracy: 0.9000\n",
      "Epoch 1758/2000\n",
      "1000/1000 [==============================] - 1s 640us/step - loss: 0.0123 - accuracy: 0.9430 - val_loss: 0.0224 - val_accuracy: 0.9250\n",
      "Epoch 1759/2000\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0073 - accuracy: 0.9540 - val_loss: 0.0264 - val_accuracy: 0.9500\n",
      "Epoch 1760/2000\n",
      "1000/1000 [==============================] - 1s 577us/step - loss: 0.0088 - accuracy: 0.9480 - val_loss: 0.0277 - val_accuracy: 0.9000\n",
      "Epoch 1761/2000\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 0.0083 - accuracy: 0.9430 - val_loss: 0.0301 - val_accuracy: 0.9250\n",
      "Epoch 1762/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.0097 - accuracy: 0.9400 - val_loss: 0.0142 - val_accuracy: 0.8750\n",
      "Epoch 1763/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0123 - accuracy: 0.9500 - val_loss: 0.0119 - val_accuracy: 0.9250\n",
      "Epoch 1764/2000\n",
      "1000/1000 [==============================] - 1s 580us/step - loss: 0.0233 - accuracy: 0.9450 - val_loss: 0.0399 - val_accuracy: 0.9250\n",
      "Epoch 1765/2000\n",
      "1000/1000 [==============================] - 1s 594us/step - loss: 0.0129 - accuracy: 0.9490 - val_loss: 0.0349 - val_accuracy: 0.9250\n",
      "Epoch 1766/2000\n",
      "1000/1000 [==============================] - 1s 530us/step - loss: 0.0126 - accuracy: 0.9510 - val_loss: 0.0547 - val_accuracy: 0.9250\n",
      "Epoch 1767/2000\n",
      "1000/1000 [==============================] - 1s 572us/step - loss: 0.0094 - accuracy: 0.9530 - val_loss: 0.0566 - val_accuracy: 0.9000\n",
      "Epoch 1768/2000\n",
      "1000/1000 [==============================] - 1s 530us/step - loss: 0.0131 - accuracy: 0.9470 - val_loss: 0.0184 - val_accuracy: 0.9250\n",
      "Epoch 1769/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0145 - accuracy: 0.9500 - val_loss: 0.0240 - val_accuracy: 0.9500\n",
      "Epoch 1770/2000\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 0.0149 - accuracy: 0.9440 - val_loss: 0.0162 - val_accuracy: 0.9250\n",
      "Epoch 1771/2000\n",
      "1000/1000 [==============================] - 1s 549us/step - loss: 0.0139 - accuracy: 0.9570 - val_loss: 0.0230 - val_accuracy: 0.9500\n",
      "Epoch 1772/2000\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 0.0121 - accuracy: 0.9560 - val_loss: 0.0212 - val_accuracy: 0.9500\n",
      "Epoch 1773/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0187 - accuracy: 0.9540 - val_loss: 0.0419 - val_accuracy: 0.9250\n",
      "Epoch 1774/2000\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 0.0105 - accuracy: 0.9570 - val_loss: 0.0461 - val_accuracy: 0.9500\n",
      "Epoch 1775/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0138 - accuracy: 0.9500 - val_loss: 0.0315 - val_accuracy: 0.9000\n",
      "Epoch 1776/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0171 - accuracy: 0.9530 - val_loss: 0.0150 - val_accuracy: 0.9250\n",
      "Epoch 1777/2000\n",
      "1000/1000 [==============================] - 1s 568us/step - loss: 0.0094 - accuracy: 0.9520 - val_loss: 0.0167 - val_accuracy: 0.9250\n",
      "Epoch 1778/2000\n",
      "1000/1000 [==============================] - 1s 559us/step - loss: 0.0119 - accuracy: 0.9470 - val_loss: 0.0139 - val_accuracy: 0.9000\n",
      "Epoch 1779/2000\n",
      "1000/1000 [==============================] - 1s 590us/step - loss: 0.0068 - accuracy: 0.9410 - val_loss: 0.0148 - val_accuracy: 0.9500\n",
      "Epoch 1780/2000\n",
      "1000/1000 [==============================] - 1s 557us/step - loss: 0.0242 - accuracy: 0.9370 - val_loss: 0.0269 - val_accuracy: 0.9250\n",
      "Epoch 1781/2000\n",
      "1000/1000 [==============================] - 1s 559us/step - loss: 0.0111 - accuracy: 0.9480 - val_loss: 0.0241 - val_accuracy: 0.9250\n",
      "Epoch 1782/2000\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0095 - accuracy: 0.9490 - val_loss: 0.0253 - val_accuracy: 0.9250\n",
      "Epoch 1783/2000\n",
      "1000/1000 [==============================] - 1s 561us/step - loss: 0.0086 - accuracy: 0.9520 - val_loss: 0.0230 - val_accuracy: 0.9250\n",
      "Epoch 1784/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0135 - accuracy: 0.9600 - val_loss: 0.0236 - val_accuracy: 0.9000\n",
      "Epoch 1785/2000\n",
      "1000/1000 [==============================] - 1s 549us/step - loss: 0.0185 - accuracy: 0.9420 - val_loss: 0.0196 - val_accuracy: 0.9250\n",
      "Epoch 1786/2000\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 0.0168 - accuracy: 0.9550 - val_loss: 0.0443 - val_accuracy: 0.9000\n",
      "Epoch 1787/2000\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 0.0147 - accuracy: 0.9460 - val_loss: 0.0297 - val_accuracy: 0.9000\n",
      "Epoch 1788/2000\n",
      "1000/1000 [==============================] - 1s 549us/step - loss: 0.0087 - accuracy: 0.9570 - val_loss: 0.0330 - val_accuracy: 0.9500\n",
      "Epoch 1789/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0214 - accuracy: 0.9490 - val_loss: 0.0148 - val_accuracy: 0.9000\n",
      "Epoch 1790/2000\n",
      "1000/1000 [==============================] - 1s 556us/step - loss: 0.0113 - accuracy: 0.9520 - val_loss: 0.0214 - val_accuracy: 0.9250\n",
      "Epoch 1791/2000\n",
      "1000/1000 [==============================] - 1s 531us/step - loss: 0.0115 - accuracy: 0.9530 - val_loss: 0.0144 - val_accuracy: 0.9250\n",
      "Epoch 1792/2000\n",
      "1000/1000 [==============================] - 1s 534us/step - loss: 0.0072 - accuracy: 0.9520 - val_loss: 0.0218 - val_accuracy: 0.9250\n",
      "Epoch 1793/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 568us/step - loss: 0.0088 - accuracy: 0.9480 - val_loss: 0.0153 - val_accuracy: 0.9500\n",
      "Epoch 1794/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0073 - accuracy: 0.9590 - val_loss: 0.0222 - val_accuracy: 0.9500\n",
      "Epoch 1795/2000\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 0.0077 - accuracy: 0.9650 - val_loss: 0.0155 - val_accuracy: 0.9250\n",
      "Epoch 1796/2000\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 0.0145 - accuracy: 0.9580 - val_loss: 0.0232 - val_accuracy: 0.9250\n",
      "Epoch 1797/2000\n",
      "1000/1000 [==============================] - 1s 533us/step - loss: 0.0146 - accuracy: 0.9480 - val_loss: 0.0152 - val_accuracy: 0.9500\n",
      "Epoch 1798/2000\n",
      "1000/1000 [==============================] - 1s 543us/step - loss: 0.0089 - accuracy: 0.9470 - val_loss: 0.0257 - val_accuracy: 0.9250\n",
      "Epoch 1799/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0144 - accuracy: 0.9550 - val_loss: 0.0234 - val_accuracy: 0.9000\n",
      "Epoch 1800/2000\n",
      "1000/1000 [==============================] - 1s 580us/step - loss: 0.0146 - accuracy: 0.9440 - val_loss: 0.0217 - val_accuracy: 0.9250\n",
      "Epoch 1801/2000\n",
      "1000/1000 [==============================] - 1s 576us/step - loss: 0.0125 - accuracy: 0.9470 - val_loss: 0.0256 - val_accuracy: 0.9500\n",
      "Epoch 1802/2000\n",
      "1000/1000 [==============================] - 1s 543us/step - loss: 0.0124 - accuracy: 0.9510 - val_loss: 0.0301 - val_accuracy: 0.9250\n",
      "Epoch 1803/2000\n",
      "1000/1000 [==============================] - 1s 580us/step - loss: 0.0073 - accuracy: 0.9560 - val_loss: 0.0178 - val_accuracy: 0.9250\n",
      "Epoch 1804/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0121 - accuracy: 0.9570 - val_loss: 0.0477 - val_accuracy: 0.9000\n",
      "Epoch 1805/2000\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 0.0084 - accuracy: 0.9380 - val_loss: 0.0135 - val_accuracy: 0.9250\n",
      "Epoch 1806/2000\n",
      "1000/1000 [==============================] - 1s 567us/step - loss: 0.0082 - accuracy: 0.9380 - val_loss: 0.0271 - val_accuracy: 0.9500\n",
      "Epoch 1807/2000\n",
      "1000/1000 [==============================] - 1s 557us/step - loss: 0.0138 - accuracy: 0.9510 - val_loss: 0.0227 - val_accuracy: 0.9000\n",
      "Epoch 1808/2000\n",
      "1000/1000 [==============================] - 1s 525us/step - loss: 0.0092 - accuracy: 0.9510 - val_loss: 0.0170 - val_accuracy: 0.9250\n",
      "Epoch 1809/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.0085 - accuracy: 0.9480 - val_loss: 0.0191 - val_accuracy: 0.8750\n",
      "Epoch 1810/2000\n",
      "1000/1000 [==============================] - 1s 561us/step - loss: 0.0103 - accuracy: 0.9520 - val_loss: 0.0193 - val_accuracy: 0.9250\n",
      "Epoch 1811/2000\n",
      "1000/1000 [==============================] - 1s 584us/step - loss: 0.0120 - accuracy: 0.9520 - val_loss: 0.0197 - val_accuracy: 0.9250\n",
      "Epoch 1812/2000\n",
      "1000/1000 [==============================] - 1s 574us/step - loss: 0.0374 - accuracy: 0.9450 - val_loss: 0.0273 - val_accuracy: 0.9000\n",
      "Epoch 1813/2000\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.0129 - accuracy: 0.9440 - val_loss: 0.0245 - val_accuracy: 0.9500\n",
      "Epoch 1814/2000\n",
      "1000/1000 [==============================] - 1s 552us/step - loss: 0.0097 - accuracy: 0.9490 - val_loss: 0.0248 - val_accuracy: 0.9250\n",
      "Epoch 1815/2000\n",
      "1000/1000 [==============================] - 1s 591us/step - loss: 0.0115 - accuracy: 0.9590 - val_loss: 0.0173 - val_accuracy: 0.9750\n",
      "Epoch 1816/2000\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0060 - accuracy: 0.9650 - val_loss: 0.0177 - val_accuracy: 0.9750\n",
      "Epoch 1817/2000\n",
      "1000/1000 [==============================] - 1s 579us/step - loss: 0.0127 - accuracy: 0.9610 - val_loss: 0.0160 - val_accuracy: 0.9500\n",
      "Epoch 1818/2000\n",
      "1000/1000 [==============================] - 1s 577us/step - loss: 0.0105 - accuracy: 0.9510 - val_loss: 0.0104 - val_accuracy: 0.9250\n",
      "Epoch 1819/2000\n",
      "1000/1000 [==============================] - 1s 537us/step - loss: 0.0148 - accuracy: 0.9490 - val_loss: 0.0294 - val_accuracy: 0.9250\n",
      "Epoch 1820/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0158 - accuracy: 0.9560 - val_loss: 0.0155 - val_accuracy: 0.9500\n",
      "Epoch 1821/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0082 - accuracy: 0.9520 - val_loss: 0.0121 - val_accuracy: 0.9750\n",
      "Epoch 1822/2000\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.0135 - accuracy: 0.9580 - val_loss: 0.0125 - val_accuracy: 0.9500\n",
      "Epoch 1823/2000\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 0.0157 - accuracy: 0.9620 - val_loss: 0.0107 - val_accuracy: 0.9500\n",
      "Epoch 1824/2000\n",
      "1000/1000 [==============================] - 1s 581us/step - loss: 0.0075 - accuracy: 0.9530 - val_loss: 0.0262 - val_accuracy: 0.9500\n",
      "Epoch 1825/2000\n",
      "1000/1000 [==============================] - 1s 576us/step - loss: 0.0121 - accuracy: 0.9600 - val_loss: 0.0346 - val_accuracy: 0.9250\n",
      "Epoch 1826/2000\n",
      "1000/1000 [==============================] - 1s 587us/step - loss: 0.0091 - accuracy: 0.9520 - val_loss: 0.0141 - val_accuracy: 0.9250\n",
      "Epoch 1827/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0095 - accuracy: 0.9550 - val_loss: 0.0149 - val_accuracy: 0.9500\n",
      "Epoch 1828/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0098 - accuracy: 0.9540 - val_loss: 0.0247 - val_accuracy: 0.9250\n",
      "Epoch 1829/2000\n",
      "1000/1000 [==============================] - 1s 563us/step - loss: 0.0121 - accuracy: 0.9540 - val_loss: 0.0130 - val_accuracy: 0.9750\n",
      "Epoch 1830/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.0093 - accuracy: 0.9510 - val_loss: 0.0171 - val_accuracy: 0.9500\n",
      "Epoch 1831/2000\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 0.0084 - accuracy: 0.9550 - val_loss: 0.0221 - val_accuracy: 0.9500\n",
      "Epoch 1832/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0141 - accuracy: 0.9570 - val_loss: 0.0243 - val_accuracy: 0.9500\n",
      "Epoch 1833/2000\n",
      "1000/1000 [==============================] - 1s 529us/step - loss: 0.0112 - accuracy: 0.9630 - val_loss: 0.0193 - val_accuracy: 0.9750\n",
      "Epoch 1834/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0124 - accuracy: 0.9490 - val_loss: 0.0436 - val_accuracy: 0.9500\n",
      "Epoch 1835/2000\n",
      "1000/1000 [==============================] - 1s 571us/step - loss: 0.0106 - accuracy: 0.9560 - val_loss: 0.0347 - val_accuracy: 0.9500\n",
      "Epoch 1836/2000\n",
      "1000/1000 [==============================] - 1s 562us/step - loss: 0.0116 - accuracy: 0.9540 - val_loss: 0.0237 - val_accuracy: 0.9750\n",
      "Epoch 1837/2000\n",
      "1000/1000 [==============================] - 1s 563us/step - loss: 0.0209 - accuracy: 0.9520 - val_loss: 0.0224 - val_accuracy: 0.9000\n",
      "Epoch 1838/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.0156 - accuracy: 0.9420 - val_loss: 0.0112 - val_accuracy: 0.9000\n",
      "Epoch 1839/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0127 - accuracy: 0.9400 - val_loss: 0.0204 - val_accuracy: 0.9250\n",
      "Epoch 1840/2000\n",
      "1000/1000 [==============================] - 1s 523us/step - loss: 0.0080 - accuracy: 0.9520 - val_loss: 0.0401 - val_accuracy: 0.9500\n",
      "Epoch 1841/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0150 - accuracy: 0.9570 - val_loss: 0.0224 - val_accuracy: 0.9500\n",
      "Epoch 1842/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0070 - accuracy: 0.9500 - val_loss: 0.0172 - val_accuracy: 0.9500\n",
      "Epoch 1843/2000\n",
      "1000/1000 [==============================] - 1s 506us/step - loss: 0.0129 - accuracy: 0.9500 - val_loss: 0.0248 - val_accuracy: 0.9500\n",
      "Epoch 1844/2000\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.0101 - accuracy: 0.9400 - val_loss: 0.0290 - val_accuracy: 0.9250\n",
      "Epoch 1845/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0160 - accuracy: 0.9560 - val_loss: 0.0190 - val_accuracy: 0.9250\n",
      "Epoch 1846/2000\n",
      "1000/1000 [==============================] - 1s 510us/step - loss: 0.0087 - accuracy: 0.9440 - val_loss: 0.0122 - val_accuracy: 0.9250\n",
      "Epoch 1847/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 526us/step - loss: 0.0105 - accuracy: 0.9510 - val_loss: 0.0177 - val_accuracy: 0.9500\n",
      "Epoch 1848/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0073 - accuracy: 0.9480 - val_loss: 0.0162 - val_accuracy: 0.9000\n",
      "Epoch 1849/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0103 - accuracy: 0.9510 - val_loss: 0.0119 - val_accuracy: 0.9000\n",
      "Epoch 1850/2000\n",
      "1000/1000 [==============================] - 1s 530us/step - loss: 0.0164 - accuracy: 0.9450 - val_loss: 0.0220 - val_accuracy: 0.9250\n",
      "Epoch 1851/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.0094 - accuracy: 0.9610 - val_loss: 0.0355 - val_accuracy: 0.9500\n",
      "Epoch 1852/2000\n",
      "1000/1000 [==============================] - 1s 533us/step - loss: 0.0116 - accuracy: 0.9470 - val_loss: 0.0176 - val_accuracy: 0.8750\n",
      "Epoch 1853/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0107 - accuracy: 0.9460 - val_loss: 0.0131 - val_accuracy: 0.9250\n",
      "Epoch 1854/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0125 - accuracy: 0.9450 - val_loss: 0.0218 - val_accuracy: 0.9250\n",
      "Epoch 1855/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0120 - accuracy: 0.9610 - val_loss: 0.0164 - val_accuracy: 0.9000\n",
      "Epoch 1856/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0095 - accuracy: 0.9490 - val_loss: 0.0271 - val_accuracy: 0.9750\n",
      "Epoch 1857/2000\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 0.0192 - accuracy: 0.9480 - val_loss: 0.0309 - val_accuracy: 0.9500\n",
      "Epoch 1858/2000\n",
      "1000/1000 [==============================] - 1s 534us/step - loss: 0.0218 - accuracy: 0.9520 - val_loss: 0.0185 - val_accuracy: 0.9000\n",
      "Epoch 1859/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0085 - accuracy: 0.9440 - val_loss: 0.0154 - val_accuracy: 0.9250\n",
      "Epoch 1860/2000\n",
      "1000/1000 [==============================] - 1s 542us/step - loss: 0.0075 - accuracy: 0.9500 - val_loss: 0.0383 - val_accuracy: 0.9000\n",
      "Epoch 1861/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.0145 - accuracy: 0.9390 - val_loss: 0.0235 - val_accuracy: 0.9250\n",
      "Epoch 1862/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0126 - accuracy: 0.9550 - val_loss: 0.0242 - val_accuracy: 0.9250\n",
      "Epoch 1863/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.0084 - accuracy: 0.9480 - val_loss: 0.0233 - val_accuracy: 0.9250\n",
      "Epoch 1864/2000\n",
      "1000/1000 [==============================] - 1s 523us/step - loss: 0.0101 - accuracy: 0.9400 - val_loss: 0.0200 - val_accuracy: 0.9500\n",
      "Epoch 1865/2000\n",
      "1000/1000 [==============================] - 1s 543us/step - loss: 0.0054 - accuracy: 0.9590 - val_loss: 0.0181 - val_accuracy: 0.9250\n",
      "Epoch 1866/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0086 - accuracy: 0.9460 - val_loss: 0.0246 - val_accuracy: 0.9250\n",
      "Epoch 1867/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0091 - accuracy: 0.9450 - val_loss: 0.0141 - val_accuracy: 0.9000\n",
      "Epoch 1868/2000\n",
      "1000/1000 [==============================] - 1s 529us/step - loss: 0.0097 - accuracy: 0.9570 - val_loss: 0.0221 - val_accuracy: 0.9500\n",
      "Epoch 1869/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0113 - accuracy: 0.9400 - val_loss: 0.0179 - val_accuracy: 0.9500\n",
      "Epoch 1870/2000\n",
      "1000/1000 [==============================] - 1s 507us/step - loss: 0.0147 - accuracy: 0.9520 - val_loss: 0.0379 - val_accuracy: 0.9250\n",
      "Epoch 1871/2000\n",
      "1000/1000 [==============================] - 1s 539us/step - loss: 0.0116 - accuracy: 0.9560 - val_loss: 0.0583 - val_accuracy: 0.9250\n",
      "Epoch 1872/2000\n",
      "1000/1000 [==============================] - 1s 529us/step - loss: 0.0137 - accuracy: 0.9490 - val_loss: 0.0267 - val_accuracy: 0.9500\n",
      "Epoch 1873/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0117 - accuracy: 0.9490 - val_loss: 0.0302 - val_accuracy: 0.9500\n",
      "Epoch 1874/2000\n",
      "1000/1000 [==============================] - 1s 531us/step - loss: 0.0073 - accuracy: 0.9520 - val_loss: 0.0307 - val_accuracy: 0.9500\n",
      "Epoch 1875/2000\n",
      "1000/1000 [==============================] - 1s 533us/step - loss: 0.0193 - accuracy: 0.9470 - val_loss: 0.0250 - val_accuracy: 0.9500\n",
      "Epoch 1876/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0084 - accuracy: 0.9520 - val_loss: 0.0251 - val_accuracy: 0.9500\n",
      "Epoch 1877/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.0160 - accuracy: 0.9590 - val_loss: 0.0160 - val_accuracy: 0.9500\n",
      "Epoch 1878/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0106 - accuracy: 0.9530 - val_loss: 0.0272 - val_accuracy: 0.9250\n",
      "Epoch 1879/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0096 - accuracy: 0.9490 - val_loss: 0.0197 - val_accuracy: 0.9500\n",
      "Epoch 1880/2000\n",
      "1000/1000 [==============================] - 1s 505us/step - loss: 0.0126 - accuracy: 0.9580 - val_loss: 0.0241 - val_accuracy: 0.9500\n",
      "Epoch 1881/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.0084 - accuracy: 0.9510 - val_loss: 0.0156 - val_accuracy: 0.9250\n",
      "Epoch 1882/2000\n",
      "1000/1000 [==============================] - 1s 505us/step - loss: 0.0087 - accuracy: 0.9470 - val_loss: 0.0206 - val_accuracy: 0.9250\n",
      "Epoch 1883/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0102 - accuracy: 0.9550 - val_loss: 0.0296 - val_accuracy: 0.9500\n",
      "Epoch 1884/2000\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 0.0113 - accuracy: 0.9600 - val_loss: 0.0517 - val_accuracy: 0.9250\n",
      "Epoch 1885/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0129 - accuracy: 0.9460 - val_loss: 0.0236 - val_accuracy: 0.9250\n",
      "Epoch 1886/2000\n",
      "1000/1000 [==============================] - 1s 506us/step - loss: 0.0085 - accuracy: 0.9470 - val_loss: 0.0496 - val_accuracy: 0.9500\n",
      "Epoch 1887/2000\n",
      "1000/1000 [==============================] - 1s 550us/step - loss: 0.0098 - accuracy: 0.9560 - val_loss: 0.0168 - val_accuracy: 0.9750\n",
      "Epoch 1888/2000\n",
      "1000/1000 [==============================] - 1s 529us/step - loss: 0.0106 - accuracy: 0.9550 - val_loss: 0.0184 - val_accuracy: 0.9750\n",
      "Epoch 1889/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.0091 - accuracy: 0.9570 - val_loss: 0.0262 - val_accuracy: 0.9000\n",
      "Epoch 1890/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0108 - accuracy: 0.9580 - val_loss: 0.0142 - val_accuracy: 0.9250\n",
      "Epoch 1891/2000\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 0.0127 - accuracy: 0.9480 - val_loss: 0.0337 - val_accuracy: 0.8750\n",
      "Epoch 1892/2000\n",
      "1000/1000 [==============================] - 1s 510us/step - loss: 0.0512 - accuracy: 0.9410 - val_loss: 0.0300 - val_accuracy: 0.9250\n",
      "Epoch 1893/2000\n",
      "1000/1000 [==============================] - 1s 504us/step - loss: 0.0087 - accuracy: 0.9380 - val_loss: 0.0418 - val_accuracy: 0.9500\n",
      "Epoch 1894/2000\n",
      "1000/1000 [==============================] - 1s 505us/step - loss: 0.0192 - accuracy: 0.9470 - val_loss: 0.0236 - val_accuracy: 0.9750\n",
      "Epoch 1895/2000\n",
      "1000/1000 [==============================] - 1s 506us/step - loss: 0.0141 - accuracy: 0.9560 - val_loss: 0.0154 - val_accuracy: 0.9500\n",
      "Epoch 1896/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0125 - accuracy: 0.9510 - val_loss: 0.0344 - val_accuracy: 0.9500\n",
      "Epoch 1897/2000\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 0.0124 - accuracy: 0.9490 - val_loss: 0.0229 - val_accuracy: 0.9250\n",
      "Epoch 1898/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0109 - accuracy: 0.9440 - val_loss: 0.0544 - val_accuracy: 0.9500\n",
      "Epoch 1899/2000\n",
      "1000/1000 [==============================] - 1s 505us/step - loss: 0.0099 - accuracy: 0.9520 - val_loss: 0.0255 - val_accuracy: 0.9750\n",
      "Epoch 1900/2000\n",
      "1000/1000 [==============================] - 1s 529us/step - loss: 0.0104 - accuracy: 0.9520 - val_loss: 0.0146 - val_accuracy: 0.9500\n",
      "Epoch 1901/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0072 - accuracy: 0.9530 - val_loss: 0.0326 - val_accuracy: 0.9500\n",
      "Epoch 1902/2000\n",
      "1000/1000 [==============================] - 1s 542us/step - loss: 0.0051 - accuracy: 0.9460 - val_loss: 0.0179 - val_accuracy: 0.9250\n",
      "Epoch 1903/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0075 - accuracy: 0.9560 - val_loss: 0.0260 - val_accuracy: 0.9750\n",
      "Epoch 1904/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0096 - accuracy: 0.9540 - val_loss: 0.0366 - val_accuracy: 0.9750\n",
      "Epoch 1905/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.0115 - accuracy: 0.9390 - val_loss: 0.0138 - val_accuracy: 0.9000\n",
      "Epoch 1906/2000\n",
      "1000/1000 [==============================] - 1s 538us/step - loss: 0.0102 - accuracy: 0.9550 - val_loss: 0.0185 - val_accuracy: 0.9250\n",
      "Epoch 1907/2000\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 0.0078 - accuracy: 0.9660 - val_loss: 0.0157 - val_accuracy: 0.9000\n",
      "Epoch 1908/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.0101 - accuracy: 0.9530 - val_loss: 0.0352 - val_accuracy: 0.9250\n",
      "Epoch 1909/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0110 - accuracy: 0.9340 - val_loss: 0.0417 - val_accuracy: 0.9250\n",
      "Epoch 1910/2000\n",
      "1000/1000 [==============================] - 1s 533us/step - loss: 0.0065 - accuracy: 0.9490 - val_loss: 0.0155 - val_accuracy: 0.9000\n",
      "Epoch 1911/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0111 - accuracy: 0.9610 - val_loss: 0.0208 - val_accuracy: 0.9500\n",
      "Epoch 1912/2000\n",
      "1000/1000 [==============================] - 1s 551us/step - loss: 0.0090 - accuracy: 0.9650 - val_loss: 0.0411 - val_accuracy: 0.9500\n",
      "Epoch 1913/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.0119 - accuracy: 0.9530 - val_loss: 0.0158 - val_accuracy: 0.9750\n",
      "Epoch 1914/2000\n",
      "1000/1000 [==============================] - 1s 507us/step - loss: 0.0114 - accuracy: 0.9480 - val_loss: 0.0169 - val_accuracy: 0.9500\n",
      "Epoch 1915/2000\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 0.0241 - accuracy: 0.9470 - val_loss: 0.0532 - val_accuracy: 0.9250\n",
      "Epoch 1916/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0150 - accuracy: 0.9520 - val_loss: 0.0309 - val_accuracy: 0.9250\n",
      "Epoch 1917/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.0143 - accuracy: 0.9550 - val_loss: 0.0149 - val_accuracy: 0.9500\n",
      "Epoch 1918/2000\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0179 - accuracy: 0.9520 - val_loss: 0.0246 - val_accuracy: 0.9250\n",
      "Epoch 1919/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0128 - accuracy: 0.9530 - val_loss: 0.0133 - val_accuracy: 0.9250\n",
      "Epoch 1920/2000\n",
      "1000/1000 [==============================] - 1s 544us/step - loss: 0.0096 - accuracy: 0.9490 - val_loss: 0.0113 - val_accuracy: 0.9500\n",
      "Epoch 1921/2000\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 0.0108 - accuracy: 0.9510 - val_loss: 0.0458 - val_accuracy: 0.9500\n",
      "Epoch 1922/2000\n",
      "1000/1000 [==============================] - 1s 529us/step - loss: 0.0111 - accuracy: 0.9570 - val_loss: 0.0256 - val_accuracy: 0.9250\n",
      "Epoch 1923/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0097 - accuracy: 0.9590 - val_loss: 0.0207 - val_accuracy: 0.9000\n",
      "Epoch 1924/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0115 - accuracy: 0.9570 - val_loss: 0.0155 - val_accuracy: 0.9250\n",
      "Epoch 1925/2000\n",
      "1000/1000 [==============================] - 1s 543us/step - loss: 0.0114 - accuracy: 0.9530 - val_loss: 0.0209 - val_accuracy: 0.9250\n",
      "Epoch 1926/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0055 - accuracy: 0.9550 - val_loss: 0.0145 - val_accuracy: 0.9500\n",
      "Epoch 1927/2000\n",
      "1000/1000 [==============================] - 1s 534us/step - loss: 0.0098 - accuracy: 0.9510 - val_loss: 0.0456 - val_accuracy: 0.9250\n",
      "Epoch 1928/2000\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0103 - accuracy: 0.9580 - val_loss: 0.0164 - val_accuracy: 0.9250\n",
      "Epoch 1929/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0084 - accuracy: 0.9580 - val_loss: 0.0263 - val_accuracy: 0.9250\n",
      "Epoch 1930/2000\n",
      "1000/1000 [==============================] - 1s 523us/step - loss: 0.0114 - accuracy: 0.9570 - val_loss: 0.0126 - val_accuracy: 0.9000\n",
      "Epoch 1931/2000\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 0.0095 - accuracy: 0.9570 - val_loss: 0.0214 - val_accuracy: 0.9750\n",
      "Epoch 1932/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0067 - accuracy: 0.9610 - val_loss: 0.0187 - val_accuracy: 0.9250\n",
      "Epoch 1933/2000\n",
      "1000/1000 [==============================] - 1s 523us/step - loss: 0.0111 - accuracy: 0.9500 - val_loss: 0.0131 - val_accuracy: 0.9750\n",
      "Epoch 1934/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0128 - accuracy: 0.9510 - val_loss: 0.0111 - val_accuracy: 0.9500\n",
      "Epoch 1935/2000\n",
      "1000/1000 [==============================] - 1s 530us/step - loss: 0.0082 - accuracy: 0.9610 - val_loss: 0.0172 - val_accuracy: 0.9250\n",
      "Epoch 1936/2000\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.0116 - accuracy: 0.9440 - val_loss: 0.0147 - val_accuracy: 0.9750\n",
      "Epoch 1937/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0066 - accuracy: 0.9520 - val_loss: 0.0190 - val_accuracy: 0.9500\n",
      "Epoch 1938/2000\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 0.0084 - accuracy: 0.9560 - val_loss: 0.0155 - val_accuracy: 0.9250\n",
      "Epoch 1939/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0055 - accuracy: 0.9570 - val_loss: 0.0157 - val_accuracy: 0.9750\n",
      "Epoch 1940/2000\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 0.0125 - accuracy: 0.9410 - val_loss: 0.0176 - val_accuracy: 0.9750\n",
      "Epoch 1941/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0208 - accuracy: 0.9480 - val_loss: 0.0184 - val_accuracy: 0.9750\n",
      "Epoch 1942/2000\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 0.0117 - accuracy: 0.9520 - val_loss: 0.0154 - val_accuracy: 0.9500\n",
      "Epoch 1943/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0055 - accuracy: 0.9530 - val_loss: 0.0116 - val_accuracy: 0.9750\n",
      "Epoch 1944/2000\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 0.0160 - accuracy: 0.9570 - val_loss: 0.0198 - val_accuracy: 0.9500\n",
      "Epoch 1945/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0073 - accuracy: 0.9530 - val_loss: 0.0372 - val_accuracy: 0.9500\n",
      "Epoch 1946/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0090 - accuracy: 0.9540 - val_loss: 0.0190 - val_accuracy: 0.9500\n",
      "Epoch 1947/2000\n",
      "1000/1000 [==============================] - 1s 522us/step - loss: 0.0111 - accuracy: 0.9530 - val_loss: 0.0187 - val_accuracy: 0.9250\n",
      "Epoch 1948/2000\n",
      "1000/1000 [==============================] - 1s 538us/step - loss: 0.0091 - accuracy: 0.9470 - val_loss: 0.0231 - val_accuracy: 0.9250\n",
      "Epoch 1949/2000\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0105 - accuracy: 0.9480 - val_loss: 0.0465 - val_accuracy: 0.9750\n",
      "Epoch 1950/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0105 - accuracy: 0.9580 - val_loss: 0.0180 - val_accuracy: 0.9250\n",
      "Epoch 1951/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0119 - accuracy: 0.9610 - val_loss: 0.0381 - val_accuracy: 0.9250\n",
      "Epoch 1952/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0093 - accuracy: 0.9480 - val_loss: 0.0119 - val_accuracy: 0.9750\n",
      "Epoch 1953/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0097 - accuracy: 0.9600 - val_loss: 0.0163 - val_accuracy: 0.9250\n",
      "Epoch 1954/2000\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0106 - accuracy: 0.9440 - val_loss: 0.0272 - val_accuracy: 0.9250\n",
      "Epoch 1955/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 521us/step - loss: 0.0142 - accuracy: 0.9480 - val_loss: 0.0254 - val_accuracy: 0.9500\n",
      "Epoch 1956/2000\n",
      "1000/1000 [==============================] - 1s 512us/step - loss: 0.0168 - accuracy: 0.9460 - val_loss: 0.0211 - val_accuracy: 0.9250\n",
      "Epoch 1957/2000\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 0.0069 - accuracy: 0.9560 - val_loss: 0.0213 - val_accuracy: 0.9250\n",
      "Epoch 1958/2000\n",
      "1000/1000 [==============================] - 1s 514us/step - loss: 0.0121 - accuracy: 0.9580 - val_loss: 0.0215 - val_accuracy: 0.9500\n",
      "Epoch 1959/2000\n",
      "1000/1000 [==============================] - 1s 510us/step - loss: 0.0139 - accuracy: 0.9440 - val_loss: 0.0153 - val_accuracy: 0.9250\n",
      "Epoch 1960/2000\n",
      "1000/1000 [==============================] - 1s 506us/step - loss: 0.0085 - accuracy: 0.9590 - val_loss: 0.0312 - val_accuracy: 0.9250\n",
      "Epoch 1961/2000\n",
      "1000/1000 [==============================] - 1s 502us/step - loss: 0.0071 - accuracy: 0.9560 - val_loss: 0.0082 - val_accuracy: 0.9500\n",
      "Epoch 1962/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0164 - accuracy: 0.9530 - val_loss: 0.0165 - val_accuracy: 0.9250\n",
      "Epoch 1963/2000\n",
      "1000/1000 [==============================] - 1s 525us/step - loss: 0.0107 - accuracy: 0.9650 - val_loss: 0.0081 - val_accuracy: 0.8750\n",
      "Epoch 1964/2000\n",
      "1000/1000 [==============================] - 1s 510us/step - loss: 0.0222 - accuracy: 0.9550 - val_loss: 0.0137 - val_accuracy: 0.9750\n",
      "Epoch 1965/2000\n",
      "1000/1000 [==============================] - 1s 510us/step - loss: 0.0185 - accuracy: 0.9640 - val_loss: 0.0157 - val_accuracy: 0.9750\n",
      "Epoch 1966/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0162 - accuracy: 0.9440 - val_loss: 0.0164 - val_accuracy: 0.9000\n",
      "Epoch 1967/2000\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 0.0135 - accuracy: 0.9650 - val_loss: 0.0622 - val_accuracy: 0.9000\n",
      "Epoch 1968/2000\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 0.0136 - accuracy: 0.9560 - val_loss: 0.0198 - val_accuracy: 0.9250\n",
      "Epoch 1969/2000\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 0.0132 - accuracy: 0.9530 - val_loss: 0.0365 - val_accuracy: 0.9500\n",
      "Epoch 1970/2000\n",
      "1000/1000 [==============================] - 1s 517us/step - loss: 0.0107 - accuracy: 0.9520 - val_loss: 0.0189 - val_accuracy: 0.9500\n",
      "Epoch 1971/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0073 - accuracy: 0.9520 - val_loss: 0.0114 - val_accuracy: 0.9750\n",
      "Epoch 1972/2000\n",
      "1000/1000 [==============================] - 1s 505us/step - loss: 0.0087 - accuracy: 0.9590 - val_loss: 0.0243 - val_accuracy: 0.9250\n",
      "Epoch 1973/2000\n",
      "1000/1000 [==============================] - 1s 510us/step - loss: 0.0058 - accuracy: 0.9580 - val_loss: 0.0267 - val_accuracy: 0.9750\n",
      "Epoch 1974/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0061 - accuracy: 0.9530 - val_loss: 0.0376 - val_accuracy: 0.9250\n",
      "Epoch 1975/2000\n",
      "1000/1000 [==============================] - 1s 520us/step - loss: 0.0183 - accuracy: 0.9510 - val_loss: 0.0379 - val_accuracy: 0.9000\n",
      "Epoch 1976/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0167 - accuracy: 0.9520 - val_loss: 0.0257 - val_accuracy: 0.9750\n",
      "Epoch 1977/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0121 - accuracy: 0.9560 - val_loss: 0.0132 - val_accuracy: 0.9750\n",
      "Epoch 1978/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0091 - accuracy: 0.9480 - val_loss: 0.0241 - val_accuracy: 0.9500\n",
      "Epoch 1979/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0139 - accuracy: 0.9530 - val_loss: 0.0174 - val_accuracy: 0.9250\n",
      "Epoch 1980/2000\n",
      "1000/1000 [==============================] - 1s 546us/step - loss: 0.0138 - accuracy: 0.9520 - val_loss: 0.0263 - val_accuracy: 0.9500\n",
      "Epoch 1981/2000\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 0.0094 - accuracy: 0.9430 - val_loss: 0.0288 - val_accuracy: 0.9250\n",
      "Epoch 1982/2000\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 0.0102 - accuracy: 0.9600 - val_loss: 0.0171 - val_accuracy: 0.9750\n",
      "Epoch 1983/2000\n",
      "1000/1000 [==============================] - 1s 553us/step - loss: 0.0106 - accuracy: 0.9540 - val_loss: 0.0418 - val_accuracy: 0.9250\n",
      "Epoch 1984/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0135 - accuracy: 0.9580 - val_loss: 0.0186 - val_accuracy: 0.9500\n",
      "Epoch 1985/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0103 - accuracy: 0.9480 - val_loss: 0.0100 - val_accuracy: 0.9250\n",
      "Epoch 1986/2000\n",
      "1000/1000 [==============================] - 1s 552us/step - loss: 0.0136 - accuracy: 0.9550 - val_loss: 0.0279 - val_accuracy: 0.9500\n",
      "Epoch 1987/2000\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 0.0260 - accuracy: 0.9480 - val_loss: 0.0268 - val_accuracy: 0.9000\n",
      "Epoch 1988/2000\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 0.0096 - accuracy: 0.9450 - val_loss: 0.0202 - val_accuracy: 0.9250\n",
      "Epoch 1989/2000\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 0.0086 - accuracy: 0.9440 - val_loss: 0.0288 - val_accuracy: 0.9250\n",
      "Epoch 1990/2000\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 0.0093 - accuracy: 0.9500 - val_loss: 0.0259 - val_accuracy: 0.9500\n",
      "Epoch 1991/2000\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 0.0079 - accuracy: 0.9530 - val_loss: 0.0144 - val_accuracy: 0.9250\n",
      "Epoch 1992/2000\n",
      "1000/1000 [==============================] - 1s 541us/step - loss: 0.0151 - accuracy: 0.9600 - val_loss: 0.0188 - val_accuracy: 0.9750\n",
      "Epoch 1993/2000\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0065 - accuracy: 0.9600 - val_loss: 0.0165 - val_accuracy: 0.9250\n",
      "Epoch 1994/2000\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 0.0134 - accuracy: 0.9530 - val_loss: 0.0588 - val_accuracy: 0.9500\n",
      "Epoch 1995/2000\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.0164 - accuracy: 0.9510 - val_loss: 0.0175 - val_accuracy: 0.8750\n",
      "Epoch 1996/2000\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.0123 - accuracy: 0.9390 - val_loss: 0.0384 - val_accuracy: 0.9500\n",
      "Epoch 1997/2000\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 0.0100 - accuracy: 0.9460 - val_loss: 0.0163 - val_accuracy: 0.9500\n",
      "Epoch 1998/2000\n",
      "1000/1000 [==============================] - 1s 503us/step - loss: 0.0074 - accuracy: 0.9570 - val_loss: 0.0171 - val_accuracy: 0.8750\n",
      "Epoch 1999/2000\n",
      "1000/1000 [==============================] - 1s 524us/step - loss: 0.0110 - accuracy: 0.9540 - val_loss: 0.0138 - val_accuracy: 0.9500\n",
      "Epoch 2000/2000\n",
      "1000/1000 [==============================] - 1s 525us/step - loss: 0.0080 - accuracy: 0.9490 - val_loss: 0.0391 - val_accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(p_train,B_train,validation_split=0.038,batch_size=20,epochs=2000,callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('EmuBk0.2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f91d42d5cf8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f91b0295b00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "plt.suptitle(r'Accuracy and Loss on the validation set for $B(k_1,k_2,k_3)$ at $k =0.2Mpc^{-1}$')\n",
    "plt.subplot(1,2,1)\n",
    "#plt.hline()\n",
    "c = list(np.arange(0,1,0.1))\n",
    "c.append(0.93)\n",
    "plt.yticks(c)\n",
    "plt.plot(history.history['accuracy'],lw=3,color = 'purple')\n",
    "plt.plot(history.history['val_accuracy'],'.',color='orange',)\n",
    "plt.hlines(y = 0.93,xmin=0,xmax=1600,linestyles='dashdot',lw =1)\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='lower right')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plt.plot(history.history['loss'],color = 'purple')\n",
    "plt.plot(history.history['val_loss'],color='orange')\n",
    "plt.hlines(y = 0,xmin=0,xmax=1600,linestyles='dashed',lw =1)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
