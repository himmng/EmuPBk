{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras as ks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adamax,Adam\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nod = 1058          #===========no. of data points============#\n",
    "k1 = np.array([0.1903934, 0.3220935, 1.559453 ])\n",
    "k2byk1 = np.arange(0.50,1.05,0.05) \t\t#======Ratio k2byk1========#\n",
    "\n",
    "cosalpha = np.arange(0.50,1.00,0.01)\t#======cosine of the angle between the k2 and k1 arms =======#\n",
    "\n",
    "k2byk1 = k2byk1.reshape(11,1)\n",
    "\n",
    "costheta = -cosalpha\n",
    "\n",
    "B_02 = np.loadtxt('bk_norm15')\n",
    "params_02 = np.loadtxt('params15')\n",
    "\n",
    "\n",
    "B_02 = B_02/10000000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.loadtxt('index')\n",
    "index = np.zeros(len(ind),dtype = int)\n",
    "for i in range(len(ind)):\n",
    "    index[i] = ind[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_test = B_02[index]\n",
    "B_train = np.delete(B_02,index,axis=0)\n",
    "\n",
    "p_test = params_02[index]\n",
    "p_train = np.delete(params_02,index,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040, 550)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_mode='uniform'\n",
    "class myCallback(ks.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>=0.98):\n",
    "            print(\"\\nReached 80% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "callbacks = myCallback()\n",
    "model = Sequential()\n",
    "model.add(Dense(80, input_shape=[3,], activation='elu',kernel_initializer=init_mode,))\n",
    "model.add(Dense(320,activation='elu',kernel_initializer=init_mode))\n",
    "model.add(Dense(460,activation='elu',kernel_initializer=init_mode))\n",
    "model.add(Dense(560,activation='elu',kernel_initializer=init_mode))\n",
    "model.add(Dense(260,activation='elu',kernel_initializer=init_mode))\n",
    "model.add(Dense(100,activation='elu',kernel_initializer=init_mode))\n",
    "model.add(Dense(320,activation='elu',kernel_initializer=init_mode))\n",
    "model.add(Dense(400,activation='elu',kernel_initializer=init_mode))\n",
    "\n",
    "    #model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(550, activation='linear'))\n",
    "    # Compile model\n",
    "optimizer = Adamax(lr=0.0001, beta_1=0.2, beta_2=0.088)\n",
    "model.compile(loss='mse', optimizer=Adam, metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(p_train,B_train,validation_split=0.038,batch_size=20,epochs=2000,callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(ks.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>=0.98):\n",
    "            print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "callbacks = myCallback()\n",
    "model = Sequential()\n",
    "model.add(Dense(80,input_shape=[3,],activation='elu'))\n",
    "model.add(Dense(320,activation='elu'))\n",
    "model.add(Dense(460,activation='relu'))\n",
    "model.add(Dense(560,activation='elu'))\n",
    "model.add(Dense(260,activation='elu'))\n",
    "model.add(Dense(100,activation='elu'))\n",
    "model.add(Dense(11*50))\n",
    "optimizer = Adam(lr = 0.0001,)   \n",
    "model.compile(loss='mse', optimizer= optimizer, metrics=['accuracy'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 40 samples\n",
      "Epoch 1/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 21.3722 - accuracy: 0.1610 - val_loss: 16.5825 - val_accuracy: 0.2000\n",
      "Epoch 2/5000\n",
      "1000/1000 [==============================] - 1s 808us/step - loss: 13.0191 - accuracy: 0.2540 - val_loss: 9.9555 - val_accuracy: 0.7000\n",
      "Epoch 3/5000\n",
      "1000/1000 [==============================] - 1s 817us/step - loss: 7.9917 - accuracy: 0.6900 - val_loss: 8.9998 - val_accuracy: 0.8000\n",
      "Epoch 4/5000\n",
      "1000/1000 [==============================] - 1s 819us/step - loss: 5.8261 - accuracy: 0.7360 - val_loss: 8.4930 - val_accuracy: 0.7500\n",
      "Epoch 5/5000\n",
      "1000/1000 [==============================] - 1s 820us/step - loss: 5.3182 - accuracy: 0.7230 - val_loss: 8.4282 - val_accuracy: 0.7500\n",
      "Epoch 6/5000\n",
      "1000/1000 [==============================] - 1s 812us/step - loss: 4.7857 - accuracy: 0.7250 - val_loss: 7.8835 - val_accuracy: 0.7500\n",
      "Epoch 7/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 4.3786 - accuracy: 0.7220 - val_loss: 8.5745 - val_accuracy: 0.7250\n",
      "Epoch 8/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 4.4409 - accuracy: 0.7250 - val_loss: 8.0567 - val_accuracy: 0.7250\n",
      "Epoch 9/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 4.0022 - accuracy: 0.7340 - val_loss: 7.9701 - val_accuracy: 0.7250\n",
      "Epoch 10/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 3.6327 - accuracy: 0.7400 - val_loss: 7.3644 - val_accuracy: 0.7250\n",
      "Epoch 11/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 3.6559 - accuracy: 0.7540 - val_loss: 7.1317 - val_accuracy: 0.7750\n",
      "Epoch 12/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 3.4118 - accuracy: 0.7810 - val_loss: 7.3314 - val_accuracy: 0.7500\n",
      "Epoch 13/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 3.2301 - accuracy: 0.7700 - val_loss: 7.0753 - val_accuracy: 0.7750\n",
      "Epoch 14/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 3.1040 - accuracy: 0.7920 - val_loss: 7.1361 - val_accuracy: 0.8250\n",
      "Epoch 15/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 3.0457 - accuracy: 0.7950 - val_loss: 6.4240 - val_accuracy: 0.8000\n",
      "Epoch 16/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 3.0276 - accuracy: 0.7950 - val_loss: 5.8679 - val_accuracy: 0.8250\n",
      "Epoch 17/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.6052 - accuracy: 0.8160 - val_loss: 6.8372 - val_accuracy: 0.7750\n",
      "Epoch 18/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 3.0791 - accuracy: 0.8050 - val_loss: 7.2458 - val_accuracy: 0.8000\n",
      "Epoch 19/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.4405 - accuracy: 0.8140 - val_loss: 5.0514 - val_accuracy: 0.8250\n",
      "Epoch 20/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.2668 - accuracy: 0.8190 - val_loss: 5.4226 - val_accuracy: 0.8500\n",
      "Epoch 21/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.0584 - accuracy: 0.8280 - val_loss: 3.9723 - val_accuracy: 0.8500\n",
      "Epoch 22/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.0901 - accuracy: 0.8220 - val_loss: 6.4643 - val_accuracy: 0.8250\n",
      "Epoch 23/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.3445 - accuracy: 0.8200 - val_loss: 4.2651 - val_accuracy: 0.8500\n",
      "Epoch 24/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.9282 - accuracy: 0.8130 - val_loss: 4.0180 - val_accuracy: 0.8250\n",
      "Epoch 25/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.6078 - accuracy: 0.8350 - val_loss: 3.3605 - val_accuracy: 0.8500\n",
      "Epoch 26/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.7909 - accuracy: 0.8240 - val_loss: 4.5834 - val_accuracy: 0.8250\n",
      "Epoch 27/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.5856 - accuracy: 0.8280 - val_loss: 3.2162 - val_accuracy: 0.8500\n",
      "Epoch 28/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.3408 - accuracy: 0.8340 - val_loss: 2.9147 - val_accuracy: 0.8500\n",
      "Epoch 29/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.7909 - accuracy: 0.8220 - val_loss: 2.8092 - val_accuracy: 0.8500\n",
      "Epoch 30/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.4624 - accuracy: 0.8390 - val_loss: 2.8518 - val_accuracy: 0.8500\n",
      "Epoch 31/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.4067 - accuracy: 0.8390 - val_loss: 2.6774 - val_accuracy: 0.8500\n",
      "Epoch 32/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.1687 - accuracy: 0.8370 - val_loss: 2.2118 - val_accuracy: 0.8500\n",
      "Epoch 33/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0354 - accuracy: 0.8380 - val_loss: 2.1413 - val_accuracy: 0.8500\n",
      "Epoch 34/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.9688 - accuracy: 0.8420 - val_loss: 1.9702 - val_accuracy: 0.8500\n",
      "Epoch 35/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0515 - accuracy: 0.8310 - val_loss: 1.9433 - val_accuracy: 0.8750\n",
      "Epoch 36/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0904 - accuracy: 0.8330 - val_loss: 1.9425 - val_accuracy: 0.8500\n",
      "Epoch 37/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8446 - accuracy: 0.8480 - val_loss: 2.2813 - val_accuracy: 0.8500\n",
      "Epoch 38/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.9491 - accuracy: 0.8400 - val_loss: 1.8427 - val_accuracy: 0.8500\n",
      "Epoch 39/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0034 - accuracy: 0.8450 - val_loss: 2.3597 - val_accuracy: 0.8500\n",
      "Epoch 40/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0348 - accuracy: 0.8510 - val_loss: 1.7313 - val_accuracy: 0.8500\n",
      "Epoch 41/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8513 - accuracy: 0.8530 - val_loss: 1.4645 - val_accuracy: 0.8500\n",
      "Epoch 42/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.9428 - accuracy: 0.8550 - val_loss: 1.7617 - val_accuracy: 0.8750\n",
      "Epoch 43/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8258 - accuracy: 0.8500 - val_loss: 1.5751 - val_accuracy: 0.8500\n",
      "Epoch 44/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.7584 - accuracy: 0.8580 - val_loss: 1.4361 - val_accuracy: 0.8500\n",
      "Epoch 45/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8435 - accuracy: 0.8580 - val_loss: 1.3559 - val_accuracy: 0.8500\n",
      "Epoch 46/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.7400 - accuracy: 0.8530 - val_loss: 1.5393 - val_accuracy: 0.8500\n",
      "Epoch 47/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6729 - accuracy: 0.8550 - val_loss: 1.2497 - val_accuracy: 0.8500\n",
      "Epoch 48/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6425 - accuracy: 0.8550 - val_loss: 1.3492 - val_accuracy: 0.8500\n",
      "Epoch 49/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6244 - accuracy: 0.8530 - val_loss: 1.1530 - val_accuracy: 0.8750\n",
      "Epoch 50/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5662 - accuracy: 0.8680 - val_loss: 1.0804 - val_accuracy: 0.8750\n",
      "Epoch 51/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6966 - accuracy: 0.8590 - val_loss: 1.1901 - val_accuracy: 0.8500\n",
      "Epoch 52/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6266 - accuracy: 0.8520 - val_loss: 1.3708 - val_accuracy: 0.8500\n",
      "Epoch 53/5000\n",
      " 690/1000 [===================>..........] - ETA: 0s - loss: 0.6082 - accuracy: 0.8710"
     ]
    }
   ],
   "source": [
    "history = model.fit(p_train,B_train,validation_split=0.038,batch_size=10,epochs=5000,callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('98bk02.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('EmuBk0.2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "plt.suptitle(r'Accuracy and Loss on the validation set for $B(k_1,k_2,k_3)$ at $k =0.2Mpc^{-1}$')\n",
    "plt.subplot(1,2,1)\n",
    "#plt.hline()\n",
    "c = list(np.arange(0,1,0.1))\n",
    "c.append(0.93)\n",
    "plt.yticks(c)\n",
    "plt.plot(history.history['accuracy'],lw=3,color = 'purple')\n",
    "plt.plot(history.history['val_accuracy'],'.',color='orange',)\n",
    "plt.hlines(y = 0.93,xmin=0,xmax=1600,linestyles='dashdot',lw =1)\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='lower right')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plt.plot(history.history['loss'],color = 'purple')\n",
    "plt.plot(history.history['val_loss'],color='orange')\n",
    "plt.hlines(y = 0,xmin=0,xmax=1600,linestyles='dashed',lw =1)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
