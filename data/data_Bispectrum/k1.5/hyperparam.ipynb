{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras as ks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adamax,Adam\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nod = 1058          #===========no. of data points============#\n",
    "k1 = np.array([0.1903934, 0.3220935, 1.559453 ])\n",
    "k2byk1 = np.arange(0.50,1.05,0.05) \t\t#======Ratio k2byk1========#\n",
    "\n",
    "cosalpha = np.arange(0.50,1.00,0.01)\t#======cosine of the angle between the k2 and k1 arms =======#\n",
    "\n",
    "k2byk1 = k2byk1.reshape(11,1)\n",
    "\n",
    "costheta = -cosalpha\n",
    "\n",
    "B_02 = np.loadtxt('bk_norm15')\n",
    "params_02 = np.loadtxt('params15')\n",
    "\n",
    "\n",
    "B_02 = B_02/10000000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.loadtxt('index')\n",
    "index = np.zeros(len(ind),dtype = int)\n",
    "for i in range(len(ind)):\n",
    "    index[i] = ind[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_test = B_02[index]\n",
    "B_train = np.delete(B_02,index,axis=0)\n",
    "\n",
    "p_test = params_02[index]\n",
    "p_train = np.delete(params_02,index,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040, 550)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_mode='uniform'\n",
    "class myCallback(ks.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>=0.98):\n",
    "            print(\"\\nReached 80% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "callbacks = myCallback()\n",
    "model = Sequential()\n",
    "model.add(Dense(80, input_shape=[3,], activation='elu',kernel_initializer=init_mode,))\n",
    "model.add(Dense(320,activation='elu',kernel_initializer=init_mode))\n",
    "model.add(Dense(460,activation='elu',kernel_initializer=init_mode))\n",
    "model.add(Dense(560,activation='elu',kernel_initializer=init_mode))\n",
    "model.add(Dense(260,activation='elu',kernel_initializer=init_mode))\n",
    "model.add(Dense(100,activation='elu',kernel_initializer=init_mode))\n",
    "model.add(Dense(320,activation='elu',kernel_initializer=init_mode))\n",
    "model.add(Dense(400,activation='elu',kernel_initializer=init_mode))\n",
    "\n",
    "    #model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(550, activation='linear'))\n",
    "    # Compile model\n",
    "optimizer = Adamax(lr=0.0001, beta_1=0.2, beta_2=0.088)\n",
    "model.compile(loss='mse', optimizer=Adam, metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(p_train,B_train,validation_split=0.038,batch_size=20,epochs=2000,callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(ks.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>=0.98):\n",
    "            print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "callbacks = myCallback()\n",
    "model = Sequential()\n",
    "model.add(Dense(80,input_shape=[3,],activation='elu'))\n",
    "model.add(Dense(320,activation='elu'))\n",
    "model.add(Dense(460,activation='relu'))\n",
    "model.add(Dense(560,activation='elu'))\n",
    "model.add(Dense(260,activation='elu'))\n",
    "model.add(Dense(100,activation='elu'))\n",
    "model.add(Dense(11*50))\n",
    "optimizer = Adam(lr = 0.0001,)   \n",
    "model.compile(loss='mse', optimizer= optimizer, metrics=['accuracy'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 40 samples\n",
      "Epoch 1/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 21.3722 - accuracy: 0.1610 - val_loss: 16.5825 - val_accuracy: 0.2000\n",
      "Epoch 2/5000\n",
      "1000/1000 [==============================] - 1s 808us/step - loss: 13.0191 - accuracy: 0.2540 - val_loss: 9.9555 - val_accuracy: 0.7000\n",
      "Epoch 3/5000\n",
      "1000/1000 [==============================] - 1s 817us/step - loss: 7.9917 - accuracy: 0.6900 - val_loss: 8.9998 - val_accuracy: 0.8000\n",
      "Epoch 4/5000\n",
      "1000/1000 [==============================] - 1s 819us/step - loss: 5.8261 - accuracy: 0.7360 - val_loss: 8.4930 - val_accuracy: 0.7500\n",
      "Epoch 5/5000\n",
      "1000/1000 [==============================] - 1s 820us/step - loss: 5.3182 - accuracy: 0.7230 - val_loss: 8.4282 - val_accuracy: 0.7500\n",
      "Epoch 6/5000\n",
      "1000/1000 [==============================] - 1s 812us/step - loss: 4.7857 - accuracy: 0.7250 - val_loss: 7.8835 - val_accuracy: 0.7500\n",
      "Epoch 7/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 4.3786 - accuracy: 0.7220 - val_loss: 8.5745 - val_accuracy: 0.7250\n",
      "Epoch 8/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 4.4409 - accuracy: 0.7250 - val_loss: 8.0567 - val_accuracy: 0.7250\n",
      "Epoch 9/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 4.0022 - accuracy: 0.7340 - val_loss: 7.9701 - val_accuracy: 0.7250\n",
      "Epoch 10/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 3.6327 - accuracy: 0.7400 - val_loss: 7.3644 - val_accuracy: 0.7250\n",
      "Epoch 11/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 3.6559 - accuracy: 0.7540 - val_loss: 7.1317 - val_accuracy: 0.7750\n",
      "Epoch 12/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 3.4118 - accuracy: 0.7810 - val_loss: 7.3314 - val_accuracy: 0.7500\n",
      "Epoch 13/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 3.2301 - accuracy: 0.7700 - val_loss: 7.0753 - val_accuracy: 0.7750\n",
      "Epoch 14/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 3.1040 - accuracy: 0.7920 - val_loss: 7.1361 - val_accuracy: 0.8250\n",
      "Epoch 15/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 3.0457 - accuracy: 0.7950 - val_loss: 6.4240 - val_accuracy: 0.8000\n",
      "Epoch 16/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 3.0276 - accuracy: 0.7950 - val_loss: 5.8679 - val_accuracy: 0.8250\n",
      "Epoch 17/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.6052 - accuracy: 0.8160 - val_loss: 6.8372 - val_accuracy: 0.7750\n",
      "Epoch 18/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 3.0791 - accuracy: 0.8050 - val_loss: 7.2458 - val_accuracy: 0.8000\n",
      "Epoch 19/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.4405 - accuracy: 0.8140 - val_loss: 5.0514 - val_accuracy: 0.8250\n",
      "Epoch 20/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.2668 - accuracy: 0.8190 - val_loss: 5.4226 - val_accuracy: 0.8500\n",
      "Epoch 21/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.0584 - accuracy: 0.8280 - val_loss: 3.9723 - val_accuracy: 0.8500\n",
      "Epoch 22/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.0901 - accuracy: 0.8220 - val_loss: 6.4643 - val_accuracy: 0.8250\n",
      "Epoch 23/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.3445 - accuracy: 0.8200 - val_loss: 4.2651 - val_accuracy: 0.8500\n",
      "Epoch 24/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.9282 - accuracy: 0.8130 - val_loss: 4.0180 - val_accuracy: 0.8250\n",
      "Epoch 25/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.6078 - accuracy: 0.8350 - val_loss: 3.3605 - val_accuracy: 0.8500\n",
      "Epoch 26/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.7909 - accuracy: 0.8240 - val_loss: 4.5834 - val_accuracy: 0.8250\n",
      "Epoch 27/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.5856 - accuracy: 0.8280 - val_loss: 3.2162 - val_accuracy: 0.8500\n",
      "Epoch 28/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.3408 - accuracy: 0.8340 - val_loss: 2.9147 - val_accuracy: 0.8500\n",
      "Epoch 29/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.7909 - accuracy: 0.8220 - val_loss: 2.8092 - val_accuracy: 0.8500\n",
      "Epoch 30/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.4624 - accuracy: 0.8390 - val_loss: 2.8518 - val_accuracy: 0.8500\n",
      "Epoch 31/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.4067 - accuracy: 0.8390 - val_loss: 2.6774 - val_accuracy: 0.8500\n",
      "Epoch 32/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.1687 - accuracy: 0.8370 - val_loss: 2.2118 - val_accuracy: 0.8500\n",
      "Epoch 33/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0354 - accuracy: 0.8380 - val_loss: 2.1413 - val_accuracy: 0.8500\n",
      "Epoch 34/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.9688 - accuracy: 0.8420 - val_loss: 1.9702 - val_accuracy: 0.8500\n",
      "Epoch 35/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0515 - accuracy: 0.8310 - val_loss: 1.9433 - val_accuracy: 0.8750\n",
      "Epoch 36/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0904 - accuracy: 0.8330 - val_loss: 1.9425 - val_accuracy: 0.8500\n",
      "Epoch 37/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8446 - accuracy: 0.8480 - val_loss: 2.2813 - val_accuracy: 0.8500\n",
      "Epoch 38/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.9491 - accuracy: 0.8400 - val_loss: 1.8427 - val_accuracy: 0.8500\n",
      "Epoch 39/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0034 - accuracy: 0.8450 - val_loss: 2.3597 - val_accuracy: 0.8500\n",
      "Epoch 40/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0348 - accuracy: 0.8510 - val_loss: 1.7313 - val_accuracy: 0.8500\n",
      "Epoch 41/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8513 - accuracy: 0.8530 - val_loss: 1.4645 - val_accuracy: 0.8500\n",
      "Epoch 42/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.9428 - accuracy: 0.8550 - val_loss: 1.7617 - val_accuracy: 0.8750\n",
      "Epoch 43/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8258 - accuracy: 0.8500 - val_loss: 1.5751 - val_accuracy: 0.8500\n",
      "Epoch 44/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.7584 - accuracy: 0.8580 - val_loss: 1.4361 - val_accuracy: 0.8500\n",
      "Epoch 45/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8435 - accuracy: 0.8580 - val_loss: 1.3559 - val_accuracy: 0.8500\n",
      "Epoch 46/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.7400 - accuracy: 0.8530 - val_loss: 1.5393 - val_accuracy: 0.8500\n",
      "Epoch 47/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6729 - accuracy: 0.8550 - val_loss: 1.2497 - val_accuracy: 0.8500\n",
      "Epoch 48/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6425 - accuracy: 0.8550 - val_loss: 1.3492 - val_accuracy: 0.8500\n",
      "Epoch 49/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6244 - accuracy: 0.8530 - val_loss: 1.1530 - val_accuracy: 0.8750\n",
      "Epoch 50/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5662 - accuracy: 0.8680 - val_loss: 1.0804 - val_accuracy: 0.8750\n",
      "Epoch 51/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6966 - accuracy: 0.8590 - val_loss: 1.1901 - val_accuracy: 0.8500\n",
      "Epoch 52/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6266 - accuracy: 0.8520 - val_loss: 1.3708 - val_accuracy: 0.8500\n",
      "Epoch 53/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6125 - accuracy: 0.8620 - val_loss: 1.2999 - val_accuracy: 0.8500\n",
      "Epoch 54/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6804 - accuracy: 0.8580 - val_loss: 1.3067 - val_accuracy: 0.8500\n",
      "Epoch 55/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5591 - accuracy: 0.8590 - val_loss: 1.1124 - val_accuracy: 0.8500\n",
      "Epoch 56/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6296 - accuracy: 0.8620 - val_loss: 2.0654 - val_accuracy: 0.8250\n",
      "Epoch 57/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.7459 - accuracy: 0.8320 - val_loss: 1.2133 - val_accuracy: 0.8500\n",
      "Epoch 58/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6060 - accuracy: 0.8620 - val_loss: 1.1836 - val_accuracy: 0.8750\n",
      "Epoch 59/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.7359 - accuracy: 0.8690 - val_loss: 1.4228 - val_accuracy: 0.8500\n",
      "Epoch 60/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5873 - accuracy: 0.8620 - val_loss: 1.5461 - val_accuracy: 0.8750\n",
      "Epoch 61/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5654 - accuracy: 0.8650 - val_loss: 0.9483 - val_accuracy: 0.8750\n",
      "Epoch 62/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4339 - accuracy: 0.8730 - val_loss: 1.0122 - val_accuracy: 0.8500\n",
      "Epoch 63/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5528 - accuracy: 0.8660 - val_loss: 1.0172 - val_accuracy: 0.8500\n",
      "Epoch 64/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4623 - accuracy: 0.8590 - val_loss: 1.0265 - val_accuracy: 0.8250\n",
      "Epoch 65/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4770 - accuracy: 0.8670 - val_loss: 0.9071 - val_accuracy: 0.8500\n",
      "Epoch 66/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4757 - accuracy: 0.8650 - val_loss: 0.9656 - val_accuracy: 0.8500\n",
      "Epoch 67/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4086 - accuracy: 0.8640 - val_loss: 0.8850 - val_accuracy: 0.8500\n",
      "Epoch 68/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6247 - accuracy: 0.8700 - val_loss: 0.9021 - val_accuracy: 0.8250\n",
      "Epoch 69/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3982 - accuracy: 0.8680 - val_loss: 0.9122 - val_accuracy: 0.8750\n",
      "Epoch 70/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3849 - accuracy: 0.8720 - val_loss: 0.8888 - val_accuracy: 0.8750\n",
      "Epoch 71/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3565 - accuracy: 0.8800 - val_loss: 0.7996 - val_accuracy: 0.8750\n",
      "Epoch 72/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4685 - accuracy: 0.8610 - val_loss: 0.9316 - val_accuracy: 0.9000\n",
      "Epoch 73/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4376 - accuracy: 0.8740 - val_loss: 0.8197 - val_accuracy: 0.8500\n",
      "Epoch 74/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.2601 - accuracy: 0.8580 - val_loss: 2.0497 - val_accuracy: 0.8750\n",
      "Epoch 75/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.6448 - accuracy: 0.8300 - val_loss: 0.9646 - val_accuracy: 0.8750\n",
      "Epoch 76/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4306 - accuracy: 0.8660 - val_loss: 0.8811 - val_accuracy: 0.8750\n",
      "Epoch 77/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6012 - accuracy: 0.8690 - val_loss: 0.7961 - val_accuracy: 0.8750\n",
      "Epoch 78/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3587 - accuracy: 0.8750 - val_loss: 0.8993 - val_accuracy: 0.8500\n",
      "Epoch 79/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4555 - accuracy: 0.8680 - val_loss: 0.9427 - val_accuracy: 0.9000\n",
      "Epoch 80/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3569 - accuracy: 0.8700 - val_loss: 0.8782 - val_accuracy: 0.9000\n",
      "Epoch 81/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3560 - accuracy: 0.8790 - val_loss: 0.7353 - val_accuracy: 0.8750\n",
      "Epoch 82/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3332 - accuracy: 0.8760 - val_loss: 0.7551 - val_accuracy: 0.8750\n",
      "Epoch 83/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3274 - accuracy: 0.8620 - val_loss: 0.7306 - val_accuracy: 0.8750\n",
      "Epoch 84/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5205 - accuracy: 0.8780 - val_loss: 0.8017 - val_accuracy: 0.8750\n",
      "Epoch 85/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3137 - accuracy: 0.8720 - val_loss: 0.7803 - val_accuracy: 0.9000\n",
      "Epoch 86/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3104 - accuracy: 0.8800 - val_loss: 0.7867 - val_accuracy: 0.8750\n",
      "Epoch 87/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2875 - accuracy: 0.8740 - val_loss: 0.6784 - val_accuracy: 0.8750\n",
      "Epoch 88/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2828 - accuracy: 0.8790 - val_loss: 0.6542 - val_accuracy: 0.9000\n",
      "Epoch 89/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3443 - accuracy: 0.8670 - val_loss: 1.0984 - val_accuracy: 0.9000\n",
      "Epoch 90/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6602 - accuracy: 0.8630 - val_loss: 0.7938 - val_accuracy: 0.8750\n",
      "Epoch 91/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4609 - accuracy: 0.8710 - val_loss: 0.7755 - val_accuracy: 0.9250\n",
      "Epoch 92/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2978 - accuracy: 0.8730 - val_loss: 0.7079 - val_accuracy: 0.8750\n",
      "Epoch 93/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2958 - accuracy: 0.8810 - val_loss: 0.6392 - val_accuracy: 0.8750\n",
      "Epoch 94/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2790 - accuracy: 0.8860 - val_loss: 0.6423 - val_accuracy: 0.9000\n",
      "Epoch 95/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3249 - accuracy: 0.8840 - val_loss: 0.8905 - val_accuracy: 0.9000\n",
      "Epoch 96/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.4524 - accuracy: 0.8660 - val_loss: 3.4268 - val_accuracy: 0.8250\n",
      "Epoch 97/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8753 - accuracy: 0.8700 - val_loss: 0.8668 - val_accuracy: 0.8250\n",
      "Epoch 98/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5288 - accuracy: 0.8840 - val_loss: 0.7769 - val_accuracy: 0.8750\n",
      "Epoch 99/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3874 - accuracy: 0.8840 - val_loss: 0.6282 - val_accuracy: 0.9000\n",
      "Epoch 100/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2852 - accuracy: 0.8800 - val_loss: 0.7126 - val_accuracy: 0.9000\n",
      "Epoch 101/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2783 - accuracy: 0.8820 - val_loss: 0.6832 - val_accuracy: 0.9250\n",
      "Epoch 102/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4582 - accuracy: 0.8790 - val_loss: 1.0451 - val_accuracy: 0.8500\n",
      "Epoch 103/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3430 - accuracy: 0.8790 - val_loss: 0.5971 - val_accuracy: 0.9000\n",
      "Epoch 104/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2451 - accuracy: 0.8810 - val_loss: 0.6317 - val_accuracy: 0.8750\n",
      "Epoch 105/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2662 - accuracy: 0.8810 - val_loss: 0.5724 - val_accuracy: 0.9000\n",
      "Epoch 106/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2483 - accuracy: 0.8820 - val_loss: 0.6403 - val_accuracy: 0.8750\n",
      "Epoch 107/5000\n",
      "1000/1000 [==============================] - 1s 987us/step - loss: 0.2592 - accuracy: 0.8870 - val_loss: 0.6547 - val_accuracy: 0.9000\n",
      "Epoch 108/5000\n",
      "1000/1000 [==============================] - 1s 943us/step - loss: 0.2573 - accuracy: 0.8780 - val_loss: 0.9141 - val_accuracy: 0.8500\n",
      "Epoch 109/5000\n",
      "1000/1000 [==============================] - 1s 893us/step - loss: 0.5520 - accuracy: 0.8710 - val_loss: 0.7196 - val_accuracy: 0.9000\n",
      "Epoch 110/5000\n",
      "1000/1000 [==============================] - 1s 868us/step - loss: 0.3621 - accuracy: 0.8640 - val_loss: 0.6475 - val_accuracy: 0.8750\n",
      "Epoch 111/5000\n",
      "1000/1000 [==============================] - 1s 905us/step - loss: 0.2230 - accuracy: 0.8830 - val_loss: 0.6108 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/5000\n",
      "1000/1000 [==============================] - 1s 826us/step - loss: 0.2369 - accuracy: 0.8880 - val_loss: 0.4941 - val_accuracy: 0.9000\n",
      "Epoch 113/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3920 - accuracy: 0.8900 - val_loss: 0.6537 - val_accuracy: 0.8750\n",
      "Epoch 114/5000\n",
      "1000/1000 [==============================] - 1s 963us/step - loss: 0.4576 - accuracy: 0.8750 - val_loss: 0.8484 - val_accuracy: 0.9250\n",
      "Epoch 115/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2391 - accuracy: 0.8900 - val_loss: 0.5633 - val_accuracy: 0.8750\n",
      "Epoch 116/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2362 - accuracy: 0.8860 - val_loss: 0.5177 - val_accuracy: 0.9000\n",
      "Epoch 117/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2802 - accuracy: 0.8830 - val_loss: 0.6125 - val_accuracy: 0.9000\n",
      "Epoch 118/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2640 - accuracy: 0.8890 - val_loss: 0.5460 - val_accuracy: 0.9000\n",
      "Epoch 119/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2860 - accuracy: 0.8900 - val_loss: 0.5233 - val_accuracy: 0.8500\n",
      "Epoch 120/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2352 - accuracy: 0.8920 - val_loss: 0.6083 - val_accuracy: 0.8500\n",
      "Epoch 121/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8936 - accuracy: 0.8870 - val_loss: 0.8761 - val_accuracy: 0.8500\n",
      "Epoch 122/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8902 - accuracy: 0.8730 - val_loss: 0.8076 - val_accuracy: 0.8250\n",
      "Epoch 123/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6103 - accuracy: 0.8770 - val_loss: 0.6447 - val_accuracy: 0.9250\n",
      "Epoch 124/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2880 - accuracy: 0.8810 - val_loss: 0.5929 - val_accuracy: 0.9000\n",
      "Epoch 125/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2100 - accuracy: 0.8940 - val_loss: 0.5441 - val_accuracy: 0.9000\n",
      "Epoch 126/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2060 - accuracy: 0.8970 - val_loss: 0.5646 - val_accuracy: 0.9000\n",
      "Epoch 127/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2358 - accuracy: 0.9050 - val_loss: 0.5797 - val_accuracy: 0.8750\n",
      "Epoch 128/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1950 - accuracy: 0.8970 - val_loss: 0.6673 - val_accuracy: 0.8750\n",
      "Epoch 129/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2686 - accuracy: 0.8940 - val_loss: 0.4624 - val_accuracy: 0.9000\n",
      "Epoch 130/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2739 - accuracy: 0.9030 - val_loss: 0.6660 - val_accuracy: 0.8750\n",
      "Epoch 131/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3495 - accuracy: 0.8920 - val_loss: 0.5985 - val_accuracy: 0.9000\n",
      "Epoch 132/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2771 - accuracy: 0.9010 - val_loss: 0.4638 - val_accuracy: 0.8750\n",
      "Epoch 133/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1846 - accuracy: 0.9150 - val_loss: 0.5103 - val_accuracy: 0.8750\n",
      "Epoch 134/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2952 - accuracy: 0.9050 - val_loss: 0.5975 - val_accuracy: 0.8500\n",
      "Epoch 135/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3065 - accuracy: 0.8920 - val_loss: 0.4655 - val_accuracy: 0.8500\n",
      "Epoch 136/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2272 - accuracy: 0.9070 - val_loss: 0.4507 - val_accuracy: 0.9000\n",
      "Epoch 137/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3751 - accuracy: 0.8860 - val_loss: 0.7057 - val_accuracy: 0.8000\n",
      "Epoch 138/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6310 - accuracy: 0.8930 - val_loss: 0.6144 - val_accuracy: 0.8250\n",
      "Epoch 139/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2118 - accuracy: 0.9080 - val_loss: 0.7391 - val_accuracy: 0.9000\n",
      "Epoch 140/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2391 - accuracy: 0.8990 - val_loss: 0.5443 - val_accuracy: 0.8750\n",
      "Epoch 141/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1928 - accuracy: 0.9100 - val_loss: 0.4929 - val_accuracy: 0.9250\n",
      "Epoch 142/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2618 - accuracy: 0.9090 - val_loss: 0.5343 - val_accuracy: 0.9250\n",
      "Epoch 143/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2082 - accuracy: 0.9100 - val_loss: 0.4175 - val_accuracy: 0.8750\n",
      "Epoch 144/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2705 - accuracy: 0.8970 - val_loss: 0.5043 - val_accuracy: 0.9000\n",
      "Epoch 145/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2250 - accuracy: 0.9090 - val_loss: 0.5108 - val_accuracy: 0.9000\n",
      "Epoch 146/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2268 - accuracy: 0.9160 - val_loss: 0.5217 - val_accuracy: 0.9250\n",
      "Epoch 147/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1617 - accuracy: 0.9100 - val_loss: 0.4709 - val_accuracy: 0.9000\n",
      "Epoch 148/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1885 - accuracy: 0.9100 - val_loss: 0.4692 - val_accuracy: 0.9000\n",
      "Epoch 149/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1789 - accuracy: 0.9170 - val_loss: 0.4353 - val_accuracy: 0.8750\n",
      "Epoch 150/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1756 - accuracy: 0.9180 - val_loss: 0.4116 - val_accuracy: 0.9000\n",
      "Epoch 151/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2152 - accuracy: 0.9100 - val_loss: 0.5878 - val_accuracy: 0.8750\n",
      "Epoch 152/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1728 - accuracy: 0.9100 - val_loss: 0.4224 - val_accuracy: 0.9000\n",
      "Epoch 153/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4646 - accuracy: 0.9120 - val_loss: 1.0624 - val_accuracy: 0.8750\n",
      "Epoch 154/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4821 - accuracy: 0.8870 - val_loss: 0.6913 - val_accuracy: 0.8250\n",
      "Epoch 155/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3488 - accuracy: 0.9070 - val_loss: 0.5124 - val_accuracy: 0.9250\n",
      "Epoch 156/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3265 - accuracy: 0.8990 - val_loss: 0.4131 - val_accuracy: 0.8750\n",
      "Epoch 157/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1772 - accuracy: 0.9200 - val_loss: 0.4061 - val_accuracy: 0.9250\n",
      "Epoch 158/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1568 - accuracy: 0.9160 - val_loss: 0.4015 - val_accuracy: 0.9250\n",
      "Epoch 159/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1622 - accuracy: 0.9190 - val_loss: 0.4059 - val_accuracy: 0.8750\n",
      "Epoch 160/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1842 - accuracy: 0.9190 - val_loss: 0.4563 - val_accuracy: 0.9250\n",
      "Epoch 161/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3217 - accuracy: 0.9040 - val_loss: 0.5213 - val_accuracy: 0.8500\n",
      "Epoch 162/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2291 - accuracy: 0.9180 - val_loss: 0.5496 - val_accuracy: 0.9000\n",
      "Epoch 163/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2381 - accuracy: 0.9160 - val_loss: 0.5023 - val_accuracy: 0.8750\n",
      "Epoch 164/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2277 - accuracy: 0.9070 - val_loss: 0.4306 - val_accuracy: 0.9000\n",
      "Epoch 165/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1721 - accuracy: 0.9120 - val_loss: 0.3954 - val_accuracy: 0.8750\n",
      "Epoch 166/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2009 - accuracy: 0.9130 - val_loss: 0.4457 - val_accuracy: 0.9000\n",
      "Epoch 167/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1872 - accuracy: 0.9140 - val_loss: 0.3786 - val_accuracy: 0.9000\n",
      "Epoch 168/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2272 - accuracy: 0.9160 - val_loss: 0.4375 - val_accuracy: 0.8750\n",
      "Epoch 169/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4376 - accuracy: 0.9150 - val_loss: 2.6833 - val_accuracy: 0.8500\n",
      "Epoch 170/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5091 - accuracy: 0.9020 - val_loss: 0.4998 - val_accuracy: 0.8500\n",
      "Epoch 171/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2101 - accuracy: 0.9190 - val_loss: 0.4657 - val_accuracy: 0.8750\n",
      "Epoch 172/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1553 - accuracy: 0.9220 - val_loss: 0.3727 - val_accuracy: 0.8500\n",
      "Epoch 173/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1786 - accuracy: 0.9220 - val_loss: 0.3557 - val_accuracy: 0.9000\n",
      "Epoch 174/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4879 - accuracy: 0.9050 - val_loss: 0.6970 - val_accuracy: 0.8750\n",
      "Epoch 175/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5881 - accuracy: 0.8950 - val_loss: 0.6263 - val_accuracy: 0.9000\n",
      "Epoch 176/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2148 - accuracy: 0.9240 - val_loss: 0.4972 - val_accuracy: 0.9000\n",
      "Epoch 177/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1589 - accuracy: 0.9250 - val_loss: 0.4358 - val_accuracy: 0.9000\n",
      "Epoch 178/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2240 - accuracy: 0.9200 - val_loss: 0.3657 - val_accuracy: 0.9000\n",
      "Epoch 179/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1547 - accuracy: 0.9210 - val_loss: 0.4302 - val_accuracy: 0.9000\n",
      "Epoch 180/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1534 - accuracy: 0.9220 - val_loss: 0.6778 - val_accuracy: 0.9000\n",
      "Epoch 181/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2978 - accuracy: 0.9230 - val_loss: 0.4278 - val_accuracy: 0.9000\n",
      "Epoch 182/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1592 - accuracy: 0.9250 - val_loss: 0.4385 - val_accuracy: 0.9000\n",
      "Epoch 183/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1907 - accuracy: 0.9180 - val_loss: 0.3310 - val_accuracy: 0.9000\n",
      "Epoch 184/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1545 - accuracy: 0.9220 - val_loss: 0.3549 - val_accuracy: 0.9250\n",
      "Epoch 185/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1895 - accuracy: 0.9260 - val_loss: 0.5692 - val_accuracy: 0.8750\n",
      "Epoch 186/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2232 - accuracy: 0.9090 - val_loss: 0.3908 - val_accuracy: 0.8750\n",
      "Epoch 187/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1544 - accuracy: 0.9180 - val_loss: 0.4264 - val_accuracy: 0.9000\n",
      "Epoch 188/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2898 - accuracy: 0.9210 - val_loss: 0.3813 - val_accuracy: 0.9000\n",
      "Epoch 189/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2319 - accuracy: 0.9170 - val_loss: 0.5301 - val_accuracy: 0.9000\n",
      "Epoch 190/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1540 - accuracy: 0.9280 - val_loss: 0.4063 - val_accuracy: 0.9000\n",
      "Epoch 191/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1602 - accuracy: 0.9230 - val_loss: 0.3279 - val_accuracy: 0.8750\n",
      "Epoch 192/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1429 - accuracy: 0.9300 - val_loss: 0.4959 - val_accuracy: 0.9000\n",
      "Epoch 193/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1916 - accuracy: 0.9150 - val_loss: 0.4086 - val_accuracy: 0.8750\n",
      "Epoch 194/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2561 - accuracy: 0.9180 - val_loss: 0.5208 - val_accuracy: 0.9000\n",
      "Epoch 195/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4122 - accuracy: 0.9080 - val_loss: 0.4339 - val_accuracy: 0.9000\n",
      "Epoch 196/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2414 - accuracy: 0.9220 - val_loss: 0.5256 - val_accuracy: 0.9000\n",
      "Epoch 197/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4021 - accuracy: 0.9220 - val_loss: 0.5224 - val_accuracy: 0.8500\n",
      "Epoch 198/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1862 - accuracy: 0.9170 - val_loss: 0.3269 - val_accuracy: 0.8750\n",
      "Epoch 199/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1540 - accuracy: 0.9290 - val_loss: 0.5543 - val_accuracy: 0.8750\n",
      "Epoch 200/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2726 - accuracy: 0.9190 - val_loss: 0.4273 - val_accuracy: 0.9000\n",
      "Epoch 201/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2288 - accuracy: 0.9260 - val_loss: 0.3213 - val_accuracy: 0.8750\n",
      "Epoch 202/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1863 - accuracy: 0.9230 - val_loss: 0.5035 - val_accuracy: 0.9000\n",
      "Epoch 203/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2315 - accuracy: 0.9200 - val_loss: 0.3100 - val_accuracy: 0.8750\n",
      "Epoch 204/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1334 - accuracy: 0.9380 - val_loss: 0.4107 - val_accuracy: 0.9250\n",
      "Epoch 205/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1266 - accuracy: 0.9310 - val_loss: 0.2901 - val_accuracy: 0.9250\n",
      "Epoch 206/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1128 - accuracy: 0.9330 - val_loss: 0.3196 - val_accuracy: 0.8750\n",
      "Epoch 207/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1651 - accuracy: 0.9340 - val_loss: 0.3635 - val_accuracy: 0.8750\n",
      "Epoch 208/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4108 - accuracy: 0.9210 - val_loss: 0.4552 - val_accuracy: 0.8250\n",
      "Epoch 209/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2555 - accuracy: 0.9060 - val_loss: 0.5416 - val_accuracy: 0.8500\n",
      "Epoch 210/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1453 - accuracy: 0.9350 - val_loss: 0.3360 - val_accuracy: 0.9000\n",
      "Epoch 211/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2000 - accuracy: 0.9250 - val_loss: 0.5204 - val_accuracy: 0.9000\n",
      "Epoch 212/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1969 - accuracy: 0.9190 - val_loss: 0.7770 - val_accuracy: 0.8750\n",
      "Epoch 213/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4571 - accuracy: 0.9070 - val_loss: 0.3654 - val_accuracy: 0.8750\n",
      "Epoch 214/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2094 - accuracy: 0.9100 - val_loss: 0.3802 - val_accuracy: 0.9000\n",
      "Epoch 215/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1982 - accuracy: 0.9310 - val_loss: 0.3358 - val_accuracy: 0.9000\n",
      "Epoch 216/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2139 - accuracy: 0.9170 - val_loss: 0.4434 - val_accuracy: 0.8750\n",
      "Epoch 217/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1542 - accuracy: 0.9310 - val_loss: 0.3311 - val_accuracy: 0.8750\n",
      "Epoch 218/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1376 - accuracy: 0.9270 - val_loss: 0.8839 - val_accuracy: 0.9250\n",
      "Epoch 219/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6945 - accuracy: 0.9140 - val_loss: 1.2140 - val_accuracy: 0.8750\n",
      "Epoch 220/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2295 - accuracy: 0.9270 - val_loss: 0.3193 - val_accuracy: 0.9250\n",
      "Epoch 221/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1692 - accuracy: 0.9380 - val_loss: 0.3124 - val_accuracy: 0.9000\n",
      "Epoch 222/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1301 - accuracy: 0.9320 - val_loss: 0.3507 - val_accuracy: 0.9250\n",
      "Epoch 223/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1092 - accuracy: 0.9410 - val_loss: 0.3268 - val_accuracy: 0.9000\n",
      "Epoch 224/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1218 - accuracy: 0.9350 - val_loss: 0.3341 - val_accuracy: 0.9000\n",
      "Epoch 225/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1414 - accuracy: 0.9330 - val_loss: 0.3341 - val_accuracy: 0.8750\n",
      "Epoch 226/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1182 - accuracy: 0.9380 - val_loss: 0.2839 - val_accuracy: 0.9000\n",
      "Epoch 227/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2446 - accuracy: 0.9260 - val_loss: 0.3864 - val_accuracy: 0.9250\n",
      "Epoch 228/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3577 - accuracy: 0.9020 - val_loss: 0.6653 - val_accuracy: 0.9000\n",
      "Epoch 229/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0899 - accuracy: 0.9040 - val_loss: 0.3892 - val_accuracy: 0.9000\n",
      "Epoch 230/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2816 - accuracy: 0.9280 - val_loss: 0.6750 - val_accuracy: 0.8750\n",
      "Epoch 231/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1932 - accuracy: 0.9300 - val_loss: 0.3100 - val_accuracy: 0.8750\n",
      "Epoch 232/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1488 - accuracy: 0.9320 - val_loss: 0.3359 - val_accuracy: 0.9000\n",
      "Epoch 233/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1065 - accuracy: 0.9410 - val_loss: 0.2967 - val_accuracy: 0.9000\n",
      "Epoch 234/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1076 - accuracy: 0.9410 - val_loss: 0.2648 - val_accuracy: 0.9000\n",
      "Epoch 235/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1134 - accuracy: 0.9440 - val_loss: 0.3012 - val_accuracy: 0.9000\n",
      "Epoch 236/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1120 - accuracy: 0.9330 - val_loss: 0.3129 - val_accuracy: 0.9000\n",
      "Epoch 237/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1572 - accuracy: 0.9390 - val_loss: 0.3789 - val_accuracy: 0.8750\n",
      "Epoch 238/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3209 - accuracy: 0.9240 - val_loss: 0.3321 - val_accuracy: 0.8750\n",
      "Epoch 239/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1721 - accuracy: 0.9300 - val_loss: 0.3163 - val_accuracy: 0.8750\n",
      "Epoch 240/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1451 - accuracy: 0.9350 - val_loss: 0.8234 - val_accuracy: 0.9000\n",
      "Epoch 241/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2569 - accuracy: 0.9320 - val_loss: 0.3594 - val_accuracy: 0.8750\n",
      "Epoch 242/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1549 - accuracy: 0.9270 - val_loss: 0.3530 - val_accuracy: 0.9000\n",
      "Epoch 243/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1374 - accuracy: 0.9440 - val_loss: 0.3378 - val_accuracy: 0.9250\n",
      "Epoch 244/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1297 - accuracy: 0.9300 - val_loss: 0.2998 - val_accuracy: 0.9000\n",
      "Epoch 245/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1383 - accuracy: 0.9260 - val_loss: 0.3445 - val_accuracy: 0.8750\n",
      "Epoch 246/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1436 - accuracy: 0.9350 - val_loss: 0.2953 - val_accuracy: 0.9000\n",
      "Epoch 247/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1972 - accuracy: 0.9280 - val_loss: 0.2404 - val_accuracy: 0.9000\n",
      "Epoch 248/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1346 - accuracy: 0.9270 - val_loss: 0.3800 - val_accuracy: 0.9000\n",
      "Epoch 249/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3562 - accuracy: 0.9240 - val_loss: 0.8886 - val_accuracy: 0.9000\n",
      "Epoch 250/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2902 - accuracy: 0.9230 - val_loss: 0.3717 - val_accuracy: 0.9250\n",
      "Epoch 251/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1435 - accuracy: 0.9300 - val_loss: 0.3618 - val_accuracy: 0.9250\n",
      "Epoch 252/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1632 - accuracy: 0.9300 - val_loss: 0.4580 - val_accuracy: 0.8750\n",
      "Epoch 253/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1840 - accuracy: 0.9360 - val_loss: 0.4791 - val_accuracy: 0.9250\n",
      "Epoch 254/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1462 - accuracy: 0.9340 - val_loss: 0.2621 - val_accuracy: 0.9000\n",
      "Epoch 255/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1171 - accuracy: 0.9300 - val_loss: 0.3998 - val_accuracy: 0.9000\n",
      "Epoch 256/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3611 - accuracy: 0.9210 - val_loss: 0.3641 - val_accuracy: 0.8750\n",
      "Epoch 257/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1597 - accuracy: 0.9190 - val_loss: 0.3404 - val_accuracy: 0.8750\n",
      "Epoch 258/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1755 - accuracy: 0.9250 - val_loss: 0.3571 - val_accuracy: 0.9000\n",
      "Epoch 259/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1356 - accuracy: 0.9380 - val_loss: 0.2763 - val_accuracy: 0.9250\n",
      "Epoch 260/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1846 - accuracy: 0.9300 - val_loss: 0.3493 - val_accuracy: 0.9000\n",
      "Epoch 261/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1484 - accuracy: 0.9440 - val_loss: 0.3637 - val_accuracy: 0.8750\n",
      "Epoch 262/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2939 - accuracy: 0.9170 - val_loss: 0.2589 - val_accuracy: 0.9000\n",
      "Epoch 263/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1232 - accuracy: 0.9370 - val_loss: 0.3645 - val_accuracy: 0.8750\n",
      "Epoch 264/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1319 - accuracy: 0.9300 - val_loss: 0.3450 - val_accuracy: 0.9250\n",
      "Epoch 265/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1497 - accuracy: 0.9350 - val_loss: 0.3502 - val_accuracy: 0.8750\n",
      "Epoch 266/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1529 - accuracy: 0.9330 - val_loss: 0.3963 - val_accuracy: 0.8750\n",
      "Epoch 267/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1278 - accuracy: 0.9290 - val_loss: 0.6435 - val_accuracy: 0.9000\n",
      "Epoch 268/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1623 - accuracy: 0.9250 - val_loss: 0.3606 - val_accuracy: 0.8750\n",
      "Epoch 269/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1504 - accuracy: 0.9190 - val_loss: 0.2910 - val_accuracy: 0.9250\n",
      "Epoch 270/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1519 - accuracy: 0.9320 - val_loss: 0.3587 - val_accuracy: 0.9000\n",
      "Epoch 271/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1474 - accuracy: 0.9390 - val_loss: 0.3136 - val_accuracy: 0.9250\n",
      "Epoch 272/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1432 - accuracy: 0.9270 - val_loss: 0.3097 - val_accuracy: 0.9000\n",
      "Epoch 273/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1872 - accuracy: 0.9280 - val_loss: 0.2778 - val_accuracy: 0.9000\n",
      "Epoch 274/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1711 - accuracy: 0.9150 - val_loss: 0.2761 - val_accuracy: 0.9250\n",
      "Epoch 275/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2043 - accuracy: 0.9270 - val_loss: 0.3875 - val_accuracy: 0.8750\n",
      "Epoch 276/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1327 - accuracy: 0.9340 - val_loss: 0.3305 - val_accuracy: 0.9500\n",
      "Epoch 277/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1401 - accuracy: 0.9260 - val_loss: 0.2470 - val_accuracy: 0.8750\n",
      "Epoch 278/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1344 - accuracy: 0.9300 - val_loss: 0.2625 - val_accuracy: 0.8750\n",
      "Epoch 279/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3093 - accuracy: 0.9320 - val_loss: 0.4697 - val_accuracy: 0.9250\n",
      "Epoch 280/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0273 - accuracy: 0.8810 - val_loss: 0.5832 - val_accuracy: 0.8750\n",
      "Epoch 281/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3691 - accuracy: 0.9160 - val_loss: 0.6083 - val_accuracy: 0.9000\n",
      "Epoch 282/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2228 - accuracy: 0.9120 - val_loss: 0.2920 - val_accuracy: 0.9250\n",
      "Epoch 283/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1133 - accuracy: 0.9250 - val_loss: 0.3331 - val_accuracy: 0.9000\n",
      "Epoch 284/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0944 - accuracy: 0.9370 - val_loss: 0.2804 - val_accuracy: 0.9250\n",
      "Epoch 285/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0994 - accuracy: 0.9380 - val_loss: 0.3144 - val_accuracy: 0.9000\n",
      "Epoch 286/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0970 - accuracy: 0.9330 - val_loss: 0.2630 - val_accuracy: 0.9250\n",
      "Epoch 287/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0854 - accuracy: 0.9340 - val_loss: 0.3684 - val_accuracy: 0.9000\n",
      "Epoch 288/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2007 - accuracy: 0.9250 - val_loss: 0.3892 - val_accuracy: 0.8750\n",
      "Epoch 289/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1554 - accuracy: 0.9340 - val_loss: 0.2615 - val_accuracy: 0.9000\n",
      "Epoch 290/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0941 - accuracy: 0.9370 - val_loss: 0.2674 - val_accuracy: 0.9250\n",
      "Epoch 291/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0789 - accuracy: 0.9470 - val_loss: 0.2651 - val_accuracy: 0.8750\n",
      "Epoch 292/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0948 - accuracy: 0.9320 - val_loss: 0.3459 - val_accuracy: 0.9000\n",
      "Epoch 293/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1653 - accuracy: 0.9330 - val_loss: 0.5158 - val_accuracy: 0.9500\n",
      "Epoch 294/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2424 - accuracy: 0.9260 - val_loss: 0.3016 - val_accuracy: 0.8750\n",
      "Epoch 295/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1569 - accuracy: 0.9360 - val_loss: 0.2575 - val_accuracy: 0.9250\n",
      "Epoch 296/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2068 - accuracy: 0.9240 - val_loss: 0.2994 - val_accuracy: 0.9250\n",
      "Epoch 297/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1142 - accuracy: 0.9330 - val_loss: 0.3132 - val_accuracy: 0.8750\n",
      "Epoch 298/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1969 - accuracy: 0.9330 - val_loss: 0.3670 - val_accuracy: 0.9250\n",
      "Epoch 299/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2885 - accuracy: 0.9320 - val_loss: 0.2793 - val_accuracy: 0.9500\n",
      "Epoch 300/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1872 - accuracy: 0.9220 - val_loss: 0.3408 - val_accuracy: 0.8750\n",
      "Epoch 301/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1767 - accuracy: 0.9250 - val_loss: 0.2967 - val_accuracy: 0.9250\n",
      "Epoch 302/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1132 - accuracy: 0.9350 - val_loss: 0.2342 - val_accuracy: 0.9000\n",
      "Epoch 303/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0905 - accuracy: 0.9430 - val_loss: 0.2383 - val_accuracy: 0.9000\n",
      "Epoch 304/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1197 - accuracy: 0.9380 - val_loss: 0.3112 - val_accuracy: 0.9000\n",
      "Epoch 305/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3820 - accuracy: 0.9160 - val_loss: 0.4987 - val_accuracy: 0.9000\n",
      "Epoch 306/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1139 - accuracy: 0.9280 - val_loss: 0.2442 - val_accuracy: 0.9000\n",
      "Epoch 307/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0908 - accuracy: 0.9330 - val_loss: 0.2664 - val_accuracy: 0.9250\n",
      "Epoch 308/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1570 - accuracy: 0.9310 - val_loss: 0.2653 - val_accuracy: 0.9250\n",
      "Epoch 309/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3053 - accuracy: 0.9170 - val_loss: 0.3295 - val_accuracy: 0.9250\n",
      "Epoch 310/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2069 - accuracy: 0.9220 - val_loss: 0.2666 - val_accuracy: 0.9000\n",
      "Epoch 311/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2208 - accuracy: 0.9270 - val_loss: 0.3718 - val_accuracy: 0.9250\n",
      "Epoch 312/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1399 - accuracy: 0.9410 - val_loss: 0.2602 - val_accuracy: 0.9250\n",
      "Epoch 313/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1219 - accuracy: 0.9210 - val_loss: 0.3326 - val_accuracy: 0.9000\n",
      "Epoch 314/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0940 - accuracy: 0.9340 - val_loss: 0.2594 - val_accuracy: 0.9250\n",
      "Epoch 315/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0870 - accuracy: 0.9360 - val_loss: 0.2404 - val_accuracy: 0.9000\n",
      "Epoch 316/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0861 - accuracy: 0.9470 - val_loss: 0.2887 - val_accuracy: 0.9250\n",
      "Epoch 317/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1101 - accuracy: 0.9370 - val_loss: 0.2580 - val_accuracy: 0.8750\n",
      "Epoch 318/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1499 - accuracy: 0.9320 - val_loss: 0.3512 - val_accuracy: 0.9250\n",
      "Epoch 319/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0954 - accuracy: 0.9340 - val_loss: 0.2372 - val_accuracy: 0.8750\n",
      "Epoch 320/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0781 - accuracy: 0.9370 - val_loss: 0.2422 - val_accuracy: 0.8750\n",
      "Epoch 321/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1105 - accuracy: 0.9280 - val_loss: 0.2188 - val_accuracy: 0.9250\n",
      "Epoch 322/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0853 - accuracy: 0.9350 - val_loss: 0.2164 - val_accuracy: 0.9000\n",
      "Epoch 323/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1009 - accuracy: 0.9340 - val_loss: 0.2603 - val_accuracy: 0.9000\n",
      "Epoch 324/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2206 - accuracy: 0.9270 - val_loss: 0.5150 - val_accuracy: 0.9250\n",
      "Epoch 325/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.5643 - accuracy: 0.9060 - val_loss: 0.4618 - val_accuracy: 0.9000\n",
      "Epoch 326/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2606 - accuracy: 0.9340 - val_loss: 0.2787 - val_accuracy: 0.9000\n",
      "Epoch 327/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0973 - accuracy: 0.9410 - val_loss: 0.2820 - val_accuracy: 0.9000\n",
      "Epoch 328/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0960 - accuracy: 0.9450 - val_loss: 0.2484 - val_accuracy: 0.9250\n",
      "Epoch 329/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0877 - accuracy: 0.9420 - val_loss: 0.2470 - val_accuracy: 0.9000\n",
      "Epoch 330/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1095 - accuracy: 0.9270 - val_loss: 0.2041 - val_accuracy: 0.9000\n",
      "Epoch 331/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0787 - accuracy: 0.9310 - val_loss: 0.2166 - val_accuracy: 0.9000\n",
      "Epoch 332/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0687 - accuracy: 0.9470 - val_loss: 0.2203 - val_accuracy: 0.9000\n",
      "Epoch 333/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0775 - accuracy: 0.9400 - val_loss: 0.2710 - val_accuracy: 0.9000\n",
      "Epoch 334/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0831 - accuracy: 0.9450 - val_loss: 0.2200 - val_accuracy: 0.9250\n",
      "Epoch 335/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1308 - accuracy: 0.9380 - val_loss: 0.3896 - val_accuracy: 0.9250\n",
      "Epoch 336/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2313 - accuracy: 0.9220 - val_loss: 0.3917 - val_accuracy: 0.9000\n",
      "Epoch 337/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1218 - accuracy: 0.9400 - val_loss: 0.2378 - val_accuracy: 0.9250\n",
      "Epoch 338/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1733 - accuracy: 0.9410 - val_loss: 0.6504 - val_accuracy: 0.9500\n",
      "Epoch 339/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2717 - accuracy: 0.9170 - val_loss: 0.2533 - val_accuracy: 0.9250\n",
      "Epoch 340/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3093 - accuracy: 0.9240 - val_loss: 0.2436 - val_accuracy: 0.9000\n",
      "Epoch 341/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1761 - accuracy: 0.9320 - val_loss: 0.2883 - val_accuracy: 0.9000\n",
      "Epoch 342/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0986 - accuracy: 0.9380 - val_loss: 0.2479 - val_accuracy: 0.9000\n",
      "Epoch 343/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0796 - accuracy: 0.9370 - val_loss: 0.2248 - val_accuracy: 0.9000\n",
      "Epoch 344/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0820 - accuracy: 0.9460 - val_loss: 0.2077 - val_accuracy: 0.9250\n",
      "Epoch 345/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1511 - accuracy: 0.9400 - val_loss: 0.3327 - val_accuracy: 0.9000\n",
      "Epoch 346/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1191 - accuracy: 0.9370 - val_loss: 0.3245 - val_accuracy: 0.9000\n",
      "Epoch 347/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1163 - accuracy: 0.9330 - val_loss: 0.2310 - val_accuracy: 0.9250\n",
      "Epoch 348/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0810 - accuracy: 0.9420 - val_loss: 0.2362 - val_accuracy: 0.9250\n",
      "Epoch 349/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0723 - accuracy: 0.9510 - val_loss: 0.2170 - val_accuracy: 0.9250\n",
      "Epoch 350/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0926 - accuracy: 0.9420 - val_loss: 0.2402 - val_accuracy: 0.9000\n",
      "Epoch 351/5000\n",
      "1000/1000 [==============================] - 1s 810us/step - loss: 0.0766 - accuracy: 0.9420 - val_loss: 0.2010 - val_accuracy: 0.9000\n",
      "Epoch 352/5000\n",
      "1000/1000 [==============================] - 1s 801us/step - loss: 0.1021 - accuracy: 0.9360 - val_loss: 0.4265 - val_accuracy: 0.9000\n",
      "Epoch 353/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2360 - accuracy: 0.9220 - val_loss: 0.2402 - val_accuracy: 0.9250\n",
      "Epoch 354/5000\n",
      "1000/1000 [==============================] - 1s 827us/step - loss: 0.4888 - accuracy: 0.8960 - val_loss: 0.2548 - val_accuracy: 0.9000\n",
      "Epoch 355/5000\n",
      "1000/1000 [==============================] - 1s 813us/step - loss: 0.1363 - accuracy: 0.9300 - val_loss: 0.1912 - val_accuracy: 0.9000\n",
      "Epoch 356/5000\n",
      "1000/1000 [==============================] - 1s 932us/step - loss: 0.0950 - accuracy: 0.9450 - val_loss: 0.2089 - val_accuracy: 0.8750\n",
      "Epoch 357/5000\n",
      "1000/1000 [==============================] - 1s 971us/step - loss: 0.0831 - accuracy: 0.9350 - val_loss: 0.1868 - val_accuracy: 0.8750\n",
      "Epoch 358/5000\n",
      "1000/1000 [==============================] - 1s 931us/step - loss: 0.0718 - accuracy: 0.9360 - val_loss: 0.1893 - val_accuracy: 0.9000\n",
      "Epoch 359/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0977 - accuracy: 0.9400 - val_loss: 0.1946 - val_accuracy: 0.8750\n",
      "Epoch 360/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0848 - accuracy: 0.9380 - val_loss: 0.2676 - val_accuracy: 0.9250\n",
      "Epoch 361/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0705 - accuracy: 0.9500 - val_loss: 0.1705 - val_accuracy: 0.9250\n",
      "Epoch 362/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3049 - accuracy: 0.9290 - val_loss: 0.4340 - val_accuracy: 0.8750\n",
      "Epoch 363/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2630 - accuracy: 0.9400 - val_loss: 0.5591 - val_accuracy: 0.8750\n",
      "Epoch 364/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2001 - accuracy: 0.9310 - val_loss: 0.2333 - val_accuracy: 0.9000\n",
      "Epoch 365/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1222 - accuracy: 0.9400 - val_loss: 0.2497 - val_accuracy: 0.8750\n",
      "Epoch 366/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0756 - accuracy: 0.9420 - val_loss: 0.2267 - val_accuracy: 0.9000\n",
      "Epoch 367/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0651 - accuracy: 0.9420 - val_loss: 0.2078 - val_accuracy: 0.9000\n",
      "Epoch 368/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0916 - accuracy: 0.9430 - val_loss: 0.2233 - val_accuracy: 0.9000\n",
      "Epoch 369/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0648 - accuracy: 0.9390 - val_loss: 0.1904 - val_accuracy: 0.9000\n",
      "Epoch 370/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0585 - accuracy: 0.9500 - val_loss: 0.2408 - val_accuracy: 0.9000\n",
      "Epoch 371/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0836 - accuracy: 0.9420 - val_loss: 0.2055 - val_accuracy: 0.9000\n",
      "Epoch 372/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0753 - accuracy: 0.9440 - val_loss: 0.1979 - val_accuracy: 0.8750\n",
      "Epoch 373/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1265 - accuracy: 0.9320 - val_loss: 0.1931 - val_accuracy: 0.9000\n",
      "Epoch 374/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1098 - accuracy: 0.9360 - val_loss: 0.2318 - val_accuracy: 0.9000\n",
      "Epoch 375/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1043 - accuracy: 0.9370 - val_loss: 0.2108 - val_accuracy: 0.9250\n",
      "Epoch 376/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1379 - accuracy: 0.9430 - val_loss: 0.2565 - val_accuracy: 0.9250\n",
      "Epoch 377/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1859 - accuracy: 0.9350 - val_loss: 0.9731 - val_accuracy: 0.9500\n",
      "Epoch 378/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2759 - accuracy: 0.9260 - val_loss: 0.5009 - val_accuracy: 0.9000\n",
      "Epoch 379/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.8033 - accuracy: 0.9140 - val_loss: 1.8735 - val_accuracy: 0.8750\n",
      "Epoch 380/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3754 - accuracy: 0.9050 - val_loss: 0.6157 - val_accuracy: 0.9250\n",
      "Epoch 381/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1542 - accuracy: 0.9420 - val_loss: 0.1977 - val_accuracy: 0.9000\n",
      "Epoch 382/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0805 - accuracy: 0.9520 - val_loss: 0.1876 - val_accuracy: 0.9000\n",
      "Epoch 383/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0759 - accuracy: 0.9520 - val_loss: 0.2302 - val_accuracy: 0.9000\n",
      "Epoch 384/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0628 - accuracy: 0.9470 - val_loss: 0.2010 - val_accuracy: 0.9000\n",
      "Epoch 385/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0652 - accuracy: 0.9500 - val_loss: 0.2049 - val_accuracy: 0.9000\n",
      "Epoch 386/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0596 - accuracy: 0.9540 - val_loss: 0.2573 - val_accuracy: 0.9000\n",
      "Epoch 387/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0634 - accuracy: 0.9490 - val_loss: 0.1944 - val_accuracy: 0.9000\n",
      "Epoch 388/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0561 - accuracy: 0.9440 - val_loss: 0.2132 - val_accuracy: 0.9250\n",
      "Epoch 389/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0963 - accuracy: 0.9530 - val_loss: 0.7316 - val_accuracy: 0.9000\n",
      "Epoch 390/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2101 - accuracy: 0.9350 - val_loss: 0.2220 - val_accuracy: 0.9000\n",
      "Epoch 391/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0818 - accuracy: 0.9480 - val_loss: 0.2287 - val_accuracy: 0.9250\n",
      "Epoch 392/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1237 - accuracy: 0.9450 - val_loss: 0.2801 - val_accuracy: 0.9000\n",
      "Epoch 393/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1701 - accuracy: 0.9210 - val_loss: 0.2469 - val_accuracy: 0.9250\n",
      "Epoch 394/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0852 - accuracy: 0.9350 - val_loss: 0.2228 - val_accuracy: 0.9000\n",
      "Epoch 395/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0901 - accuracy: 0.9340 - val_loss: 0.2510 - val_accuracy: 0.9000\n",
      "Epoch 396/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2195 - accuracy: 0.9250 - val_loss: 0.1827 - val_accuracy: 0.9250\n",
      "Epoch 397/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0904 - accuracy: 0.9450 - val_loss: 0.2375 - val_accuracy: 0.9000\n",
      "Epoch 398/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0629 - accuracy: 0.9520 - val_loss: 0.2059 - val_accuracy: 0.9000\n",
      "Epoch 399/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0942 - accuracy: 0.9500 - val_loss: 0.2522 - val_accuracy: 0.8750\n",
      "Epoch 400/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0684 - accuracy: 0.9480 - val_loss: 0.1648 - val_accuracy: 0.9000\n",
      "Epoch 401/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1060 - accuracy: 0.9500 - val_loss: 0.3123 - val_accuracy: 0.9500\n",
      "Epoch 402/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2260 - accuracy: 0.9450 - val_loss: 0.4645 - val_accuracy: 0.9000\n",
      "Epoch 403/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2608 - accuracy: 0.9170 - val_loss: 0.3105 - val_accuracy: 0.9250\n",
      "Epoch 404/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1522 - accuracy: 0.9490 - val_loss: 0.2472 - val_accuracy: 0.9000\n",
      "Epoch 405/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1201 - accuracy: 0.9460 - val_loss: 0.2502 - val_accuracy: 0.8750\n",
      "Epoch 406/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0769 - accuracy: 0.9500 - val_loss: 0.2567 - val_accuracy: 0.8750\n",
      "Epoch 407/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0917 - accuracy: 0.9490 - val_loss: 0.2004 - val_accuracy: 0.9000\n",
      "Epoch 408/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0729 - accuracy: 0.9530 - val_loss: 0.4250 - val_accuracy: 0.9250\n",
      "Epoch 409/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0910 - accuracy: 0.9520 - val_loss: 0.1989 - val_accuracy: 0.9250\n",
      "Epoch 410/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0665 - accuracy: 0.9450 - val_loss: 0.1901 - val_accuracy: 0.9000\n",
      "Epoch 411/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0624 - accuracy: 0.9500 - val_loss: 0.1609 - val_accuracy: 0.9000\n",
      "Epoch 412/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0569 - accuracy: 0.9520 - val_loss: 0.1911 - val_accuracy: 0.9000\n",
      "Epoch 413/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0994 - accuracy: 0.9530 - val_loss: 0.2515 - val_accuracy: 0.9000\n",
      "Epoch 414/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0784 - accuracy: 0.9500 - val_loss: 0.2045 - val_accuracy: 0.9000\n",
      "Epoch 415/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1003 - accuracy: 0.9470 - val_loss: 0.1518 - val_accuracy: 0.8750\n",
      "Epoch 416/5000\n",
      "1000/1000 [==============================] - 1s 788us/step - loss: 0.1370 - accuracy: 0.9380 - val_loss: 0.2134 - val_accuracy: 0.8750\n",
      "Epoch 417/5000\n",
      "1000/1000 [==============================] - 1s 787us/step - loss: 0.5301 - accuracy: 0.9260 - val_loss: 0.9989 - val_accuracy: 0.8750\n",
      "Epoch 418/5000\n",
      "1000/1000 [==============================] - 1s 933us/step - loss: 0.5430 - accuracy: 0.9140 - val_loss: 0.2025 - val_accuracy: 0.9000\n",
      "Epoch 419/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0984 - accuracy: 0.9510 - val_loss: 0.2169 - val_accuracy: 0.9250\n",
      "Epoch 420/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0598 - accuracy: 0.9540 - val_loss: 0.1906 - val_accuracy: 0.9000\n",
      "Epoch 421/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0636 - accuracy: 0.9510 - val_loss: 0.1768 - val_accuracy: 0.9000\n",
      "Epoch 422/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0641 - accuracy: 0.9570 - val_loss: 0.2098 - val_accuracy: 0.9000\n",
      "Epoch 423/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0827 - accuracy: 0.9580 - val_loss: 0.1906 - val_accuracy: 0.9000\n",
      "Epoch 424/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0656 - accuracy: 0.9480 - val_loss: 0.2004 - val_accuracy: 0.9000\n",
      "Epoch 425/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0488 - accuracy: 0.9540 - val_loss: 0.1606 - val_accuracy: 0.9000\n",
      "Epoch 426/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0486 - accuracy: 0.9580 - val_loss: 0.2534 - val_accuracy: 0.9000\n",
      "Epoch 427/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0668 - accuracy: 0.9520 - val_loss: 0.1733 - val_accuracy: 0.9000\n",
      "Epoch 428/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0981 - accuracy: 0.9480 - val_loss: 0.1592 - val_accuracy: 0.9000\n",
      "Epoch 429/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0839 - accuracy: 0.9480 - val_loss: 0.2173 - val_accuracy: 0.9250\n",
      "Epoch 430/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0812 - accuracy: 0.9420 - val_loss: 0.2062 - val_accuracy: 0.8750\n",
      "Epoch 431/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0905 - accuracy: 0.9570 - val_loss: 0.1866 - val_accuracy: 0.9000\n",
      "Epoch 432/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0623 - accuracy: 0.9500 - val_loss: 0.1452 - val_accuracy: 0.9000\n",
      "Epoch 433/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0658 - accuracy: 0.9520 - val_loss: 0.1849 - val_accuracy: 0.9000\n",
      "Epoch 434/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0848 - accuracy: 0.9490 - val_loss: 0.2450 - val_accuracy: 0.8750\n",
      "Epoch 435/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2159 - accuracy: 0.9310 - val_loss: 0.5233 - val_accuracy: 0.9000\n",
      "Epoch 436/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2467 - accuracy: 0.9240 - val_loss: 0.2191 - val_accuracy: 0.8750\n",
      "Epoch 437/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1123 - accuracy: 0.9460 - val_loss: 0.3239 - val_accuracy: 0.9250\n",
      "Epoch 438/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2173 - accuracy: 0.9380 - val_loss: 0.2406 - val_accuracy: 0.9500\n",
      "Epoch 439/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0862 - accuracy: 0.9410 - val_loss: 0.2070 - val_accuracy: 0.9000\n",
      "Epoch 440/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0728 - accuracy: 0.9530 - val_loss: 0.1960 - val_accuracy: 0.9250\n",
      "Epoch 441/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1126 - accuracy: 0.9420 - val_loss: 0.2322 - val_accuracy: 0.9250\n",
      "Epoch 442/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0536 - accuracy: 0.9560 - val_loss: 0.1770 - val_accuracy: 0.8750\n",
      "Epoch 443/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3610 - accuracy: 0.9300 - val_loss: 0.2312 - val_accuracy: 0.9000\n",
      "Epoch 444/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1009 - accuracy: 0.9560 - val_loss: 0.2102 - val_accuracy: 0.9000\n",
      "Epoch 445/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0739 - accuracy: 0.9610 - val_loss: 0.1673 - val_accuracy: 0.9250\n",
      "Epoch 446/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0629 - accuracy: 0.9560 - val_loss: 0.2231 - val_accuracy: 0.9250\n",
      "Epoch 447/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0473 - accuracy: 0.9600 - val_loss: 0.1820 - val_accuracy: 0.9000\n",
      "Epoch 448/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0458 - accuracy: 0.9610 - val_loss: 0.1752 - val_accuracy: 0.9000\n",
      "Epoch 449/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0505 - accuracy: 0.9510 - val_loss: 0.2063 - val_accuracy: 0.9250\n",
      "Epoch 450/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0540 - accuracy: 0.9530 - val_loss: 0.1744 - val_accuracy: 0.8750\n",
      "Epoch 451/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0571 - accuracy: 0.9580 - val_loss: 0.1634 - val_accuracy: 0.9500\n",
      "Epoch 452/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0566 - accuracy: 0.9600 - val_loss: 0.1673 - val_accuracy: 0.9500\n",
      "Epoch 453/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0565 - accuracy: 0.9470 - val_loss: 0.1615 - val_accuracy: 0.9500\n",
      "Epoch 454/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0615 - accuracy: 0.9550 - val_loss: 0.2032 - val_accuracy: 0.9000\n",
      "Epoch 455/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1061 - accuracy: 0.9480 - val_loss: 0.2528 - val_accuracy: 0.8750\n",
      "Epoch 456/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1336 - accuracy: 0.9520 - val_loss: 0.2691 - val_accuracy: 0.9000\n",
      "Epoch 457/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1248 - accuracy: 0.9510 - val_loss: 0.4496 - val_accuracy: 0.9000\n",
      "Epoch 458/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1779 - accuracy: 0.9400 - val_loss: 0.2171 - val_accuracy: 0.9000\n",
      "Epoch 459/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0927 - accuracy: 0.9450 - val_loss: 0.2093 - val_accuracy: 0.9250\n",
      "Epoch 460/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1644 - accuracy: 0.9470 - val_loss: 0.2497 - val_accuracy: 0.9000\n",
      "Epoch 461/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1031 - accuracy: 0.9510 - val_loss: 0.1882 - val_accuracy: 0.9250\n",
      "Epoch 462/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0622 - accuracy: 0.9460 - val_loss: 0.1575 - val_accuracy: 0.9000\n",
      "Epoch 463/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0528 - accuracy: 0.9540 - val_loss: 0.1732 - val_accuracy: 0.9250\n",
      "Epoch 464/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0565 - accuracy: 0.9520 - val_loss: 0.1527 - val_accuracy: 0.9250\n",
      "Epoch 465/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0535 - accuracy: 0.9610 - val_loss: 0.1771 - val_accuracy: 0.9250\n",
      "Epoch 466/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0838 - accuracy: 0.9590 - val_loss: 0.5085 - val_accuracy: 0.9250\n",
      "Epoch 467/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6811 - accuracy: 0.9200 - val_loss: 0.4858 - val_accuracy: 0.8750\n",
      "Epoch 468/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1333 - accuracy: 0.9400 - val_loss: 0.2230 - val_accuracy: 0.9500\n",
      "Epoch 469/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0760 - accuracy: 0.9530 - val_loss: 0.2041 - val_accuracy: 0.9250\n",
      "Epoch 470/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0555 - accuracy: 0.9510 - val_loss: 0.2243 - val_accuracy: 0.9250\n",
      "Epoch 471/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0538 - accuracy: 0.9510 - val_loss: 0.2306 - val_accuracy: 0.9000\n",
      "Epoch 472/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0615 - accuracy: 0.9620 - val_loss: 0.2188 - val_accuracy: 0.9000\n",
      "Epoch 473/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0730 - accuracy: 0.9590 - val_loss: 0.2668 - val_accuracy: 0.8750\n",
      "Epoch 474/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0562 - accuracy: 0.9570 - val_loss: 0.1924 - val_accuracy: 0.9250\n",
      "Epoch 475/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0517 - accuracy: 0.9550 - val_loss: 0.1592 - val_accuracy: 0.9500\n",
      "Epoch 476/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0487 - accuracy: 0.9590 - val_loss: 0.1359 - val_accuracy: 0.9250\n",
      "Epoch 477/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0423 - accuracy: 0.9600 - val_loss: 0.1359 - val_accuracy: 0.9250\n",
      "Epoch 478/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0532 - accuracy: 0.9580 - val_loss: 0.1636 - val_accuracy: 0.9250\n",
      "Epoch 479/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0521 - accuracy: 0.9590 - val_loss: 0.1601 - val_accuracy: 0.9500\n",
      "Epoch 480/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0499 - accuracy: 0.9550 - val_loss: 0.1776 - val_accuracy: 0.9000\n",
      "Epoch 481/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0699 - accuracy: 0.9510 - val_loss: 0.1819 - val_accuracy: 0.9000\n",
      "Epoch 482/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0651 - accuracy: 0.9500 - val_loss: 0.1754 - val_accuracy: 0.9000\n",
      "Epoch 483/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0792 - accuracy: 0.9480 - val_loss: 0.1631 - val_accuracy: 0.9250\n",
      "Epoch 484/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0989 - accuracy: 0.9520 - val_loss: 0.6330 - val_accuracy: 0.9000\n",
      "Epoch 485/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.7268 - accuracy: 0.9150 - val_loss: 0.3017 - val_accuracy: 0.9250\n",
      "Epoch 486/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1545 - accuracy: 0.9410 - val_loss: 0.2029 - val_accuracy: 0.9750\n",
      "Epoch 487/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0850 - accuracy: 0.9610 - val_loss: 0.1835 - val_accuracy: 0.9250\n",
      "Epoch 488/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0600 - accuracy: 0.9560 - val_loss: 0.1539 - val_accuracy: 0.9250\n",
      "Epoch 489/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0573 - accuracy: 0.9630 - val_loss: 0.1515 - val_accuracy: 0.9250\n",
      "Epoch 490/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0597 - accuracy: 0.9550 - val_loss: 0.1942 - val_accuracy: 0.9000\n",
      "Epoch 491/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0513 - accuracy: 0.9550 - val_loss: 0.1898 - val_accuracy: 0.9000\n",
      "Epoch 492/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0427 - accuracy: 0.9620 - val_loss: 0.1466 - val_accuracy: 0.9250\n",
      "Epoch 493/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0408 - accuracy: 0.9570 - val_loss: 0.1293 - val_accuracy: 0.9250\n",
      "Epoch 494/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0402 - accuracy: 0.9580 - val_loss: 0.1619 - val_accuracy: 0.9000\n",
      "Epoch 495/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0521 - accuracy: 0.9550 - val_loss: 0.1528 - val_accuracy: 0.9000\n",
      "Epoch 496/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0429 - accuracy: 0.9640 - val_loss: 0.1570 - val_accuracy: 0.9500\n",
      "Epoch 497/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0706 - accuracy: 0.9420 - val_loss: 0.1599 - val_accuracy: 0.8750\n",
      "Epoch 498/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0477 - accuracy: 0.9590 - val_loss: 0.1985 - val_accuracy: 0.9000\n",
      "Epoch 499/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0605 - accuracy: 0.9550 - val_loss: 0.1516 - val_accuracy: 0.9250\n",
      "Epoch 500/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2295 - accuracy: 0.9420 - val_loss: 0.4199 - val_accuracy: 0.9000\n",
      "Epoch 501/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1160 - accuracy: 0.9450 - val_loss: 0.1451 - val_accuracy: 0.9250\n",
      "Epoch 502/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0556 - accuracy: 0.9550 - val_loss: 0.1577 - val_accuracy: 0.9250\n",
      "Epoch 503/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0525 - accuracy: 0.9570 - val_loss: 0.2404 - val_accuracy: 0.9250\n",
      "Epoch 504/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1693 - accuracy: 0.9480 - val_loss: 0.2420 - val_accuracy: 0.9000\n",
      "Epoch 505/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0737 - accuracy: 0.9500 - val_loss: 0.1559 - val_accuracy: 0.9750\n",
      "Epoch 506/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0597 - accuracy: 0.9560 - val_loss: 0.2014 - val_accuracy: 0.9000\n",
      "Epoch 507/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0431 - accuracy: 0.9560 - val_loss: 0.1733 - val_accuracy: 0.9000\n",
      "Epoch 508/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0463 - accuracy: 0.9520 - val_loss: 0.1742 - val_accuracy: 0.9250\n",
      "Epoch 509/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0446 - accuracy: 0.9510 - val_loss: 0.1617 - val_accuracy: 0.9250\n",
      "Epoch 510/5000\n",
      "1000/1000 [==============================] - 1s 818us/step - loss: 0.1077 - accuracy: 0.9450 - val_loss: 0.1863 - val_accuracy: 0.9250\n",
      "Epoch 511/5000\n",
      "1000/1000 [==============================] - 1s 875us/step - loss: 0.1429 - accuracy: 0.9390 - val_loss: 0.2726 - val_accuracy: 0.9250\n",
      "Epoch 512/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0960 - accuracy: 0.9420 - val_loss: 0.1488 - val_accuracy: 0.9750\n",
      "Epoch 513/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0646 - accuracy: 0.9590 - val_loss: 0.1884 - val_accuracy: 0.9250\n",
      "Epoch 514/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0492 - accuracy: 0.9550 - val_loss: 0.1939 - val_accuracy: 0.9000\n",
      "Epoch 515/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0431 - accuracy: 0.9560 - val_loss: 0.1346 - val_accuracy: 0.9000\n",
      "Epoch 516/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0555 - accuracy: 0.9540 - val_loss: 0.1495 - val_accuracy: 0.9250\n",
      "Epoch 517/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1203 - accuracy: 0.9500 - val_loss: 0.2194 - val_accuracy: 0.9250\n",
      "Epoch 518/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3628 - accuracy: 0.9290 - val_loss: 0.1951 - val_accuracy: 0.9000\n",
      "Epoch 519/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1548 - accuracy: 0.9380 - val_loss: 0.2394 - val_accuracy: 0.9250\n",
      "Epoch 520/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0756 - accuracy: 0.9460 - val_loss: 0.1888 - val_accuracy: 0.9750\n",
      "Epoch 521/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1842 - accuracy: 0.9510 - val_loss: 0.7167 - val_accuracy: 0.9250\n",
      "Epoch 522/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1687 - accuracy: 0.9330 - val_loss: 0.2568 - val_accuracy: 0.9000\n",
      "Epoch 523/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0856 - accuracy: 0.9540 - val_loss: 0.1948 - val_accuracy: 0.9250\n",
      "Epoch 524/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0563 - accuracy: 0.9570 - val_loss: 0.2435 - val_accuracy: 0.9750\n",
      "Epoch 525/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0481 - accuracy: 0.9600 - val_loss: 0.1498 - val_accuracy: 0.9250\n",
      "Epoch 526/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0649 - accuracy: 0.9540 - val_loss: 0.1330 - val_accuracy: 0.9500\n",
      "Epoch 527/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0722 - accuracy: 0.9480 - val_loss: 0.2606 - val_accuracy: 0.9250\n",
      "Epoch 528/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0507 - accuracy: 0.9590 - val_loss: 0.1790 - val_accuracy: 0.9500\n",
      "Epoch 529/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0595 - accuracy: 0.9600 - val_loss: 0.1941 - val_accuracy: 0.9250\n",
      "Epoch 530/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0726 - accuracy: 0.9500 - val_loss: 0.2086 - val_accuracy: 0.9000\n",
      "Epoch 531/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1215 - accuracy: 0.9440 - val_loss: 0.3202 - val_accuracy: 0.8750\n",
      "Epoch 532/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1487 - accuracy: 0.9410 - val_loss: 0.2598 - val_accuracy: 0.9250\n",
      "Epoch 533/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1063 - accuracy: 0.9430 - val_loss: 0.1782 - val_accuracy: 0.9250\n",
      "Epoch 534/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1520 - accuracy: 0.9450 - val_loss: 0.1902 - val_accuracy: 0.9250\n",
      "Epoch 535/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1024 - accuracy: 0.9620 - val_loss: 0.2572 - val_accuracy: 0.9250\n",
      "Epoch 536/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1386 - accuracy: 0.9450 - val_loss: 0.2536 - val_accuracy: 0.9500\n",
      "Epoch 537/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1881 - accuracy: 0.9480 - val_loss: 0.3046 - val_accuracy: 0.9250\n",
      "Epoch 538/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1235 - accuracy: 0.9540 - val_loss: 0.1534 - val_accuracy: 0.9250\n",
      "Epoch 539/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0770 - accuracy: 0.9610 - val_loss: 0.1280 - val_accuracy: 0.9500\n",
      "Epoch 540/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0435 - accuracy: 0.9620 - val_loss: 0.1417 - val_accuracy: 0.9500\n",
      "Epoch 541/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0390 - accuracy: 0.9630 - val_loss: 0.1747 - val_accuracy: 0.9250\n",
      "Epoch 542/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0588 - accuracy: 0.9570 - val_loss: 0.1618 - val_accuracy: 0.9250\n",
      "Epoch 543/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0766 - accuracy: 0.9680 - val_loss: 0.3029 - val_accuracy: 0.9000\n",
      "Epoch 544/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1641 - accuracy: 0.9510 - val_loss: 0.2017 - val_accuracy: 0.9000\n",
      "Epoch 545/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0955 - accuracy: 0.9520 - val_loss: 0.1434 - val_accuracy: 0.9000\n",
      "Epoch 546/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0695 - accuracy: 0.9570 - val_loss: 0.2429 - val_accuracy: 0.9250\n",
      "Epoch 547/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0606 - accuracy: 0.9570 - val_loss: 0.1903 - val_accuracy: 0.9750\n",
      "Epoch 548/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0758 - accuracy: 0.9600 - val_loss: 0.1768 - val_accuracy: 0.9500\n",
      "Epoch 549/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0600 - accuracy: 0.9540 - val_loss: 0.1445 - val_accuracy: 0.8750\n",
      "Epoch 550/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0479 - accuracy: 0.9630 - val_loss: 0.1413 - val_accuracy: 0.9500\n",
      "Epoch 551/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0428 - accuracy: 0.9620 - val_loss: 0.1379 - val_accuracy: 0.9250\n",
      "Epoch 552/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0418 - accuracy: 0.9610 - val_loss: 0.1258 - val_accuracy: 0.9500\n",
      "Epoch 553/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0381 - accuracy: 0.9580 - val_loss: 0.1269 - val_accuracy: 0.9000\n",
      "Epoch 554/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0592 - accuracy: 0.9580 - val_loss: 0.1419 - val_accuracy: 0.9250\n",
      "Epoch 555/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0533 - accuracy: 0.9510 - val_loss: 0.1500 - val_accuracy: 0.9750\n",
      "Epoch 556/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0544 - accuracy: 0.9580 - val_loss: 0.1470 - val_accuracy: 0.9500\n",
      "Epoch 557/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0412 - accuracy: 0.9560 - val_loss: 0.1652 - val_accuracy: 0.9000\n",
      "Epoch 558/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0511 - accuracy: 0.9550 - val_loss: 0.1045 - val_accuracy: 0.9250\n",
      "Epoch 559/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0796 - accuracy: 0.9520 - val_loss: 0.2322 - val_accuracy: 0.9000\n",
      "Epoch 560/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2716 - accuracy: 0.9200 - val_loss: 0.3932 - val_accuracy: 0.8500\n",
      "Epoch 561/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1556 - accuracy: 0.9280 - val_loss: 0.2021 - val_accuracy: 0.9000\n",
      "Epoch 562/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0674 - accuracy: 0.9630 - val_loss: 0.1916 - val_accuracy: 0.9750\n",
      "Epoch 563/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0467 - accuracy: 0.9580 - val_loss: 0.1241 - val_accuracy: 0.9250\n",
      "Epoch 564/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0434 - accuracy: 0.9580 - val_loss: 0.1478 - val_accuracy: 0.9750\n",
      "Epoch 565/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0579 - accuracy: 0.9660 - val_loss: 0.2438 - val_accuracy: 0.9250\n",
      "Epoch 566/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0864 - accuracy: 0.9470 - val_loss: 0.1532 - val_accuracy: 0.9250\n",
      "Epoch 567/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0378 - accuracy: 0.9570 - val_loss: 0.1480 - val_accuracy: 0.9500\n",
      "Epoch 568/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0399 - accuracy: 0.9640 - val_loss: 0.1222 - val_accuracy: 0.9250\n",
      "Epoch 569/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0337 - accuracy: 0.9600 - val_loss: 0.1233 - val_accuracy: 0.9250\n",
      "Epoch 570/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0335 - accuracy: 0.9560 - val_loss: 0.1118 - val_accuracy: 0.9250\n",
      "Epoch 571/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0654 - accuracy: 0.9620 - val_loss: 0.1994 - val_accuracy: 0.9250\n",
      "Epoch 572/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1420 - accuracy: 0.9490 - val_loss: 0.2277 - val_accuracy: 0.9500\n",
      "Epoch 573/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4753 - accuracy: 0.9160 - val_loss: 1.0034 - val_accuracy: 0.9000\n",
      "Epoch 574/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2567 - accuracy: 0.9350 - val_loss: 0.2903 - val_accuracy: 0.9000\n",
      "Epoch 575/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1002 - accuracy: 0.9290 - val_loss: 0.3417 - val_accuracy: 0.9750\n",
      "Epoch 576/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1407 - accuracy: 0.9520 - val_loss: 0.4561 - val_accuracy: 0.9500\n",
      "Epoch 577/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1349 - accuracy: 0.9490 - val_loss: 0.1853 - val_accuracy: 0.9750\n",
      "Epoch 578/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0359 - accuracy: 0.9550 - val_loss: 0.1302 - val_accuracy: 0.9250\n",
      "Epoch 579/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0324 - accuracy: 0.9610 - val_loss: 0.1297 - val_accuracy: 0.9250\n",
      "Epoch 580/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0320 - accuracy: 0.9610 - val_loss: 0.1393 - val_accuracy: 0.9250\n",
      "Epoch 581/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0325 - accuracy: 0.9620 - val_loss: 0.1291 - val_accuracy: 0.9250\n",
      "Epoch 582/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0413 - accuracy: 0.9610 - val_loss: 0.1259 - val_accuracy: 0.9500\n",
      "Epoch 583/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0346 - accuracy: 0.9650 - val_loss: 0.1280 - val_accuracy: 0.9500\n",
      "Epoch 584/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0291 - accuracy: 0.9640 - val_loss: 0.1281 - val_accuracy: 0.9750\n",
      "Epoch 585/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0312 - accuracy: 0.9600 - val_loss: 0.1036 - val_accuracy: 0.9750\n",
      "Epoch 586/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0325 - accuracy: 0.9600 - val_loss: 0.1457 - val_accuracy: 0.9750\n",
      "Epoch 587/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0430 - accuracy: 0.9710 - val_loss: 0.1395 - val_accuracy: 0.9750\n",
      "Epoch 588/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0911 - accuracy: 0.9540 - val_loss: 0.1985 - val_accuracy: 0.9500\n",
      "Epoch 589/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1945 - accuracy: 0.9420 - val_loss: 0.2813 - val_accuracy: 0.9000\n",
      "Epoch 590/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2082 - accuracy: 0.9340 - val_loss: 0.2070 - val_accuracy: 0.9250\n",
      "Epoch 591/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1049 - accuracy: 0.9460 - val_loss: 0.1842 - val_accuracy: 0.9500\n",
      "Epoch 592/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0395 - accuracy: 0.9590 - val_loss: 0.1657 - val_accuracy: 0.9250\n",
      "Epoch 593/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0386 - accuracy: 0.9550 - val_loss: 0.1672 - val_accuracy: 0.9000\n",
      "Epoch 594/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0301 - accuracy: 0.9590 - val_loss: 0.1513 - val_accuracy: 0.9250\n",
      "Epoch 595/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0448 - accuracy: 0.9600 - val_loss: 0.1538 - val_accuracy: 0.9000\n",
      "Epoch 596/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0618 - accuracy: 0.9590 - val_loss: 0.1171 - val_accuracy: 0.9000\n",
      "Epoch 597/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0589 - accuracy: 0.9530 - val_loss: 0.1301 - val_accuracy: 0.9750\n",
      "Epoch 598/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0540 - accuracy: 0.9540 - val_loss: 0.2295 - val_accuracy: 0.9250\n",
      "Epoch 599/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0825 - accuracy: 0.9540 - val_loss: 0.3676 - val_accuracy: 0.9750\n",
      "Epoch 600/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1135 - accuracy: 0.9570 - val_loss: 0.1714 - val_accuracy: 0.9500\n",
      "Epoch 601/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0591 - accuracy: 0.9530 - val_loss: 0.1613 - val_accuracy: 0.9500\n",
      "Epoch 602/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0372 - accuracy: 0.9550 - val_loss: 0.1090 - val_accuracy: 0.9250\n",
      "Epoch 603/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0403 - accuracy: 0.9580 - val_loss: 0.1183 - val_accuracy: 0.9500\n",
      "Epoch 604/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0350 - accuracy: 0.9640 - val_loss: 0.1332 - val_accuracy: 0.9750\n",
      "Epoch 605/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0342 - accuracy: 0.9650 - val_loss: 0.1460 - val_accuracy: 0.9000\n",
      "Epoch 606/5000\n",
      "1000/1000 [==============================] - 1s 924us/step - loss: 0.0314 - accuracy: 0.9590 - val_loss: 0.1089 - val_accuracy: 0.9750\n",
      "Epoch 607/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 785us/step - loss: 0.0328 - accuracy: 0.9560 - val_loss: 0.1477 - val_accuracy: 0.9750\n",
      "Epoch 608/5000\n",
      "1000/1000 [==============================] - 1s 771us/step - loss: 0.0486 - accuracy: 0.9590 - val_loss: 0.1723 - val_accuracy: 0.9250\n",
      "Epoch 609/5000\n",
      "1000/1000 [==============================] - 1s 779us/step - loss: 0.6523 - accuracy: 0.9100 - val_loss: 0.3477 - val_accuracy: 0.8500\n",
      "Epoch 610/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1869 - accuracy: 0.9410 - val_loss: 0.1930 - val_accuracy: 0.9250\n",
      "Epoch 611/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2473 - accuracy: 0.9440 - val_loss: 0.2980 - val_accuracy: 0.9250\n",
      "Epoch 612/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1034 - accuracy: 0.9510 - val_loss: 0.2898 - val_accuracy: 0.9250\n",
      "Epoch 613/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0509 - accuracy: 0.9620 - val_loss: 0.1388 - val_accuracy: 0.9000\n",
      "Epoch 614/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0323 - accuracy: 0.9590 - val_loss: 0.1694 - val_accuracy: 0.9500\n",
      "Epoch 615/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0350 - accuracy: 0.9590 - val_loss: 0.1299 - val_accuracy: 0.9750\n",
      "Epoch 616/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0318 - accuracy: 0.9570 - val_loss: 0.1286 - val_accuracy: 0.9250\n",
      "Epoch 617/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0272 - accuracy: 0.9600 - val_loss: 0.1219 - val_accuracy: 0.9750\n",
      "Epoch 618/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0250 - accuracy: 0.9590 - val_loss: 0.1122 - val_accuracy: 0.9500\n",
      "Epoch 619/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0258 - accuracy: 0.9650 - val_loss: 0.1164 - val_accuracy: 0.9500\n",
      "Epoch 620/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0275 - accuracy: 0.9610 - val_loss: 0.1584 - val_accuracy: 0.9500\n",
      "Epoch 621/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0305 - accuracy: 0.9620 - val_loss: 0.1371 - val_accuracy: 0.9500\n",
      "Epoch 622/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0348 - accuracy: 0.9660 - val_loss: 0.1891 - val_accuracy: 0.9750\n",
      "Epoch 623/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0469 - accuracy: 0.9510 - val_loss: 0.1313 - val_accuracy: 0.9250\n",
      "Epoch 624/5000\n",
      "1000/1000 [==============================] - 1s 771us/step - loss: 0.0333 - accuracy: 0.9580 - val_loss: 0.1221 - val_accuracy: 0.9750\n",
      "Epoch 625/5000\n",
      "1000/1000 [==============================] - 1s 934us/step - loss: 0.0525 - accuracy: 0.9540 - val_loss: 0.1086 - val_accuracy: 0.9500\n",
      "Epoch 626/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0348 - accuracy: 0.9590 - val_loss: 0.1344 - val_accuracy: 0.9500\n",
      "Epoch 627/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0598 - accuracy: 0.9560 - val_loss: 0.1823 - val_accuracy: 0.9500\n",
      "Epoch 628/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1765 - accuracy: 0.9460 - val_loss: 0.4097 - val_accuracy: 0.9500\n",
      "Epoch 629/5000\n",
      "1000/1000 [==============================] - 1s 794us/step - loss: 0.1111 - accuracy: 0.9520 - val_loss: 0.1983 - val_accuracy: 0.9500\n",
      "Epoch 630/5000\n",
      "1000/1000 [==============================] - 1s 798us/step - loss: 0.1046 - accuracy: 0.9590 - val_loss: 0.2178 - val_accuracy: 0.9000\n",
      "Epoch 631/5000\n",
      "1000/1000 [==============================] - 1s 969us/step - loss: 0.1985 - accuracy: 0.9440 - val_loss: 0.2216 - val_accuracy: 0.9000\n",
      "Epoch 632/5000\n",
      "1000/1000 [==============================] - 1s 989us/step - loss: 0.0632 - accuracy: 0.9460 - val_loss: 0.1817 - val_accuracy: 0.9250\n",
      "Epoch 633/5000\n",
      "1000/1000 [==============================] - 1s 850us/step - loss: 0.0502 - accuracy: 0.9570 - val_loss: 0.1737 - val_accuracy: 0.9250\n",
      "Epoch 634/5000\n",
      "1000/1000 [==============================] - 1s 878us/step - loss: 0.2378 - accuracy: 0.9420 - val_loss: 0.3919 - val_accuracy: 0.9500\n",
      "Epoch 635/5000\n",
      "1000/1000 [==============================] - 1s 854us/step - loss: 0.1190 - accuracy: 0.9440 - val_loss: 0.1535 - val_accuracy: 0.9250\n",
      "Epoch 636/5000\n",
      "1000/1000 [==============================] - 1s 824us/step - loss: 0.0545 - accuracy: 0.9650 - val_loss: 0.1720 - val_accuracy: 0.9500\n",
      "Epoch 637/5000\n",
      "1000/1000 [==============================] - 1s 808us/step - loss: 0.1418 - accuracy: 0.9600 - val_loss: 0.1856 - val_accuracy: 0.9500\n",
      "Epoch 638/5000\n",
      "1000/1000 [==============================] - 1s 845us/step - loss: 0.0731 - accuracy: 0.9570 - val_loss: 0.1379 - val_accuracy: 0.9500\n",
      "Epoch 639/5000\n",
      "1000/1000 [==============================] - 1s 868us/step - loss: 0.0340 - accuracy: 0.9670 - val_loss: 0.1495 - val_accuracy: 0.9750\n",
      "Epoch 640/5000\n",
      "1000/1000 [==============================] - 1s 868us/step - loss: 0.0315 - accuracy: 0.9600 - val_loss: 0.1285 - val_accuracy: 0.9500\n",
      "Epoch 641/5000\n",
      "1000/1000 [==============================] - 1s 840us/step - loss: 0.0267 - accuracy: 0.9620 - val_loss: 0.1196 - val_accuracy: 0.9500\n",
      "Epoch 642/5000\n",
      "1000/1000 [==============================] - 1s 827us/step - loss: 0.0263 - accuracy: 0.9620 - val_loss: 0.1144 - val_accuracy: 0.9250\n",
      "Epoch 643/5000\n",
      "1000/1000 [==============================] - 1s 796us/step - loss: 0.0248 - accuracy: 0.9640 - val_loss: 0.1291 - val_accuracy: 0.9250\n",
      "Epoch 644/5000\n",
      "1000/1000 [==============================] - 1s 803us/step - loss: 0.0261 - accuracy: 0.9630 - val_loss: 0.1359 - val_accuracy: 0.9250\n",
      "Epoch 645/5000\n",
      "1000/1000 [==============================] - 1s 808us/step - loss: 0.0338 - accuracy: 0.9600 - val_loss: 0.1234 - val_accuracy: 0.9500\n",
      "Epoch 646/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0284 - accuracy: 0.9580 - val_loss: 0.1265 - val_accuracy: 0.9750\n",
      "Epoch 647/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0341 - accuracy: 0.9640 - val_loss: 0.1276 - val_accuracy: 0.9500\n",
      "Epoch 648/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1270 - accuracy: 0.9530 - val_loss: 0.2560 - val_accuracy: 0.8500\n",
      "Epoch 649/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2272 - accuracy: 0.9410 - val_loss: 0.3036 - val_accuracy: 0.9000\n",
      "Epoch 650/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1005 - accuracy: 0.9450 - val_loss: 0.1669 - val_accuracy: 0.9500\n",
      "Epoch 651/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0713 - accuracy: 0.9480 - val_loss: 0.1257 - val_accuracy: 0.9500\n",
      "Epoch 652/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0424 - accuracy: 0.9600 - val_loss: 0.1222 - val_accuracy: 0.9250\n",
      "Epoch 653/5000\n",
      "1000/1000 [==============================] - 1s 803us/step - loss: 0.0301 - accuracy: 0.9600 - val_loss: 0.1299 - val_accuracy: 0.9750\n",
      "Epoch 654/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0293 - accuracy: 0.9600 - val_loss: 0.1298 - val_accuracy: 0.9500\n",
      "Epoch 655/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0242 - accuracy: 0.9590 - val_loss: 0.1418 - val_accuracy: 0.9750\n",
      "Epoch 656/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0336 - accuracy: 0.9580 - val_loss: 0.1254 - val_accuracy: 0.9500\n",
      "Epoch 657/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0604 - accuracy: 0.9540 - val_loss: 0.1753 - val_accuracy: 0.9000\n",
      "Epoch 658/5000\n",
      "1000/1000 [==============================] - 1s 989us/step - loss: 0.0832 - accuracy: 0.9530 - val_loss: 0.1726 - val_accuracy: 0.9500\n",
      "Epoch 659/5000\n",
      "1000/1000 [==============================] - 1s 966us/step - loss: 0.0962 - accuracy: 0.9450 - val_loss: 0.1662 - val_accuracy: 0.9000\n",
      "Epoch 660/5000\n",
      "1000/1000 [==============================] - 1s 965us/step - loss: 0.0485 - accuracy: 0.9530 - val_loss: 0.1313 - val_accuracy: 0.9750\n",
      "Epoch 661/5000\n",
      "1000/1000 [==============================] - 1s 953us/step - loss: 0.0294 - accuracy: 0.9680 - val_loss: 0.1395 - val_accuracy: 0.9500\n",
      "Epoch 662/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 910us/step - loss: 0.0329 - accuracy: 0.9620 - val_loss: 0.1045 - val_accuracy: 0.9750\n",
      "Epoch 663/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0699 - accuracy: 0.9610 - val_loss: 0.3202 - val_accuracy: 0.9500\n",
      "Epoch 664/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3173 - accuracy: 0.9260 - val_loss: 0.2398 - val_accuracy: 0.9500\n",
      "Epoch 665/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.6559 - accuracy: 0.9200 - val_loss: 0.4203 - val_accuracy: 0.9250\n",
      "Epoch 666/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2017 - accuracy: 0.9320 - val_loss: 0.2644 - val_accuracy: 0.9250\n",
      "Epoch 667/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0547 - accuracy: 0.9470 - val_loss: 0.1614 - val_accuracy: 0.9500\n",
      "Epoch 668/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0302 - accuracy: 0.9540 - val_loss: 0.1560 - val_accuracy: 0.9250\n",
      "Epoch 669/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0271 - accuracy: 0.9590 - val_loss: 0.1364 - val_accuracy: 0.9500\n",
      "Epoch 670/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0281 - accuracy: 0.9590 - val_loss: 0.1442 - val_accuracy: 0.9500\n",
      "Epoch 671/5000\n",
      "1000/1000 [==============================] - 1s 932us/step - loss: 0.0225 - accuracy: 0.9710 - val_loss: 0.1283 - val_accuracy: 0.9500\n",
      "Epoch 672/5000\n",
      "1000/1000 [==============================] - 1s 888us/step - loss: 0.0254 - accuracy: 0.9630 - val_loss: 0.1186 - val_accuracy: 0.9750\n",
      "Epoch 673/5000\n",
      "1000/1000 [==============================] - 1s 855us/step - loss: 0.0259 - accuracy: 0.9620 - val_loss: 0.1275 - val_accuracy: 0.9750\n",
      "Epoch 674/5000\n",
      "1000/1000 [==============================] - 1s 911us/step - loss: 0.0231 - accuracy: 0.9680 - val_loss: 0.1132 - val_accuracy: 0.9750\n",
      "Epoch 675/5000\n",
      "1000/1000 [==============================] - 1s 849us/step - loss: 0.0225 - accuracy: 0.9660 - val_loss: 0.1323 - val_accuracy: 0.9750\n",
      "Epoch 676/5000\n",
      "1000/1000 [==============================] - 1s 859us/step - loss: 0.0221 - accuracy: 0.9660 - val_loss: 0.1257 - val_accuracy: 0.9500\n",
      "Epoch 677/5000\n",
      "1000/1000 [==============================] - 1s 902us/step - loss: 0.0208 - accuracy: 0.9740 - val_loss: 0.1288 - val_accuracy: 0.9750\n",
      "Epoch 678/5000\n",
      "1000/1000 [==============================] - 1s 919us/step - loss: 0.0265 - accuracy: 0.9660 - val_loss: 0.1478 - val_accuracy: 0.9500\n",
      "Epoch 679/5000\n",
      "1000/1000 [==============================] - 1s 875us/step - loss: 0.0411 - accuracy: 0.9670 - val_loss: 0.1411 - val_accuracy: 0.9500\n",
      "Epoch 680/5000\n",
      "1000/1000 [==============================] - 1s 885us/step - loss: 0.0427 - accuracy: 0.9600 - val_loss: 0.2038 - val_accuracy: 0.9500\n",
      "Epoch 681/5000\n",
      "1000/1000 [==============================] - 1s 871us/step - loss: 0.0495 - accuracy: 0.9550 - val_loss: 0.1644 - val_accuracy: 0.9500\n",
      "Epoch 682/5000\n",
      "1000/1000 [==============================] - 1s 901us/step - loss: 0.0647 - accuracy: 0.9550 - val_loss: 0.1054 - val_accuracy: 0.9500\n",
      "Epoch 683/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1110 - accuracy: 0.9570 - val_loss: 0.3584 - val_accuracy: 0.9250\n",
      "Epoch 684/5000\n",
      "1000/1000 [==============================] - 1s 960us/step - loss: 0.1126 - accuracy: 0.9500 - val_loss: 0.2091 - val_accuracy: 0.9250\n",
      "Epoch 685/5000\n",
      "1000/1000 [==============================] - 1s 922us/step - loss: 0.0763 - accuracy: 0.9440 - val_loss: 0.1576 - val_accuracy: 0.9000\n",
      "Epoch 686/5000\n",
      "1000/1000 [==============================] - 1s 941us/step - loss: 0.0456 - accuracy: 0.9590 - val_loss: 0.1695 - val_accuracy: 0.9750\n",
      "Epoch 687/5000\n",
      "1000/1000 [==============================] - 1s 959us/step - loss: 0.0343 - accuracy: 0.9590 - val_loss: 0.1229 - val_accuracy: 0.9750\n",
      "Epoch 688/5000\n",
      "1000/1000 [==============================] - 1s 944us/step - loss: 0.0244 - accuracy: 0.9630 - val_loss: 0.1175 - val_accuracy: 0.9750\n",
      "Epoch 689/5000\n",
      "1000/1000 [==============================] - 1s 899us/step - loss: 0.0278 - accuracy: 0.9580 - val_loss: 0.1292 - val_accuracy: 0.9750\n",
      "Epoch 690/5000\n",
      "1000/1000 [==============================] - 1s 911us/step - loss: 0.0264 - accuracy: 0.9710 - val_loss: 0.1401 - val_accuracy: 0.9750\n",
      "Epoch 691/5000\n",
      "1000/1000 [==============================] - 1s 919us/step - loss: 0.0325 - accuracy: 0.9680 - val_loss: 0.0926 - val_accuracy: 0.9750\n",
      "Epoch 692/5000\n",
      "1000/1000 [==============================] - 1s 869us/step - loss: 0.0288 - accuracy: 0.9700 - val_loss: 0.1349 - val_accuracy: 0.9500\n",
      "Epoch 693/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0355 - accuracy: 0.9640 - val_loss: 0.1222 - val_accuracy: 0.9750\n",
      "Epoch 694/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0283 - accuracy: 0.9650 - val_loss: 0.1093 - val_accuracy: 0.9750\n",
      "Epoch 695/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0314 - accuracy: 0.9630 - val_loss: 0.1372 - val_accuracy: 0.9500\n",
      "Epoch 696/5000\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0316 - accuracy: 0.9610 - val_loss: 0.1229 - val_accuracy: 0.9750\n",
      "Epoch 697/5000\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.3191 - accuracy: 0.9420 - val_loss: 0.4491 - val_accuracy: 0.9000\n",
      "Epoch 698/5000\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.2343 - accuracy: 0.9330 - val_loss: 0.3620 - val_accuracy: 0.9250\n",
      "Epoch 699/5000\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0916 - accuracy: 0.9600 - val_loss: 0.1886 - val_accuracy: 0.9750\n",
      "Epoch 700/5000\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0632 - accuracy: 0.9610 - val_loss: 0.1343 - val_accuracy: 0.9250\n",
      "Epoch 701/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0458 - accuracy: 0.9730 - val_loss: 0.1551 - val_accuracy: 0.9500\n",
      "Epoch 702/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0751 - accuracy: 0.9690 - val_loss: 0.2368 - val_accuracy: 0.9500\n",
      "Epoch 703/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5608 - accuracy: 0.9230 - val_loss: 0.3786 - val_accuracy: 0.8750\n",
      "Epoch 704/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1783 - accuracy: 0.9260 - val_loss: 0.1920 - val_accuracy: 0.9000\n",
      "Epoch 705/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0410 - accuracy: 0.9570 - val_loss: 0.1445 - val_accuracy: 0.9500\n",
      "Epoch 706/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0266 - accuracy: 0.9630 - val_loss: 0.1430 - val_accuracy: 0.9500\n",
      "Epoch 707/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0223 - accuracy: 0.9720 - val_loss: 0.1322 - val_accuracy: 0.9500\n",
      "Epoch 708/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0272 - accuracy: 0.9670 - val_loss: 0.1294 - val_accuracy: 0.9500\n",
      "Epoch 709/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0213 - accuracy: 0.9680 - val_loss: 0.1230 - val_accuracy: 0.9750\n",
      "Epoch 710/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0211 - accuracy: 0.9670 - val_loss: 0.1234 - val_accuracy: 0.9500\n",
      "Epoch 711/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0226 - accuracy: 0.9710 - val_loss: 0.1205 - val_accuracy: 0.9500\n",
      "Epoch 712/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0198 - accuracy: 0.9670 - val_loss: 0.1212 - val_accuracy: 0.9500\n",
      "Epoch 713/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0274 - accuracy: 0.9640 - val_loss: 0.0944 - val_accuracy: 0.9750\n",
      "Epoch 714/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0423 - accuracy: 0.9670 - val_loss: 0.1944 - val_accuracy: 0.9250\n",
      "Epoch 715/5000\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.0574 - accuracy: 0.9590 - val_loss: 0.1225 - val_accuracy: 0.9250\n",
      "Epoch 716/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0402 - accuracy: 0.9660 - val_loss: 0.1414 - val_accuracy: 0.9500\n",
      "Epoch 717/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0316 - accuracy: 0.9540 - val_loss: 0.1249 - val_accuracy: 0.9500\n",
      "Epoch 718/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0246 - accuracy: 0.9700 - val_loss: 0.1373 - val_accuracy: 0.9750\n",
      "Epoch 719/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0462 - accuracy: 0.9700 - val_loss: 0.1566 - val_accuracy: 0.9500\n",
      "Epoch 720/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0694 - accuracy: 0.9600 - val_loss: 0.2398 - val_accuracy: 0.9250\n",
      "Epoch 721/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0703 - accuracy: 0.9480 - val_loss: 0.2327 - val_accuracy: 0.9250\n",
      "Epoch 722/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2963 - accuracy: 0.9410 - val_loss: 0.2117 - val_accuracy: 0.9000\n",
      "Epoch 723/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1529 - accuracy: 0.9420 - val_loss: 0.3199 - val_accuracy: 0.9250\n",
      "Epoch 724/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2229 - accuracy: 0.9430 - val_loss: 0.3152 - val_accuracy: 0.9500\n",
      "Epoch 725/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0778 - accuracy: 0.9600 - val_loss: 0.3289 - val_accuracy: 0.9750\n",
      "Epoch 726/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0829 - accuracy: 0.9610 - val_loss: 0.1691 - val_accuracy: 0.9250\n",
      "Epoch 727/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0326 - accuracy: 0.9690 - val_loss: 0.1690 - val_accuracy: 0.9500\n",
      "Epoch 728/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0324 - accuracy: 0.9640 - val_loss: 0.1559 - val_accuracy: 0.9500\n",
      "Epoch 729/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0250 - accuracy: 0.9660 - val_loss: 0.1272 - val_accuracy: 0.9750\n",
      "Epoch 730/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0256 - accuracy: 0.9710 - val_loss: 0.1281 - val_accuracy: 0.9500\n",
      "Epoch 731/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0216 - accuracy: 0.9680 - val_loss: 0.1374 - val_accuracy: 0.9500\n",
      "Epoch 732/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0206 - accuracy: 0.9740 - val_loss: 0.1187 - val_accuracy: 0.9750\n",
      "Epoch 733/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0214 - accuracy: 0.9710 - val_loss: 0.1441 - val_accuracy: 0.9750\n",
      "Epoch 734/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0261 - accuracy: 0.9750 - val_loss: 0.1270 - val_accuracy: 0.9250\n",
      "Epoch 735/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0272 - accuracy: 0.9630 - val_loss: 0.1152 - val_accuracy: 0.9500\n",
      "Epoch 736/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0200 - accuracy: 0.9690 - val_loss: 0.1187 - val_accuracy: 0.9500\n",
      "Epoch 737/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0208 - accuracy: 0.9690 - val_loss: 0.1370 - val_accuracy: 0.9250\n",
      "Epoch 738/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0410 - accuracy: 0.9560 - val_loss: 0.1142 - val_accuracy: 0.9500\n",
      "Epoch 739/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0353 - accuracy: 0.9510 - val_loss: 0.1787 - val_accuracy: 0.9500\n",
      "Epoch 740/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1056 - accuracy: 0.9440 - val_loss: 0.2433 - val_accuracy: 0.9250\n",
      "Epoch 741/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3172 - accuracy: 0.9250 - val_loss: 0.1986 - val_accuracy: 0.9250\n",
      "Epoch 742/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0969 - accuracy: 0.9530 - val_loss: 0.1400 - val_accuracy: 0.9000\n",
      "Epoch 743/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0605 - accuracy: 0.9560 - val_loss: 0.2113 - val_accuracy: 0.9250\n",
      "Epoch 744/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0857 - accuracy: 0.9550 - val_loss: 0.1801 - val_accuracy: 0.9500\n",
      "Epoch 745/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1050 - accuracy: 0.9540 - val_loss: 0.1452 - val_accuracy: 0.9250\n",
      "Epoch 746/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0689 - accuracy: 0.9660 - val_loss: 0.1336 - val_accuracy: 0.9000\n",
      "Epoch 747/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0282 - accuracy: 0.9710 - val_loss: 0.1240 - val_accuracy: 0.9500\n",
      "Epoch 748/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0269 - accuracy: 0.9700 - val_loss: 0.1519 - val_accuracy: 0.9250\n",
      "Epoch 749/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0241 - accuracy: 0.9710 - val_loss: 0.1212 - val_accuracy: 0.9500\n",
      "Epoch 750/5000\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0220 - accuracy: 0.9700 - val_loss: 0.1284 - val_accuracy: 0.9750\n",
      "Epoch 751/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0219 - accuracy: 0.9660 - val_loss: 0.1055 - val_accuracy: 0.9500\n",
      "Epoch 752/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0186 - accuracy: 0.9710 - val_loss: 0.1367 - val_accuracy: 0.9750\n",
      "Epoch 753/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0316 - accuracy: 0.9670 - val_loss: 0.1126 - val_accuracy: 0.9750\n",
      "Epoch 754/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0374 - accuracy: 0.9640 - val_loss: 0.5051 - val_accuracy: 0.9250\n",
      "Epoch 755/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0780 - accuracy: 0.9420 - val_loss: 0.1671 - val_accuracy: 0.9250\n",
      "Epoch 756/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0987 - accuracy: 0.9500 - val_loss: 0.1902 - val_accuracy: 0.9250\n",
      "Epoch 757/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0643 - accuracy: 0.9640 - val_loss: 0.1422 - val_accuracy: 0.9500\n",
      "Epoch 758/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1325 - accuracy: 0.9610 - val_loss: 0.2382 - val_accuracy: 0.9250\n",
      "Epoch 759/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2656 - accuracy: 0.9380 - val_loss: 0.1971 - val_accuracy: 0.9250\n",
      "Epoch 760/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0697 - accuracy: 0.9530 - val_loss: 0.1604 - val_accuracy: 0.9750\n",
      "Epoch 761/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0349 - accuracy: 0.9620 - val_loss: 0.1185 - val_accuracy: 0.9750\n",
      "Epoch 762/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0268 - accuracy: 0.9680 - val_loss: 0.1501 - val_accuracy: 0.9750\n",
      "Epoch 763/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0274 - accuracy: 0.9690 - val_loss: 0.1760 - val_accuracy: 0.9500\n",
      "Epoch 764/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0239 - accuracy: 0.9700 - val_loss: 0.1262 - val_accuracy: 0.9750\n",
      "Epoch 765/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0210 - accuracy: 0.9710 - val_loss: 0.1385 - val_accuracy: 0.9750\n",
      "Epoch 766/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0181 - accuracy: 0.9720 - val_loss: 0.1182 - val_accuracy: 0.9500\n",
      "Epoch 767/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0170 - accuracy: 0.9740 - val_loss: 0.1238 - val_accuracy: 0.9750\n",
      "Epoch 768/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0193 - accuracy: 0.9720 - val_loss: 0.1582 - val_accuracy: 0.9000\n",
      "Epoch 769/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0708 - accuracy: 0.9580 - val_loss: 0.1484 - val_accuracy: 0.9500\n",
      "Epoch 770/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0448 - accuracy: 0.9580 - val_loss: 0.1291 - val_accuracy: 0.9500\n",
      "Epoch 771/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0684 - accuracy: 0.9550 - val_loss: 0.1510 - val_accuracy: 0.9750\n",
      "Epoch 772/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0399 - accuracy: 0.9640 - val_loss: 0.1370 - val_accuracy: 0.9250\n",
      "Epoch 773/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1230 - accuracy: 0.9510 - val_loss: 0.1696 - val_accuracy: 0.9000\n",
      "Epoch 774/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0505 - accuracy: 0.9580 - val_loss: 0.1483 - val_accuracy: 0.9500\n",
      "Epoch 775/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0288 - accuracy: 0.9650 - val_loss: 0.1421 - val_accuracy: 0.9500\n",
      "Epoch 776/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0748 - accuracy: 0.9610 - val_loss: 0.2914 - val_accuracy: 0.9500\n",
      "Epoch 777/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3423 - accuracy: 0.9450 - val_loss: 0.1940 - val_accuracy: 0.9000\n",
      "Epoch 778/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1593 - accuracy: 0.9510 - val_loss: 0.1742 - val_accuracy: 0.9000\n",
      "Epoch 779/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2313 - accuracy: 0.9420 - val_loss: 0.2346 - val_accuracy: 0.9250\n",
      "Epoch 780/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0579 - accuracy: 0.9540 - val_loss: 0.3225 - val_accuracy: 0.9500\n",
      "Epoch 781/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0272 - accuracy: 0.9680 - val_loss: 0.1175 - val_accuracy: 0.9250\n",
      "Epoch 782/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0212 - accuracy: 0.9670 - val_loss: 0.1466 - val_accuracy: 0.9500\n",
      "Epoch 783/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0186 - accuracy: 0.9710 - val_loss: 0.1164 - val_accuracy: 0.9500\n",
      "Epoch 784/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0204 - accuracy: 0.9730 - val_loss: 0.1235 - val_accuracy: 0.9750\n",
      "Epoch 785/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0179 - accuracy: 0.9720 - val_loss: 0.1195 - val_accuracy: 0.9500\n",
      "Epoch 786/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0164 - accuracy: 0.9700 - val_loss: 0.1058 - val_accuracy: 0.9750\n",
      "Epoch 787/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0166 - accuracy: 0.9740 - val_loss: 0.1201 - val_accuracy: 0.9750\n",
      "Epoch 788/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0185 - accuracy: 0.9730 - val_loss: 0.0932 - val_accuracy: 0.9750\n",
      "Epoch 789/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0164 - accuracy: 0.9690 - val_loss: 0.1192 - val_accuracy: 0.9750\n",
      "Epoch 790/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0193 - accuracy: 0.9680 - val_loss: 0.1593 - val_accuracy: 0.9500\n",
      "Epoch 791/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0229 - accuracy: 0.9660 - val_loss: 0.1131 - val_accuracy: 0.9750\n",
      "Epoch 792/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0207 - accuracy: 0.9690 - val_loss: 0.1292 - val_accuracy: 0.9750\n",
      "Epoch 793/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0251 - accuracy: 0.9730 - val_loss: 0.1332 - val_accuracy: 0.9750\n",
      "Epoch 794/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0235 - accuracy: 0.9740 - val_loss: 0.1501 - val_accuracy: 0.9500\n",
      "Epoch 795/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0663 - accuracy: 0.9600 - val_loss: 0.1667 - val_accuracy: 0.9750\n",
      "Epoch 796/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0727 - accuracy: 0.9450 - val_loss: 0.1465 - val_accuracy: 0.9250\n",
      "Epoch 797/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0403 - accuracy: 0.9660 - val_loss: 0.1214 - val_accuracy: 0.9500\n",
      "Epoch 798/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1491 - accuracy: 0.9410 - val_loss: 0.1070 - val_accuracy: 0.8750\n",
      "Epoch 799/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3791 - accuracy: 0.9310 - val_loss: 0.2764 - val_accuracy: 0.8750\n",
      "Epoch 800/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1765 - accuracy: 0.9500 - val_loss: 0.1182 - val_accuracy: 0.9250\n",
      "Epoch 801/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0499 - accuracy: 0.9660 - val_loss: 0.1854 - val_accuracy: 0.9250\n",
      "Epoch 802/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0652 - accuracy: 0.9720 - val_loss: 0.1855 - val_accuracy: 0.9500\n",
      "Epoch 803/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0328 - accuracy: 0.9690 - val_loss: 0.1175 - val_accuracy: 0.9750\n",
      "Epoch 804/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0217 - accuracy: 0.9720 - val_loss: 0.1285 - val_accuracy: 0.9750\n",
      "Epoch 805/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0173 - accuracy: 0.9670 - val_loss: 0.1265 - val_accuracy: 0.9500\n",
      "Epoch 806/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0156 - accuracy: 0.9750 - val_loss: 0.1054 - val_accuracy: 0.9750\n",
      "Epoch 807/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0192 - accuracy: 0.9780 - val_loss: 0.1197 - val_accuracy: 0.9750\n",
      "Epoch 808/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0218 - accuracy: 0.9700 - val_loss: 0.1062 - val_accuracy: 0.9750\n",
      "Epoch 809/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0181 - accuracy: 0.9720 - val_loss: 0.1199 - val_accuracy: 0.9750\n",
      "Epoch 810/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0203 - accuracy: 0.9710 - val_loss: 0.1196 - val_accuracy: 0.9500\n",
      "Epoch 811/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0181 - accuracy: 0.9690 - val_loss: 0.1325 - val_accuracy: 0.9250\n",
      "Epoch 812/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0247 - accuracy: 0.9650 - val_loss: 0.1283 - val_accuracy: 0.9000\n",
      "Epoch 813/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0348 - accuracy: 0.9660 - val_loss: 0.1789 - val_accuracy: 0.9500\n",
      "Epoch 814/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0828 - accuracy: 0.9650 - val_loss: 0.1123 - val_accuracy: 0.9500\n",
      "Epoch 815/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0604 - accuracy: 0.9580 - val_loss: 0.1411 - val_accuracy: 0.9500\n",
      "Epoch 816/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0669 - accuracy: 0.9560 - val_loss: 0.1749 - val_accuracy: 0.9250\n",
      "Epoch 817/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2045 - accuracy: 0.9600 - val_loss: 0.2350 - val_accuracy: 0.9500\n",
      "Epoch 818/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1165 - accuracy: 0.9340 - val_loss: 0.1229 - val_accuracy: 0.9500\n",
      "Epoch 819/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0443 - accuracy: 0.9710 - val_loss: 0.1541 - val_accuracy: 0.9500\n",
      "Epoch 820/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0200 - accuracy: 0.9640 - val_loss: 0.1238 - val_accuracy: 0.9750\n",
      "Epoch 821/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0168 - accuracy: 0.9710 - val_loss: 0.1205 - val_accuracy: 0.9750\n",
      "Epoch 822/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0163 - accuracy: 0.9750 - val_loss: 0.1286 - val_accuracy: 0.9750\n",
      "Epoch 823/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0642 - accuracy: 0.9620 - val_loss: 0.1332 - val_accuracy: 0.9250\n",
      "Epoch 824/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2316 - accuracy: 0.9460 - val_loss: 0.9594 - val_accuracy: 0.9250\n",
      "Epoch 825/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3357 - accuracy: 0.9360 - val_loss: 0.2359 - val_accuracy: 0.9250\n",
      "Epoch 826/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0671 - accuracy: 0.9490 - val_loss: 0.1560 - val_accuracy: 0.9250\n",
      "Epoch 827/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0428 - accuracy: 0.9650 - val_loss: 0.1836 - val_accuracy: 0.9500\n",
      "Epoch 828/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0307 - accuracy: 0.9690 - val_loss: 0.1201 - val_accuracy: 0.9750\n",
      "Epoch 829/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0244 - accuracy: 0.9730 - val_loss: 0.1572 - val_accuracy: 0.9750\n",
      "Epoch 830/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0198 - accuracy: 0.9750 - val_loss: 0.1007 - val_accuracy: 0.9500\n",
      "Epoch 831/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0163 - accuracy: 0.9770 - val_loss: 0.1074 - val_accuracy: 0.9750\n",
      "Epoch 832/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0144 - accuracy: 0.9730 - val_loss: 0.1305 - val_accuracy: 0.9750\n",
      "Epoch 833/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0146 - accuracy: 0.9740 - val_loss: 0.1195 - val_accuracy: 0.9750\n",
      "Epoch 834/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0191 - accuracy: 0.9730 - val_loss: 0.1208 - val_accuracy: 0.9500\n",
      "Epoch 835/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0185 - accuracy: 0.9750 - val_loss: 0.1260 - val_accuracy: 0.9750\n",
      "Epoch 836/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0149 - accuracy: 0.9760 - val_loss: 0.1248 - val_accuracy: 0.9750\n",
      "Epoch 837/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0152 - accuracy: 0.9760 - val_loss: 0.1176 - val_accuracy: 0.9750\n",
      "Epoch 838/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0189 - accuracy: 0.9750 - val_loss: 0.1308 - val_accuracy: 0.9500\n",
      "Epoch 839/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0585 - accuracy: 0.9640 - val_loss: 0.1767 - val_accuracy: 0.9250\n",
      "Epoch 840/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0845 - accuracy: 0.9580 - val_loss: 0.1106 - val_accuracy: 0.9250\n",
      "Epoch 841/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0415 - accuracy: 0.9540 - val_loss: 0.1082 - val_accuracy: 0.9750\n",
      "Epoch 842/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0427 - accuracy: 0.9620 - val_loss: 0.1731 - val_accuracy: 0.9500\n",
      "Epoch 843/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1011 - accuracy: 0.9550 - val_loss: 0.6250 - val_accuracy: 0.9250\n",
      "Epoch 844/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1584 - accuracy: 0.9550 - val_loss: 0.1007 - val_accuracy: 0.9250\n",
      "Epoch 845/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1052 - accuracy: 0.9600 - val_loss: 0.1490 - val_accuracy: 0.9750\n",
      "Epoch 846/5000\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0486 - accuracy: 0.9590 - val_loss: 0.1495 - val_accuracy: 0.9000\n",
      "Epoch 847/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0308 - accuracy: 0.9690 - val_loss: 0.1044 - val_accuracy: 0.9750\n",
      "Epoch 848/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0205 - accuracy: 0.9680 - val_loss: 0.1253 - val_accuracy: 0.9750\n",
      "Epoch 849/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0195 - accuracy: 0.9690 - val_loss: 0.1319 - val_accuracy: 0.9750\n",
      "Epoch 850/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0183 - accuracy: 0.9680 - val_loss: 0.0971 - val_accuracy: 0.9500\n",
      "Epoch 851/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0154 - accuracy: 0.9720 - val_loss: 0.1068 - val_accuracy: 0.9750\n",
      "Epoch 852/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0140 - accuracy: 0.9780 - val_loss: 0.0996 - val_accuracy: 0.9750\n",
      "Epoch 853/5000\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0145 - accuracy: 0.9770 - val_loss: 0.1223 - val_accuracy: 0.9500\n",
      "Epoch 854/5000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0186 - accuracy: 0.9690 - val_loss: 0.1007 - val_accuracy: 0.9750\n",
      "Epoch 855/5000\n",
      "1000/1000 [==============================] - 1s 617us/step - loss: 0.0357 - accuracy: 0.9710 - val_loss: 0.1918 - val_accuracy: 0.9250\n",
      "Epoch 856/5000\n",
      "1000/1000 [==============================] - 1s 612us/step - loss: 0.1605 - accuracy: 0.9370 - val_loss: 0.2614 - val_accuracy: 0.9500\n",
      "Epoch 857/5000\n",
      "1000/1000 [==============================] - 1s 607us/step - loss: 0.1229 - accuracy: 0.9450 - val_loss: 0.3219 - val_accuracy: 0.9250\n",
      "Epoch 858/5000\n",
      "1000/1000 [==============================] - 1s 610us/step - loss: 0.1260 - accuracy: 0.9530 - val_loss: 0.2199 - val_accuracy: 0.9750\n",
      "Epoch 859/5000\n",
      "1000/1000 [==============================] - 1s 605us/step - loss: 0.0527 - accuracy: 0.9630 - val_loss: 0.1369 - val_accuracy: 0.9500\n",
      "Epoch 860/5000\n",
      "1000/1000 [==============================] - 1s 608us/step - loss: 0.0344 - accuracy: 0.9720 - val_loss: 0.1070 - val_accuracy: 0.9500\n",
      "Epoch 861/5000\n",
      "1000/1000 [==============================] - 1s 609us/step - loss: 0.0201 - accuracy: 0.9720 - val_loss: 0.1016 - val_accuracy: 0.9500\n",
      "Epoch 862/5000\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 0.0243 - accuracy: 0.9740 - val_loss: 0.0763 - val_accuracy: 0.9500\n",
      "Epoch 863/5000\n",
      "1000/1000 [==============================] - 1s 606us/step - loss: 0.0190 - accuracy: 0.9720 - val_loss: 0.1288 - val_accuracy: 0.9750\n",
      "Epoch 864/5000\n",
      "1000/1000 [==============================] - 1s 605us/step - loss: 0.0172 - accuracy: 0.9700 - val_loss: 0.1102 - val_accuracy: 0.9750\n",
      "Epoch 865/5000\n",
      "1000/1000 [==============================] - 1s 604us/step - loss: 0.0151 - accuracy: 0.9740 - val_loss: 0.1059 - val_accuracy: 0.9750\n",
      "Epoch 866/5000\n",
      "1000/1000 [==============================] - 1s 605us/step - loss: 0.0144 - accuracy: 0.9640 - val_loss: 0.1128 - val_accuracy: 0.9750\n",
      "Epoch 867/5000\n",
      "1000/1000 [==============================] - 1s 607us/step - loss: 0.0159 - accuracy: 0.9720 - val_loss: 0.1258 - val_accuracy: 0.9750\n",
      "Epoch 868/5000\n",
      "1000/1000 [==============================] - 1s 607us/step - loss: 0.0194 - accuracy: 0.9660 - val_loss: 0.1235 - val_accuracy: 0.9750\n",
      "Epoch 869/5000\n",
      "1000/1000 [==============================] - 1s 607us/step - loss: 0.0249 - accuracy: 0.9740 - val_loss: 0.1126 - val_accuracy: 0.9500\n",
      "Epoch 870/5000\n",
      "1000/1000 [==============================] - 1s 604us/step - loss: 0.0853 - accuracy: 0.9570 - val_loss: 0.3117 - val_accuracy: 0.9250\n",
      "Epoch 871/5000\n",
      "1000/1000 [==============================] - 1s 607us/step - loss: 0.3154 - accuracy: 0.9260 - val_loss: 0.3028 - val_accuracy: 0.9750\n",
      "Epoch 872/5000\n",
      "1000/1000 [==============================] - 1s 606us/step - loss: 0.1359 - accuracy: 0.9440 - val_loss: 0.1498 - val_accuracy: 0.9750\n",
      "Epoch 873/5000\n",
      "1000/1000 [==============================] - 1s 605us/step - loss: 0.1105 - accuracy: 0.9660 - val_loss: 0.4262 - val_accuracy: 0.9250\n",
      "Epoch 874/5000\n",
      "1000/1000 [==============================] - 1s 610us/step - loss: 0.0892 - accuracy: 0.9450 - val_loss: 0.1413 - val_accuracy: 0.9750\n",
      "Epoch 875/5000\n",
      "1000/1000 [==============================] - 1s 604us/step - loss: 0.0359 - accuracy: 0.9690 - val_loss: 0.2016 - val_accuracy: 0.9750\n",
      "Epoch 876/5000\n",
      "1000/1000 [==============================] - 1s 605us/step - loss: 0.0474 - accuracy: 0.9680 - val_loss: 0.1232 - val_accuracy: 0.9500\n",
      "Epoch 877/5000\n",
      "1000/1000 [==============================] - 1s 612us/step - loss: 0.0249 - accuracy: 0.9690 - val_loss: 0.1115 - val_accuracy: 0.9250\n",
      "Epoch 878/5000\n",
      "1000/1000 [==============================] - 1s 604us/step - loss: 0.0252 - accuracy: 0.9730 - val_loss: 0.1388 - val_accuracy: 0.9750\n",
      "Epoch 879/5000\n",
      "1000/1000 [==============================] - 1s 616us/step - loss: 0.0157 - accuracy: 0.9730 - val_loss: 0.1228 - val_accuracy: 0.9750\n",
      "Epoch 880/5000\n",
      "1000/1000 [==============================] - 1s 608us/step - loss: 0.0163 - accuracy: 0.9780 - val_loss: 0.1074 - val_accuracy: 0.9750\n",
      "Epoch 881/5000\n",
      "1000/1000 [==============================] - 1s 613us/step - loss: 0.0138 - accuracy: 0.9790 - val_loss: 0.1285 - val_accuracy: 0.9750\n",
      "Epoch 882/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 608us/step - loss: 0.0140 - accuracy: 0.9750 - val_loss: 0.1132 - val_accuracy: 0.9750\n",
      "Epoch 883/5000\n",
      "1000/1000 [==============================] - 1s 604us/step - loss: 0.0137 - accuracy: 0.9730 - val_loss: 0.1240 - val_accuracy: 0.9500\n",
      "Epoch 884/5000\n",
      "1000/1000 [==============================] - 1s 604us/step - loss: 0.0133 - accuracy: 0.9730 - val_loss: 0.1091 - val_accuracy: 0.9500\n",
      "Epoch 885/5000\n",
      "1000/1000 [==============================] - 1s 606us/step - loss: 0.0152 - accuracy: 0.9730 - val_loss: 0.1091 - val_accuracy: 0.9750\n",
      "Epoch 886/5000\n",
      "1000/1000 [==============================] - 1s 606us/step - loss: 0.0195 - accuracy: 0.9720 - val_loss: 0.1160 - val_accuracy: 0.9750\n",
      "Epoch 887/5000\n",
      "1000/1000 [==============================] - 1s 606us/step - loss: 0.0815 - accuracy: 0.9670 - val_loss: 0.5140 - val_accuracy: 0.9000\n",
      "Epoch 888/5000\n",
      "1000/1000 [==============================] - 1s 605us/step - loss: 0.4063 - accuracy: 0.9330 - val_loss: 0.2059 - val_accuracy: 0.8750\n",
      "Epoch 889/5000\n",
      "1000/1000 [==============================] - 1s 605us/step - loss: 0.0732 - accuracy: 0.9480 - val_loss: 0.1265 - val_accuracy: 0.9500\n",
      "Epoch 890/5000\n",
      "1000/1000 [==============================] - 1s 615us/step - loss: 0.0336 - accuracy: 0.9690 - val_loss: 0.1220 - val_accuracy: 0.9750\n",
      "Epoch 891/5000\n",
      "1000/1000 [==============================] - 1s 615us/step - loss: 0.0170 - accuracy: 0.9780 - val_loss: 0.1071 - val_accuracy: 0.9750\n",
      "Epoch 892/5000\n",
      "1000/1000 [==============================] - 1s 605us/step - loss: 0.0145 - accuracy: 0.9780 - val_loss: 0.1092 - val_accuracy: 0.9750\n",
      "Epoch 893/5000\n",
      "1000/1000 [==============================] - 1s 609us/step - loss: 0.0136 - accuracy: 0.9760 - val_loss: 0.1070 - val_accuracy: 0.9750\n",
      "Epoch 894/5000\n",
      "1000/1000 [==============================] - 1s 604us/step - loss: 0.0132 - accuracy: 0.9780 - val_loss: 0.1185 - val_accuracy: 0.9750\n",
      "Epoch 895/5000\n",
      "1000/1000 [==============================] - 1s 609us/step - loss: 0.0134 - accuracy: 0.9750 - val_loss: 0.1101 - val_accuracy: 0.9750\n",
      "Epoch 896/5000\n",
      "1000/1000 [==============================] - 1s 611us/step - loss: 0.0146 - accuracy: 0.9720 - val_loss: 0.1250 - val_accuracy: 0.9500\n",
      "Epoch 897/5000\n",
      "1000/1000 [==============================] - 1s 612us/step - loss: 0.0163 - accuracy: 0.9720 - val_loss: 0.1049 - val_accuracy: 0.9500\n",
      "Epoch 898/5000\n",
      "1000/1000 [==============================] - 1s 608us/step - loss: 0.0152 - accuracy: 0.9760 - val_loss: 0.1009 - val_accuracy: 0.9750\n",
      "Epoch 899/5000\n",
      "1000/1000 [==============================] - 1s 607us/step - loss: 0.2412 - accuracy: 0.9500 - val_loss: 0.3624 - val_accuracy: 0.8750\n",
      "Epoch 900/5000\n",
      "1000/1000 [==============================] - 1s 607us/step - loss: 0.3289 - accuracy: 0.9410 - val_loss: 0.2578 - val_accuracy: 0.9250\n",
      "Epoch 901/5000\n",
      "1000/1000 [==============================] - 1s 604us/step - loss: 0.2036 - accuracy: 0.9360 - val_loss: 0.1438 - val_accuracy: 0.9250\n",
      "Epoch 902/5000\n",
      "1000/1000 [==============================] - 1s 608us/step - loss: 0.0470 - accuracy: 0.9700 - val_loss: 0.1546 - val_accuracy: 0.9750\n",
      "Epoch 903/5000\n",
      "1000/1000 [==============================] - 1s 604us/step - loss: 0.0211 - accuracy: 0.9750 - val_loss: 0.1327 - val_accuracy: 0.9750\n",
      "Epoch 904/5000\n",
      "1000/1000 [==============================] - 1s 604us/step - loss: 0.0167 - accuracy: 0.9740 - val_loss: 0.1204 - val_accuracy: 0.9750\n",
      "Epoch 905/5000\n",
      "1000/1000 [==============================] - 1s 603us/step - loss: 0.0148 - accuracy: 0.9740 - val_loss: 0.1243 - val_accuracy: 0.9750\n",
      "Epoch 906/5000\n",
      "1000/1000 [==============================] - 1s 609us/step - loss: 0.0129 - accuracy: 0.9780 - val_loss: 0.1128 - val_accuracy: 0.9500\n",
      "Epoch 907/5000\n",
      "1000/1000 [==============================] - 1s 609us/step - loss: 0.0137 - accuracy: 0.9820 - val_loss: 0.1256 - val_accuracy: 0.9750\n",
      "\n",
      "Reached 95% accuracy so cancelling training!\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(p_train,B_train,validation_split=0.038,batch_size=10,epochs=5000,callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('98bk02.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('EmuBk0.2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6308549908>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "plt.suptitle(r'Accuracy and Loss on the validation set for $B(k_1,k_2,k_3)$ at $k =1.5Mpc^{-1}$')\n",
    "plt.subplot(1,2,1)\n",
    "#plt.hline()\n",
    "c = list(np.arange(0,1,0.1))\n",
    "c.append(0.98)\n",
    "plt.yticks(c)\n",
    "plt.plot(history.history['accuracy'],lw=3,color = 'purple')\n",
    "plt.plot(history.history['val_accuracy'],color='orange',)\n",
    "plt.hlines(y = 0.98,xmin=0,xmax=1000,linestyles='dashdot',lw =1)\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='lower right')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plt.plot(history.history['loss'],color = 'purple')\n",
    "plt.plot(history.history['val_loss'],color='orange')\n",
    "plt.hlines(y = 0,xmin=0,xmax=1000,linestyles='dashed',lw =1)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.savefig('lvac1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
